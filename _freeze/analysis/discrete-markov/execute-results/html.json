{
  "hash": "b8642cca8abbfe82ec95d1d8c97c48ed",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Discrete Time Markov Model\"\nsubtitle: \"Examining the Association Between Procrastination and Cognitive Transitions\"\n---\n\n\n\n\n# Setting up {.unnumbered}\n\n## Loading packages {.unnumbered}\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Check out my packages\"}\n# Packages ---------------------------------------------------------------------\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(ggplot2)\nlibrary(patchwork)\n```\n:::\n\n\n\n\n## Loading functions {.unnumbered}\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Check out my functions\"}\n# Functions --------------------------------------------------------------------\nextract_years <- function(data, years, impute = TRUE, cog_total = FALSE, absorbing = TRUE) {\n  # Extracts cognitive function data for specified years from a dataset.\n  # Converts numeric cognitive status codes (1, 2, 3) into descriptive labels\n  # (\"Normal Cognition\", \"MCI\", \"Dementia\") for easier interpretation.\n  # Arguments:\n  #   - data: The input dataset containing cognitive function data.\n  #   - years: A vector of years for which data should be extracted.\n  # Returns:\n  #   - A dataset with ID and cognitive status columns for the specified years.\n  \n  # Create dynamic column names based on the years provided\n  cogfunction_cols <- paste0(\"cogfunction\", years)\n  cogtotal_cols    <- paste0(\"cogtot27_imp\", years)\n  \n  if(cog_total == FALSE) {\n    data <- data |>\n      # Select only the ID column and cognitive function columns for the specified years\n      select(ID, any_of(cogfunction_cols)) |>\n      mutate(across(!c(ID), ~ case_when(\n        .x == 1 ~ \"Normal Cognition\",\n        .x == 2 ~ \"MCI\",\n        .x == 3 ~ \"Dementia\",\n        TRUE ~ NA_character_  # To handle missing/other cases\n      )))\n  } else {\n    data <- data |>\n      # Select only the ID column and cognitive function columns for the specified years\n      select(ID, any_of(cogtotal_cols)) |>\n      rename_with( .cols = !ID, .fn = ~ stringr::str_replace(\n        string = .x,\n        pattern = \"cogtot27_imp\", \n        replacement = \"cog_score_\"))\n  }\n  \n  if(impute == TRUE){\n    data <- data |>\n      tidyr::pivot_longer(\n        cols = !ID,\n        names_to = \"Wave\",\n        values_to = \"Status\") |>\n      group_by(ID) |>\n      tidyr::fill(Status, .direction = \"down\") |>\n      ungroup() |>\n      tidyr::pivot_wider(names_from = \"Wave\", values_from = \"Status\")\n  }\n  \n  if(absorbing == TRUE) {\n    data <- data |>\n      tidyr::pivot_longer(\n        cols = !ID,\n        names_to = \"Wave\",\n        values_to = \"Status\") |>\n      group_by(ID) |>\n      mutate(Status = ifelse(cumany(Status == \"Dementia\"), \"Dementia\", Status)) |>\n      ungroup() |>\n      tidyr::pivot_wider(names_from = \"Wave\", values_from = \"Status\")\n  }\n  \n  return(data)\n}\n\npivot_and_factorise <- function(data) {\n  # Converts cognitive function data from wide to long format and factorizes key variables.\n  # Pivots multiple cogfunction columns into wave/status pairs and converts categorical\n  # variables (Gender, Education, status) to factors with meaningful labels.\n  # Arguments:\n  #   - data: Dataset containing cognitive function variables in wide format\n  # Returns:\n  #   - Long-format dataset with factorized variables, ordered by ID and wave\n  # \n  data |>\n    tidyr::pivot_longer(\n      cols = starts_with(\"cogfunction\"), names_to = \"wave\",\n      names_prefix = \"cogfunction\", values_to = \"status\") |>\n    mutate(\n      Gender = factor(Gender, levels = c(0, 1)),\n      Education_tri = factor(Education_tri, levels = c(0, 1, 2)),\n      wave = factor(wave),\n      status = factor(status, \n                      levels = c(\"Normal Cognition\", \"MCI\", \"Dementia\"),\n                      labels = c(1, 2, 3))) |>\n    relocate(wave, .after = ID) |>\n    relocate(status, .after = wave)\n}\n\ncreate_transition_table <- function(year_to, year_from) {\n  # Creates a transition frequency table between two specified years of cognitive status data.\n  # Calculates row sums and total observations for transition analysis.\n  # Arguments:\n  #   - year_to: Target year for transitions (character or numeric)\n  #   - year_from: Origin year for transitions (character or numeric)\n  # Returns:\n  #   - List containing: \n  #     - transition frequency table\n  #     - row sums\n  #     - total observations\n  # \n  tbl <- table(\n    table_data[[paste0(\"HRS_\", year_to)]],\n    table_data[[paste0(\"HRS_\", year_from)]],\n    dnn = c(year_to, year_from)\n  )\n  \n  # Calculate row sums and total\n  row_sums <- rowSums(tbl)\n  total <- sum(row_sums)\n  \n  # Return as a list with both the table and summary stats\n  list(\n    table = tbl,\n    row_sums = row_sums,\n    total = total\n  )\n}\n\ncreate_transition_dataset <- function(data, transition_results) {\n  # Combines multiple transition tables into a single analysis-ready dataset.\n  # Formats period labels, ensures consistent factor levels, and structures data for visualization.\n  # Arguments:\n  #   - data: List of year pairs to process (e.g., list(c(2016,2018)))\n  #   - transition_results: List containing transition tables from create_transition_table()\n  # Returns:\n  #   - Tidy dataset with transition frequencies between all specified periods\n  # \n  data |>\n    purrr::map_dfr(~ {\n      period_name <- paste(.x[2], .x[1], sep = \" - \")\n      tbl <- transition_results[[paste(.x[2], .x[1], sep = \"-\")]]$table\n      \n      as.data.frame(tbl) |>\n        rename(t_minus_1 = 1, t = 2) %>%  # Positional renaming\n        mutate(Period = period_name, .before = t_minus_1)\n    }) |>\n    mutate(\n      Period = stringr::str_replace(Period, \"(\\\\d+) - (\\\\d+)\", \"\\\\2 - \\\\1\"),\n      Period = factor(Period, levels = c(\"2016 - 2018\", \"2018 - 2020\", \"2020 - 2022\")),\n      t_minus_1 = factor(t_minus_1, levels = c(\"Normal Cognition\", \"MCI\", \"Dementia\")),\n      t = factor(t, levels = c(\"Normal Cognition\", \"MCI\", \"Dementia\"))\n    )\n}\n\ncreate_transitions <- function(data, absorbing = FALSE){\n  # Reshapes data from wide to long format to track cognitive status transitions over time.\n  # Calculates the next wave's cognitive status for each individual and creates a transition column.\n  # Optionally treats \"Dementia\" as an absorbing state, meaning once an individual is classified\n  # with dementia, their status cannot change in subsequent waves.\n  # Arguments:\n  #   - data: The dataset containing cognitive status data.\n  #   - absorbing: A logical flag indicating whether \"Dementia\" should be treated \n  #   as an absorbing state.\n  # Returns:\n  #   - A dataset with transition information, including current and next wave statuses.\n  \n  # Reshape the data from wide to long format to track cognitive status over waves\n  data <- data |>\n    select(ID, starts_with(\"cogfunction\")) |>\n    tidyr::pivot_longer(cols = !ID,\n                        names_to = \"Wave\",\n                        values_to = \"Status\") |>\n    mutate(Wave = as.factor(stringr::str_replace(Wave, \"cogfunction\", \"\"))) |>\n    # Arrange by ID and Wave to prepare for transition calculation\n    arrange(ID, Wave) |>\n    group_by(ID) |>\n    # Get the next wave's cognitive status for each person\n    mutate(next_wave_status = lead(Status)) |>\n    ungroup()\n  \n  # We can optionally specify dementia as an absorbing state\n  # Once an individual is classified with dementia they cannot be classified\n  # with anything else \n  if(absorbing == TRUE) {\n    data <- data |>\n      group_by(ID) |>\n      mutate(\n        Status = ifelse(cumany(Status == \"Dementia\"), \"Dementia\", Status),\n        next_wave_status = ifelse(cumany(Status == \"Dementia\"), \"Dementia\", next_wave_status),\n        transition = paste(Status, next_wave_status, sep = \" to \")\n      ) |>\n      filter(Wave %in% c(2016, 2018, 2020))\n  }\n  \n  # Filter out rows where either the current or next status is missing\n  data <- data |>\n    group_by(ID) |>\n    filter(!is.na(Status), !is.na(next_wave_status)) |>\n    ungroup() |>\n    # Create a new column representing the transition from one status to the next\n    mutate(\n      transition = paste(Status, next_wave_status, sep = \" to \"),\n      transition = factor(\n        transition, \n        levels = c(\"Normal Cognition to Normal Cognition\", \"Normal Cognition to MCI\",\n                   \"Normal Cognition to Dementia\", \"MCI to Normal Cognition\", \"MCI to MCI\",\n                   \"MCI to Dementia\", \"Dementia to Dementia\") \n      ))\n  \n  return(data)\n}\n\nobserved_transition_matrix <- function(data) {\n  # Converts transition data into a properly formatted probability transition matrix.\n  # Ensures consistent state ordering and converts proportions to matrix format suitable\n  # for multi-state modeling and visualization.\n  # Arguments:\n  #   - data: Transition dataset from create_transitions()\n  # Returns:\n  #   - Square transition probability matrix with states as row/column names\n  # \n  # The order I want my matrix in\n  state_order <- c(\"Normal Cognition\", \"MCI\", \"Dementia\")\n  \n  data |>\n    group_by(Status, next_wave_status) |>\n    summarise(freq = n(),  .groups = \"drop\") |>\n    group_by(Status) |>\n    mutate(freq = round(proportions(freq), 3)) |>\n    ungroup() |>\n    complete(Status, next_wave_status, fill = list(freq = 0)) |>\n    tidyr::pivot_wider(names_from = next_wave_status, values_from = freq, names_sort = TRUE) |>\n    tibble::column_to_rownames(\"Status\") |>\n    select(all_of(state_order)) |>\n    _[state_order, ] |>\n    as.matrix()\n}\n\nnormalise <- function(x) {\n  # Normalizes a matrix so that each row sums to 1.\n  # Arguments:\n  #   - x: The input matrix to normalize.\n  # Returns:\n  #   - A normalized matrix where each row sums to 1.\n  x / rowSums(x)\n}\n\ntran_stack_graph <- function(data) {\n  # Creates stacked bar charts visualizing cognitive state transitions across time periods.\n  # Shows composition of current states by previous state, faceted by observation period.\n  # Arguments:\n  #   - data: Transition dataset from create_transition_dataset()\n  # Returns:\n  #   - ggplot object showing stacked transition proportions\n  # \n  data |>\n    ggplot(aes(x = t_minus_1, y = Freq, fill = t)) +\n    geom_col(position = \"stack\", colour = \"black\") +\n    facet_wrap(~ Period, ncol = 3) +\n    labs(\n      x = \"Previous State (t-1)\", \n      y = \"Count\",\n      title = \"Outcomes by Prior Cognitive State\",\n      fill = \"Current State (t)\"\n    ) +\n    ggokabeito::scale_fill_okabe_ito() +\n    ggeasy::easy_move_legend(\"bottom\")\n}\n\ntran_heat_map <- function(data) {\n  # Generates heatmap visualization of transition frequencies between cognitive states.\n  # Uses color intensity and labeled values to show transition patterns across time periods.\n  # Arguments:\n  #   - data: Transition dataset from create_transition_dataset()\n  # Returns:\n  #   - ggplot heatmap with state transitions as cells\n  # \n  data |>\n    ggplot(aes(x = t_minus_1, y = t, fill = Freq)) +\n    geom_tile(color = \"white\") +\n    geom_text(aes(label = Freq), color = \"black\", size = 3.5) +  # Add counts\n    scale_fill_gradient(low = \"white\", high = \"steelblue\") +\n    facet_wrap(~ Period, ncol = 3) +  # Split by time period\n    labs(\n      x = \"Previous State (t-1)\", \n      y = \"Current State (t)\",\n      title = \"Cognitive State Transitions Between Time Periods\",\n      fill = \"Frequency\"\n    ) +\n    theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n    ggeasy::easy_move_legend(\"bottom\")\n}\n\ntidy_predictions <- function(predictions) {\n  # Restructures model prediction matrices into tidy format for visualization.\n  # Converts numeric codes to factor labels and reshapes multiple prediction columns\n  # into key-value pairs suitable for ggplot.\n  # Arguments:\n  #   - predictions: Raw prediction matrix from model output\n  # Returns:\n  #   - Long-format dataset with probabilities for each cognitive state\n  #   \n  predictions |>\n    as.matrix() |>\n    as_tibble() |>\n    mutate(\n      Gender = factor(ifelse(Gender == 0, \"Male\", \"Female\"), levels = c(\"Male\", \"Female\")),\n      status_prev = case_when(\n        status_prev == 1 ~ \"Normal Cognition\",\n        status_prev == 2 ~ \"MCI\",\n        status_prev == 3 ~ \"Dementia\",\n      ),\n      status_prev = factor(status_prev, levels = c(\"Normal Cognition\", \"MCI\", \"Dementia\")),\n      Total_p = as.numeric(Total_p),\n      across(c(pred.1:pred.3), as.numeric)) |>\n    tidyr::pivot_longer(cols = c(pred.1:pred.3), names_to = \"status\", values_to = \"prob\") |>\n    mutate(status = case_when(\n      status == \"pred.1\" ~ \"Normal Cognition\",\n      status == \"pred.2\" ~ \"MCI\",\n      status == \"pred.3\" ~ \"Dementia\"\n    ),\n    status = factor(status, levels = c(\"Normal Cognition\", \"MCI\", \"Dementia\")),\n    status_prev = factor(status_prev, levels = c(\"Normal Cognition\", \"MCI\", \"Dementia\")))\n}\n\nplot_predictions_stationary <- function(predictions) {\n  # Visualizes predicted transition probabilities from stationary multi-state models.\n  # Shows probability curves by procrastination level, stratified by baseline state.\n  # Arguments:\n  #   - predictions: Tidy predictions from tidy_predictions()\n  # Returns:\n  #   - Faceted ggplot showing predicted probability curves\n  # \n  predictions |>\n    ggplot(aes(x = Total_p, y = prob, colour = status_prev)) +\n    geom_line(linewidth = 1) +\n    ggokabeito::scale_colour_okabe_ito() +\n    labs(\n      title = \"Predicted transition probabilities (stationary model)\",\n      # subtitle = \"According to previous cognitive state\",\n      x = \"Total Procrastination\", y = \"Probability\", colour = \"Previous State\") +\n    facet_wrap(~ status, labeller = labeller(\n      status = function(x){paste0(\"Transition to: \", x)}\n    ))\n}\n\nget_time_varying_matrix <- function(model, time_point) {\n  expand.grid(\n    Gender = factor(0),\n    Total_p = mean(data_stack$Total_p),\n    status_prev = factor(1:3),\n    wave = time_point) |> \n    modelr::add_predictions(model, var = \"prob\", type = \"probs\") |> \n    select(status_prev, starts_with(\"prob\")) |> \n    mutate(\n      status_prev = factor(status_prev, labels = state_names),\n      across(starts_with(\"prob\"), ~round(., 3))) |>\n    tibble::column_to_rownames(\"status_prev\") |>\n    as.matrix() |> `colnames<-`(state_names)\n}\n```\n:::\n\n\n\n\n## Setting theme {.unnumbered}\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Check out my theme\"}\ncolour <- \"#212427\"\n\ntheme_set(\n  theme_minimal() +\n    theme(\n      plot.title = element_text(hjust = 0.5, size = 14, colour = colour, face = \"bold\"),\n      plot.subtitle = element_text(hjust = 0.5, size = 12, colour = colour),\n      axis.title = element_text(size = 10, colour = colour, face = \"bold\"),\n      strip.text = element_text(size = 10, colour = colour, face = \"bold\"),\n      legend.title = element_text(hjust = 0.5, colour = colour, face = \"bold\"),\n      ))\n```\n:::\n\n\n\n\n\n## Reading in data {.unnumbered}\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata <- read.csv(here::here(\"analysis/data/data.csv\"))\n```\n:::\n\n\n\n\n# Data Preparation\n\nBefore preparing the data, we want to create a vector of covariates that we are interested in using in our analysis\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncols <- c(\"ID\", \"Gender\", \"Age\", \"Education_tri\", \"Cardio_risk_16\", \"Total_dep_2016\", \"Total_p\")\n```\n:::\n\n\n\n\nFollowing this, we can now use the `extract_years()` function to extract the cognitive function data for the years 2016, 2018, and 2020. \n\n- We will also impute some missing values `impute = TRUE` using logical reasoning (if a respondent has an NA value in 2018, but has a classification of \"normal cognition\" in 2020, then the missing 2018 value becomes \"normal cognition\").\n- We will also treat dementia as an absorbing state `absorbing = TRUE`.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata_stack <- data |> extract_years(years = seq(2016, 2022, by = 2), impute = TRUE, absorbing = TRUE) |> na.omit()\n\nhead(data_stack)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 5\n     ID cogfunction2016  cogfunction2018  cogfunction2020  cogfunction2022 \n  <int> <chr>            <chr>            <chr>            <chr>           \n1     1 Normal Cognition Normal Cognition Normal Cognition Normal Cognition\n2     2 Normal Cognition Normal Cognition Normal Cognition Normal Cognition\n3     3 Dementia         Dementia         Dementia         Dementia        \n4     4 Normal Cognition Normal Cognition Normal Cognition Normal Cognition\n5     5 MCI              Normal Cognition Normal Cognition Normal Cognition\n6     6 Normal Cognition Normal Cognition Normal Cognition Normal Cognition\n```\n\n\n:::\n:::\n\n\n\n\n## Creating a stacked dataset\n\nFor each respondent we will now add in their relevant covariate data. Following this, we transform the data to long format and convert categorical variables to factors using the `pivot_and_factorise()` function. Additionally, we will fix the `Age` column to properly represent the age of the respondent at each time point\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata_stack <- data_stack |>\n  inner_join(data[, cols], by = \"ID\") |>\n  pivot_and_factorise() |>\n  group_by(ID) |>\n  mutate(Age = Age - (2022 - as.numeric(as.character(wave))))\n\nhead(data_stack)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 9\n# Groups:   ID [2]\n     ID wave  status Gender   Age Education_tri Cardio_risk_16 Total_dep_2016\n  <int> <fct> <fct>  <fct>  <dbl> <fct>                  <int>          <int>\n1     1 2016  1      1         72 2                          0              0\n2     1 2018  1      1         74 2                          0              0\n3     1 2020  1      1         76 2                          0              0\n4     1 2022  1      1         78 2                          0              0\n5     2 2016  1      1         75 2                          1              2\n6     2 2018  1      1         77 2                          1              2\n# ℹ 1 more variable: Total_p <int>\n```\n\n\n:::\n:::\n\n\n\n\nFinally, we will create a new variable `status_prev` that notes the cognitive status of the respondent in the previous wave $(t - 1)$. This will be done by using the `lag` function from the `dplyr` package.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata_stack <- data_stack |>\n  mutate(status_prev = lag(status), .after = status) |>\n  ungroup() |> \n  filter(wave != 2016, !is.na(Total_p))\n\nhead(data_stack)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 10\n     ID wave  status status_prev Gender   Age Education_tri Cardio_risk_16\n  <int> <fct> <fct>  <fct>       <fct>  <dbl> <fct>                  <int>\n1     1 2018  1      1           1         74 2                          0\n2     1 2020  1      1           1         76 2                          0\n3     1 2022  1      1           1         78 2                          0\n4     2 2018  1      1           1         77 2                          1\n5     2 2020  1      1           1         79 2                          1\n6     2 2022  1      1           1         81 2                          1\n# ℹ 2 more variables: Total_dep_2016 <int>, Total_p <int>\n```\n\n\n:::\n:::\n\n\n\n\n# Transition frequencies\n\nWe will now calculate the transition frequencies between cognitive states for each time period. We will use the `create_transition_table()` function to create a transition table for each time period. This will be done with the help of the `map()` function from the `purrr` package. Finally, to combine all the transition tables into one dataset, we will use the `create_transition_dataset()` function.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Creating a table dataset\ntable_data <- data |>\n  extract_years(seq(2016, 2022, by = 2)) |>\n  rename_with(~ gsub(\"cogfunction\", \"HRS_\", .)) |>\n  mutate(\n    across(c(HRS_2016:HRS_2022), ~ factor(.x, levels = c(\"Normal Cognition\", \"MCI\", \"Dementia\")))\n  )\n\n# Creating transition frequencies ---------------------------------------------\n## These are the time periods we are interested in\ntime_periods <- list(\n  c(\"2016\", \"2018\"),\n  c(\"2018\", \"2020\"), \n  c(\"2020\", \"2022\")\n)\n\n# Applying function\ntransition_results <- purrr::map(time_periods, ~ create_transition_table(.x[1], .x[2]))\nnames(transition_results) <- purrr::map_chr(time_periods, ~ paste(.x[2], .x[1], sep = \"-\"))\n\n### Creating one dataset\ntransition_frequencies <- time_periods |>\n  create_transition_dataset(transition_results = transition_results)\n\nhead(transition_frequencies)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       Period        t_minus_1                t Freq\n1 2016 - 2018 Normal Cognition Normal Cognition  713\n2 2016 - 2018              MCI Normal Cognition   76\n3 2016 - 2018         Dementia Normal Cognition    0\n4 2016 - 2018 Normal Cognition              MCI   58\n5 2016 - 2018              MCI              MCI   49\n6 2016 - 2018         Dementia              MCI    0\n```\n\n\n:::\n:::\n\n\n\n\n## Observed transition matrix\n\nThe probability distribution of transitions from one state to another can be represented into a transition matrix $P = (p_{ij})_{i,j}$ where each element of position $(i, j)$ represents the transition probability $p_{ij}$. \n\nIn order to create this matrix we will use both the `create_transitions()` and `observed_transition_matrix()` functions.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Creating observed transition matrix -----------------------------------------\ntransition_matrix_observed <- data |>\n  extract_years(seq(2016, 2022, by = 2)) |>\n  create_transitions() |>\n  observed_transition_matrix()\n\ntransition_matrix_observed\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                 Normal Cognition   MCI Dementia\nNormal Cognition            0.895 0.096    0.009\nMCI                         0.530 0.376    0.094\nDementia                    0.000 0.000    1.000\n```\n\n\n:::\n:::\n\n\n\n\n## Visualisation\n\nLet's visualize both the transition frequencies (@fig-frequencies) and matrix (@fig-matrix).\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Check out my code\"}\nfig_1 <- transition_frequencies |> tran_stack_graph()\nfig_2 <- transition_frequencies |> tran_heat_map()\n\nfig_1 / fig_2\n```\n\n::: {.cell-output-display}\n![Transition frequencies between cognitive states for each time period.](discrete-markov_files/figure-html/fig-frequencies-1.png){#fig-frequencies width=1152}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Check out my code\"}\ntran_df <- transition_matrix_observed |>\n  as.data.frame() |>\n  mutate(\n    from_state = factor(c(\"Normal cognition\", \"MCI\", \"Dementia\"),\n                        levels = c(\"Normal cognition\", \"MCI\", \"Dementia\"))\n    ) |>\n  reshape2::melt(\n    id.vars = \"from_state\", variable.name = \"to_state\", value.name = \"probability\") |>\n  mutate(\n    to_state = factor(to_state, levels = rev(levels(to_state)))\n    )\n\nfig_2 <- tran_df |>\n  ggplot(aes(x = from_state, y = to_state, fill = probability)) +\n  geom_tile(color = \"white\", linewidth = 0.5) +\n  geom_text(\n    aes(label = format(round(probability, 3), nsmall = 3)),\n    size = 4.5, \n    color = \"#212427\",\n    fontface = \"bold\") +\n  colorspace::scale_fill_continuous_diverging(\n    palette = \"Blue-Red 3\", mid = 0.50, alpha = 0.5, \n    limits = c(0, 1), name = \"Transition \\nProbability\") +\n  labs(title = \"Transition Probabilities Across Cognitive States\",\n       subtitle = \"Observed state transitions between assessment waves\",\n       x = \"Previous State (t - 1)\", \n       y = \"Current State (t)\") +\n  theme(\n    axis.text = element_text(size = 10),\n    axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1),\n    legend.position = \"right\",\n    legend.text = element_text(size = 9),\n    panel.grid = element_blank()\n  )\n\nfig_2\n```\n\n::: {.cell-output-display}\n![Observed transition matrix between cognitive states for the years 2016 - 2022.](discrete-markov_files/figure-html/fig-matrix-1.png){#fig-matrix width=1152}\n:::\n:::\n\n\n\n\n# Modelling\n\n## Markov Process Fundamentals\n\nDiscrete-time Markov models belong to a class of stochastic processes that satisfy the **Markov property**, which can be formally expressed as:\n\n$$\nP(X_{t+1} = j \\vert X_t = i, X_{t-1} = i_{t-1}, \\dots X_0 = i_0) = P(X_{t+1} = j \\vert X_t = i)\n$$ {#eq-markov}\n\nThis property establishes that the future state $X_{t+1}$ depends only on the current state $X_t$, not on the entire history of states.\n\n### Transition Probability Matrix\n\nFor our three-state system (Normal Cognition, Mild Cognitive Impairment [MCI], Dementia), the transition matrix $P$ captures all possible transition probabilities:\n\n$$\nP = \\begin{bmatrix} \np_{11} & p_{12} & p_{13} \\\\\np_{21} & p_{22} & p_{23} \\\\\np_{31} & p_{32} & p_{33} \\\\\n\\end{bmatrix}\n$$ {#eq-t-matrix}\n\nwhere:\n\n- $p_{ij} = P(X_{t+1} = j \\vert X_t = i)$ represents the probability of transitioning from state $i$ to state $j$.\n- Each row sums to 1, $\\sum^3_{j=1} p_{ij} = 1 \\quad  \\forall_i \\in \\{1, 2, 3\\}$\n\n### Multinomial Logistic Regression Formulation\n\nWe model the transition probabilities using **multinomial logistic regression**, where the log-odds of each transition relative to a reference state are linear functions of covariates.\n\nFor a system with $K$ states (using state $K$ as reference), we have:\n\n$$\nlog \\left( \\frac{P(Y = j \\vert x)}{P(Y = k \\vert x)} \\right) = \\beta_{j0} + \\beta_j^Tx \\qquad \\text{for } j = 1, \\dots K-1\n$$ {#eq-multinomial}\n\nFor non-reference states $j = 1, \\dots, K - 1$\n\n$$\nP(Y = j \\vert x) = \\frac{e^{\\beta_{0j} + \\beta_j^Tx}}{1 + \\sum^{k - 1}_{k = 1} e^{\\beta_{0k} + \\beta_k^Tx}}\n$$ {#eq-non-reference}\n\nFor the reference state $K$:\n\n$$\nP(Y = k \\vert x) = \\frac{1}{1 + \\sum^{k - 1}_{k = 1} e^{\\beta_{0k} + \\beta_j^Tx }}\n$$ {#eq-reference}\n\n### Time-Homogeneous Approach\n\nOur implementation assumes time-homogeneous transitions, but the framework can be extended to time-varying probabilities:\n\n$$\nP^{(t)} = \\begin{bmatrix} \np_{11}^{(t)} & p_{12}^{(t)} & \\cdots & p_{1n}^{(t)} \\\\\np_{21}^{(t)} & p_{22}^{(t)} & \\cdots & p_{2n}^{(t)} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\np_{n1}^{(t)} & \\cdots & \\cdots & p_{nn}^{(t)} \\\\\n\\end{bmatrix}\n$$ {#eq-non-stationary}\n\nOur primary analysis assumes the transition matrix remains fixed:\n\n$$\nP^{(t)} \\equiv P \\qquad \\forall \\; t\n$$ {#eq-assumption}\n\n### Absorbing State Specification\n\nWe model Dementia as an absorbing state:\n\n$$\np_{3j} = \\begin{cases} \n1 \\qquad \\text{if } j = 3 \\\\\n0 \\qquad \\text{otherwise} \\end{cases}\n$$ {#eq-dementia}\n\nyielding the constrained transition matrix:\n\n$$\nP = \\begin{bmatrix} \np_{11} & p_{12} & p_{13} \\\\\np_{21} & p_{22} & p_{23} \\\\\n0      & 0      & 1      \\\\\n\\end{bmatrix}\n$$ {#eq-t-matrix-constrained}\n\n## Stationary model\n\nWe estimate three progressively complex stationary models using `nnet::multinom()`\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Check out my models\"}\n# Baseline model (only gender)\nfit_1 <- nnet::multinom(\n  status ~ Gender, family = multinomial, \n  data = data_stack, trace = FALSE)\n\n# With procrastination\nfit_2 <- nnet::multinom(\n  status ~ Gender + Total_p, family = multinomial, \n  data = data_stack, trace = FALSE)\n\n# Full model with previous state\nfit_3 <- nnet::multinom(\n  status ~ Gender + Total_p + status_prev, family = multinomial, \n  data = data_stack, trace = FALSE)\n```\n:::\n\n\n\n\n### Model comparison\n\nWe evaluate model improvement using likelihood ratio tests:\n\n$$\nD = -2 \\times \\ell_{\\text{reduced}} - \\ell_{\\text{full}}\n$$ {#eq-liklihood}\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nanova(fit_1, fit_2, fit_3) |>\n  knitr::kable(caption = \"Nested Model Comparison\") |>\n  kableExtra::kable_styling(\n    bootstrap_options = c(\"striped\", \"hover\"),\n    full_width = FALSE)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n<caption>Nested Model Comparison</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Model </th>\n   <th style=\"text-align:right;\"> Resid. df </th>\n   <th style=\"text-align:right;\"> Resid. Dev </th>\n   <th style=\"text-align:left;\"> Test </th>\n   <th style=\"text-align:right;\"> Df </th>\n   <th style=\"text-align:right;\"> LR stat. </th>\n   <th style=\"text-align:right;\"> Pr(Chi) </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> Gender </td>\n   <td style=\"text-align:right;\"> 5510 </td>\n   <td style=\"text-align:right;\"> 3128.438 </td>\n   <td style=\"text-align:left;\">  </td>\n   <td style=\"text-align:right;\"> NA </td>\n   <td style=\"text-align:right;\"> NA </td>\n   <td style=\"text-align:right;\"> NA </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Gender + Total_p </td>\n   <td style=\"text-align:right;\"> 5508 </td>\n   <td style=\"text-align:right;\"> 3054.412 </td>\n   <td style=\"text-align:left;\"> 1 vs 2 </td>\n   <td style=\"text-align:right;\"> 2 </td>\n   <td style=\"text-align:right;\"> 74.02595 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Gender + Total_p + status_prev </td>\n   <td style=\"text-align:right;\"> 5504 </td>\n   <td style=\"text-align:right;\"> 2317.020 </td>\n   <td style=\"text-align:left;\"> 2 vs 3 </td>\n   <td style=\"text-align:right;\"> 4 </td>\n   <td style=\"text-align:right;\"> 737.39218 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\n\n### Estimated parameters\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Check out my code\"}\nbroom::tidy(fit_3) |>\n  filter(term != \"(Intercept)\") |>\n  mutate(\n    y.level = case_when(\n      y.level == \"2\" ~ \"NC - MCI\",\n      y.level == \"3\" ~ \"NC - Dementia\"),\n    term = case_when(\n      term == \"Gender1\" ~ \"Being female\",\n      term == \"Total_p\" ~ \"Procrastination\",\n      term == \"status_prev2\" ~ \"Previous state: MCI\",\n      term == \"status_prev3\" ~ \"Previous state: Dementia\",\n      TRUE ~ term)\n    ) |>\n  mutate(across(c(estimate:p.value), ~ round(x = ., digits = 3)))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 8 × 6\n  y.level       term                     estimate std.error   statistic p.value\n  <chr>         <chr>                       <dbl>     <dbl>       <dbl>   <dbl>\n1 NC - MCI      Being female                0.009     0.125       0.069   0.945\n2 NC - MCI      Procrastination             0.023     0.005       4.59    0    \n3 NC - MCI      Previous state: MCI         1.77      0.136      13.0     0    \n4 NC - MCI      Previous state: Dementia    3.84      0     1122535.      0    \n5 NC - Dementia Being female               -0.132     0.294      -0.45    0.653\n6 NC - Dementia Procrastination             0.018     0.012       1.56    0.12 \n7 NC - Dementia Previous state: MCI         2.82      0.299       9.43    0    \n8 NC - Dementia Previous state: Dementia   19.3       0     4639056.      0    \n```\n\n\n:::\n:::\n\n\n\n\n### Model visualisation\n\nLet's visualize the predicted transition probabilities from the stationary models. We will show probability curves by procrastination level\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Check out my code\"}\n## Making a prediction dataset -------------------------------------------------\npred_data <- expand.grid(\n  Gender = factor(0),\n  status_prev = levels(data_stack$status_prev),\n  Total_p = seq(0, 60, length = 200))\n\n## Plotting predictions\nfig_3 <- pred_data |>\n  modelr::add_predictions(model = fit_3, var = \"pred\", type = \"probs\") |>\n  tidy_predictions() |>\n  plot_predictions_stationary()\n\nfig_3\n```\n\n::: {.cell-output-display}\n![Predicted transition probabilities from the stationary model.](discrete-markov_files/figure-html/fig-model-predictions-1.png){#fig-model-predictions width=1152}\n:::\n:::\n\n\n\n\n### Estimated transition matrix\n\nFinally, we can compare the observed and predicted transition matrices. We will use the estimated probabilities from the model to fill in the transition matrix.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Get all unique states\nnames <- c(\"Normal Cognition\", \"MCI\", \"Dementia\")\nstates <- sort(unique(data_stack$status))\nn_states <- length(states)\n\n# Create empty transition matrix\ntransition_matrix_estimated <- matrix(\n  0, nrow = n_states, ncol = n_states,\n  dimnames = list(paste(\"From\", names), paste(\"To\", names))\n  )\n\n# Getting estimated probabilities\nestimated_probs <- expand.grid(\n  Gender = factor(0),\n  Total_p = mean(data_stack$Total_p),\n  status_prev = states) |>\n  modelr::add_predictions(model = fit_3, var = \"pred\", type = \"probs\")\n\n# Filling in matrix\nfor(i in 1:n_states) {\n  transition_matrix_estimated[i, ] <- estimated_probs$pred[i, ]\n}\n\ntransition_matrix_estimated |> round(digits = 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                      To Normal Cognition To MCI To Dementia\nFrom Normal Cognition               0.896  0.095       0.009\nFrom MCI                            0.556  0.347       0.097\nFrom Dementia                       0.000  0.000       1.000\n```\n\n\n:::\n:::\n\n\n\n\nLet's plot this and then compare with our observed matrix\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Check out my code\"}\ntran_df_estimate <- transition_matrix_estimated |>\n  as.data.frame() |>\n  mutate(from_state = factor(\n    c(\"Normal cognition\", \"MCI\", \"Dementia\"),\n    levels = c(\"Normal cognition\", \"MCI\", \"Dementia\")\n  )) |>\n  reshape2::melt(id.vars = \"from_state\",\n                 variable.name = \"to_state\",\n                 value.name = \"probability\") |>\n  mutate(to_state = factor(to_state, levels = rev(levels(to_state))))\n\nfig_4 <- tran_df_estimate |>\n  ggplot(aes(x = from_state, y = to_state, fill = probability)) +\n  geom_tile(color = \"white\", linewidth = 0.5) +\n  geom_text(\n    aes(label = format(round(probability, 3), nsmall = 3)),\n    size = 4.5, \n    color = \"#212427\",\n    fontface = \"bold\") +\n  colorspace::scale_fill_continuous_diverging(\n    palette = \"Blue-Red 3\", mid = 0.50, alpha = 0.5, \n    limits = c(0, 1), name = \"Transition \\nProbability\") +\n  labs(title = \"Transition Probabilities Across Cognitive States\",\n       subtitle = \"Estimated state transitions between assessment waves\",\n       x = \"Previous State (t - 1)\", \n       y = \"Current State (t)\") +\n  theme(\n    axis.text = element_text(size = 10),\n    axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1),\n    legend.position = \"right\",\n    legend.text = element_text(size = 9),\n    panel.grid = element_blank()\n  )\n\nfig_2 + fig_4 + plot_layout(axis_titles = \"collect\", guides = \"collect\")\n```\n\n::: {.cell-output-display}\n![Comparison of observed and estimated transition matrices.](discrete-markov_files/figure-html/fig-matrix-comparison-1.png){#fig-matrix-comparison width=1152}\n:::\n:::\n\n\n\n\n## Non-stationary model\n\nWe can also estimate a non-stationary model (@eq-non-stationary) by incorporating time `(wave)` into our model. This model allows for time-varying transition probabilities $p^{(t)}_{ij}$.\n\nWe estimate three progressively complex non-stationary models:\n\n- Additive time effects `(fit_4)`: Baseline covariates + wave\n- State-specific time effects `(fit_5)`: Interaction between previous state and wave\n- Full time interactions `(fit_6)`: All covariates interacting with wave\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Check out my models\"}\n## Small processing to fix wave column\ndata_stack <- data_stack |>\n  mutate(wave = case_when(\n    wave == \"2016\" ~ 1,\n    wave == \"2018\" ~ 2,\n    wave == \"2020\" ~ 3,\n    wave == \"2022\" ~ 4\n  ))\n\n# Model 4: Additive time effects\nfit_4 <- nnet::multinom(\n  status ~ Gender + Total_p + status_prev + wave, family = multinomial, \n  data = data_stack, trace = FALSE)\n\n# Model 5: State-specific time effects\nfit_5 <- nnet::multinom(\n  status ~ Gender + Total_p + (status_prev * wave), family = multinomial, \n  data = data_stack, trace = FALSE)\n\n# Model 6: Full time interactions\nfit_6 <- nnet::multinom(\n  status ~ (Gender + Total_p + status_prev) * wave, family = multinomial, \n  data = data_stack, trace = FALSE)\n```\n:::\n\n\n\n\n### Model comparison\n\nAgain, we will evaluate model improvement using likelihood ratio tests (@eq-liklihood). However, this time, we will also compare the best fitted non-stationary models `fit_3`.\n\n\n\n\n::: {.cell layout-nrow=\"2\"}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Check out my code\"}\n# Fit statistics\nmodels <- list(\n  \"Stationary\" = fit_3,\n  \"Additive Time\" = fit_4,\n  \"State-Time Interaction\" = fit_5,\n  \"Full Interactions\" = fit_6\n)\n\n# Create comparison table\ncomparison_table <- purrr::map_dfr(models, broom::glance, .id = \"Model\") |>\n  select(Model:AIC) |>\n  mutate(across(where(is.numeric), \\(x) round(x, digits = 1)))\n\n# Likelihood ratio tests\nlr_tests <- anova(fit_3, fit_4, fit_5, fit_6)\n\n# Outputting tables\nknitr::kable(lr_tests, caption = \"Likelihood Ratio Tests\") |>\n  kableExtra::kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover\" style=\"margin-left: auto; margin-right: auto;\">\n<caption>Likelihood Ratio Tests</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Model </th>\n   <th style=\"text-align:right;\"> Resid. df </th>\n   <th style=\"text-align:right;\"> Resid. Dev </th>\n   <th style=\"text-align:left;\"> Test </th>\n   <th style=\"text-align:right;\"> Df </th>\n   <th style=\"text-align:right;\"> LR stat. </th>\n   <th style=\"text-align:right;\"> Pr(Chi) </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> Gender + Total_p + status_prev </td>\n   <td style=\"text-align:right;\"> 5504 </td>\n   <td style=\"text-align:right;\"> 2317.020 </td>\n   <td style=\"text-align:left;\">  </td>\n   <td style=\"text-align:right;\"> NA </td>\n   <td style=\"text-align:right;\"> NA </td>\n   <td style=\"text-align:right;\"> NA </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Gender + Total_p + status_prev + wave </td>\n   <td style=\"text-align:right;\"> 5502 </td>\n   <td style=\"text-align:right;\"> 2300.938 </td>\n   <td style=\"text-align:left;\"> 1 vs 2 </td>\n   <td style=\"text-align:right;\"> 2 </td>\n   <td style=\"text-align:right;\"> 16.081480 </td>\n   <td style=\"text-align:right;\"> 0.0003221 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Gender + Total_p + (status_prev * wave) </td>\n   <td style=\"text-align:right;\"> 5498 </td>\n   <td style=\"text-align:right;\"> 2296.834 </td>\n   <td style=\"text-align:left;\"> 2 vs 3 </td>\n   <td style=\"text-align:right;\"> 4 </td>\n   <td style=\"text-align:right;\"> 4.103695 </td>\n   <td style=\"text-align:right;\"> 0.3921541 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> (Gender + Total_p + status_prev) * wave </td>\n   <td style=\"text-align:right;\"> 5494 </td>\n   <td style=\"text-align:right;\"> 2292.973 </td>\n   <td style=\"text-align:left;\"> 3 vs 4 </td>\n   <td style=\"text-align:right;\"> 4 </td>\n   <td style=\"text-align:right;\"> 3.861658 </td>\n   <td style=\"text-align:right;\"> 0.4250520 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Check out my code\"}\nknitr::kable(comparison_table, caption = \"Model Fit Statistics\") |>\n  kableExtra::kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover\" style=\"margin-left: auto; margin-right: auto;\">\n<caption>Model Fit Statistics</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Model </th>\n   <th style=\"text-align:right;\"> edf </th>\n   <th style=\"text-align:right;\"> deviance </th>\n   <th style=\"text-align:right;\"> AIC </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> Stationary </td>\n   <td style=\"text-align:right;\"> 10 </td>\n   <td style=\"text-align:right;\"> 2317.0 </td>\n   <td style=\"text-align:right;\"> 2337.0 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Additive Time </td>\n   <td style=\"text-align:right;\"> 12 </td>\n   <td style=\"text-align:right;\"> 2300.9 </td>\n   <td style=\"text-align:right;\"> 2324.9 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> State-Time Interaction </td>\n   <td style=\"text-align:right;\"> 16 </td>\n   <td style=\"text-align:right;\"> 2296.8 </td>\n   <td style=\"text-align:right;\"> 2328.8 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Full Interactions </td>\n   <td style=\"text-align:right;\"> 20 </td>\n   <td style=\"text-align:right;\"> 2293.0 </td>\n   <td style=\"text-align:right;\"> 2333.0 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\n\n**Looks like adding in time as an additive term improved things**\n\n### Estimated parameters\n\nKey coefficients from the selected non-stationary model `fit_4`\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Check out my code\"}\nbroom::tidy(fit_4) |>\n  filter(term != \"(Intercept)\") |>\n  mutate(\n    y.level = case_when(\n      y.level == \"2\" ~ \"NC - MCI\",\n      y.level == \"3\" ~ \"NC - Dementia\"),\n    term = case_when(\n      term == \"Gender1\" ~ \"Being female\",\n      term == \"Total_p\" ~ \"Procrastination\",\n      term == \"status_prev2\" ~ \"Previous state: MCI\",\n      term == \"status_prev3\" ~ \"Previous state: Dementia\",\n      term == \"wave\" ~ \"Time\",\n      TRUE ~ term)\n    ) |>\n  mutate(across(c(estimate:p.value), ~ round(x = ., digits = 3)))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 10 × 6\n   y.level       term                     estimate std.error statistic p.value\n   <chr>         <chr>                       <dbl>     <dbl>     <dbl>   <dbl>\n 1 NC - MCI      Being female                0.013     0.126   1.03e-1   0.918\n 2 NC - MCI      Procrastination             0.023     0.005   4.61e+0   0    \n 3 NC - MCI      Previous state: MCI         1.81      0.138   1.31e+1   0    \n 4 NC - MCI      Previous state: Dementia   -1.87      0      -4.21e+8   0    \n 5 NC - MCI      Time                        0.265     0.074   3.56e+0   0    \n 6 NC - Dementia Being female               -0.109     0.296  -3.68e-1   0.713\n 7 NC - Dementia Procrastination             0.019     0.012   1.58e+0   0.115\n 8 NC - Dementia Previous state: MCI         2.87      0.301   9.55e+0   0    \n 9 NC - Dementia Previous state: Dementia   20.3       0       4.48e+7   0    \n10 NC - Dementia Time                        0.395     0.178   2.22e+0   0.027\n```\n\n\n:::\n:::\n\n\n\n\n### Model visualisation\n\nLet's visualize the predicted transition probabilities from the non-stationary model @fig-non-stationary. We will show probability curves by procrastination level \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Check our my code\"}\nexpand.grid(\n  Gender = factor(0),\n  status_prev = levels(data_stack$status_prev),\n  Total_p = seq(0, 60, length = 200),\n  wave = unique(data_stack$wave)) |>\n  modelr::add_predictions(model = fit_4, var = \"pred\", type = \"probs\") |>\n  tidy_predictions() |>\n  mutate(wave = factor(wave)) |>\n  ggplot(aes(x = Total_p, y = prob, color = status_prev)) +\n  geom_line(linewidth = 1) +\n  ggokabeito::scale_color_okabe_ito() +\n  labs(\n    title = \"Time-Varying Transition Probabilities\",\n    x = \"Total Procrastination\", \n    y = \"Predicted Probability\", color = \"Previous State\") +\n  facet_grid(wave ~ status, labeller = labeller(\n    wave = function(x) paste(\"Years since baseline:\", x),\n    status = function(x) paste(\"Transition to:\", x)\n  )) +\n  theme(panel.spacing = unit(1, \"lines\"))\n```\n\n::: {.cell-output-display}\n![Predicted transition probabilities from the non-stationary model.](discrete-markov_files/figure-html/fig-non-stationary-1.png){#fig-non-stationary width=1152}\n:::\n:::\n\n\n\n\n### Estimated transition matrices\n\nLet's visualize the estimated time-varying transition matrices @fig-non-stationary-matrix-plot\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Check out my code\"}\n# Create prediction grid for each time point\ntime_points <- unique(data_stack$wave)\nstate_names <- c(\"Normal Cognition\", \"MCI\", \"Dementia\")\n\n# Get matrices for all time points\ntime_varying_matrices <- purrr::map(\n  setNames(time_points, paste(time_points, \"Years\")),\n  ~ get_time_varying_matrix(fit_4, .x)\n)\n\n# Converting into a tidy data frame\nnon_stationary_matrices <- purrr::imap_dfr(\n  time_varying_matrices,\n  ~ as.data.frame(.x) |> \n    tibble::rownames_to_column(\"From\") |> \n    pivot_longer(-From, names_to = \"To\", values_to = \"probability\") |> \n    mutate(Time = .y),\n  .id = \"Time_point\"\n) |> \n  mutate(\n    From = factor(From, levels = state_names),\n    To = factor(To, levels = rev(state_names)),\n    Time_point = forcats::fct_inorder(Time_point)\n  )\n\n# Plotting \nnon_stationary_matrices |>\nggplot(aes(x = From, y = To, fill = probability)) +\n  geom_tile(color = \"white\", linewidth = 0.5) +\n  geom_text(\n    aes(label = format(round(probability, 3), nsmall = 3)),\n    size = 4.5, \n    color = \"#212427\",\n    fontface = \"bold\") +\n    colorspace::scale_fill_continuous_diverging(\n    palette = \"Blue-Red 3\", mid = 0.50, alpha = 0.5, \n    limits = c(0, 1), name = \"Transition \\nProbability\") +\n  labs(\n    title = \"Estimated Time-Varying Transition Matrices\",\n    subtitle = \"Showing changes in transition probabilities over time\",\n    x = \"Previous State (t-1)\",\n    y = \"Next State (t)\",\n    fill = \"Probability\"\n  ) +\n  facet_wrap(~ Time_point, ncol = 3, labeller = labeller(\n    Time_point = function(x){\n      case_when(x == \"2 Years\" ~ \"2018\",\n                x == \"3 Years\" ~ \"2020\",\n                x == \"4 Years\" ~ \"2022\")\n    })) +\n  theme(\n    axis.text = element_text(size = 10),\n    axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1),\n    legend.position = \"right\",\n    legend.text = element_text(size = 9),\n    panel.grid = element_blank()\n  )\n```\n\n::: {.cell-output-display}\n![Estimated time-varying transition matrices.](discrete-markov_files/figure-html/fig-non-stationary-matrix-plot-1.png){#fig-non-stationary-matrix-plot width=1152}\n:::\n:::\n\n\n\n\n# Matrix distance metrics\n\nGiven two matrices $P = (p_{ij})$ and $\\hat{P} = (\\hat{p}_{ij})$ of size $m \\times n$, we define the following distance measures\n\n**Frobenius Norm (Matrix Euclidean Distance)**\n\n$$D_{\\text{Frobenius}}(P, \\hat{P}) = \\|P - \\hat{P}\\|_F = \\sqrt{\\sum_{i=1}^{m}\\sum_{j=1}^{n} |p_{ij} - \\hat{p}_{ij}|^2}$$\n \n- Measures the Euclidean distance in matrix space\n- Sensitive to large differences due to squaring\n- Equivalent to the vector 2-norm of the flattened matrix\n\n**Manhattan Distance (L1 Norm)**\n\n$$D_{\\text{Manhattan}}(P, \\hat{P}) = \\sum_{i=1}^{m}\\sum_{j=1}^{n} |p_{ij} - \\hat{p}_{ij}|$$\n\n- Sum of absolute differences between corresponding elements\n- Less sensitive to outliers than Frobenius norm\n- Useful when sparse differences are important\n\n**Maximum Difference (Infinity Norm)**\n\n$$D_{\\text{Max}}(A, B) = \\max_{\\substack{1 \\leq i \\leq m \\\\ 1 \\leq j \\leq n}} |a_{ij} - b_{ij}|$$\n\n- Captures the single largest difference between elements\n- Useful for worst-case analysis\n- Ignores the distribution of other differences\n\n**Mean Absolute Difference**\n\n$$D_{\\text{MeanAbs}}(P, \\hat{P}) = \\frac{1}{mn}\\sum_{i=1}^{m}\\sum_{j=1}^{n} |p_{ij} - \\hat{p}_{ij}|$$\n\n- Average absolute difference across all elements\n- Scales with matrix size (unlike Manhattan distance)\n- Easy to interpret as average error per element\n\n**Root Mean Square Error (RMSE)**\n\n$$D_{\\text{RMSE}}(P, \\hat{P}) = \\sqrt{\\frac{1}{mn}\\sum_{i=1}^{m}\\sum_{j=1}^{n} (p_{ij} - \\hat{p}_{ij})^2}$$\n\n- Similar to Frobenius but normalized by matrix size\n-  Sensitive to large errors due to squaring\n- Common in statistical and machine learning applications\n\n**Correlation-Based Distance**\n\n$$D_{\\text{Corr}}(P, \\hat{P}) = 1 - \\frac{\\sum_{i=1}^{m}\\sum_{j=1}^{n} (p_{ij} - \\bar{P})(\\hat{p}_{ij} - \\bar{\\hat{P}})}{\\sqrt{\\sum_{i=1}^{m}\\sum_{j=1}^{n} (p_{ij} - \\bar{P})^2 \\sum_{i=1}^{m}\\sum_{j=1}^{n} (\\hat{p}_{ij} - \\bar{\\hat{p}})^2}}$$\n\n- Measures linear relationship between matrix elements\n- $\\bar{P} = \\frac{1}{mn}\\sum_{i,j}p_{ij}$ (mean of all elements in $P$)\n- $\\bar{\\hat{P}} = \\frac{1}{mn}\\sum_{i,j}\\hat{p}_{ij}$ (mean of all elements in $\\hat{P}$)\n- Range: [0,2] where 0 = perfect positive correlation\n\n**Kullback-Leibler Divergence**\n\nFor matrices where each row sums to 1 ($\\sum_j p_{ij} = \\sum_j \\hat{P}_{ij} = 1$) and $p_{ij}, \\hat{p}_{ij} > 0$:\n\n$$\nD_{\\text{KL}}(P \\parallel \\hat{P}) = \\sum_{i=1}^{m}\\sum_{j=1}^{n} p_{ij} \\log\\left(\\frac{p_{ij}}{\\hat{p}_{ij}}\\right)\n$$\n\n- Measures information loss when $\\hat{P}$ approximates $P$\n- Asymmetric: $D_{\\text{KL}}(P \\parallel \\hat{P}) \\neq D_{\\text{KL}}(\\hat{P} \\parallel P)$\n- $0\\log0 = 0$ by convention\n- In practice, add $\\epsilon > 0$ (e.g., $10^{-10}$) to avoid zeros\n\n## Implementation\n\nLet's calculate the distance metrics between the observed $P$ and estimated transition matrices $\\hat{P}$.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\np       <- transition_matrix_observed\np_hat   <- transition_matrix_estimated\nepsilon <- 1e-10\n\n# Creating tibble of distance metrics\ndistances <- tibble(\n  Metric = c(\"Frobenius\", \"Manhattan\", \"Max\", \"MeanAbs\", \"RMSE\", \"Correlation\", \"KL\"),\n  Value = c(\n    norm(p - p_hat, type = \"F\"),\n    sum(abs(p - p_hat)),\n    max(abs(p - p_hat)),\n    mean(abs(p - p_hat)),\n    sqrt(mean((p - p_hat)^2)),\n    1 - cor(c(p), c(p_hat)),\n    sum((p + epsilon) * log((p + epsilon) / (p_hat + epsilon)))\n  )) |>\n  mutate(Value = round(Value, 4))\n\ndistances |>\n  mutate(Metric = case_when(\n    Metric == \"Frobenius\" ~ \"Frobenius Distance\",\n    Metric == \"Manhattan\" ~ \"Manhattan Distance\",\n    Metric == \"Max\" ~ \"Max Difference\",\n    Metric == \"MeanAbs\" ~ \"Mean Absolute Difference\",\n    Metric == \"RMSE\" ~ \"Root Mean Square Error\",\n    Metric == \"Correlation\" ~ \"Correlation Distance\",\n    Metric == \"KL\" ~ \"Kullback-Leibler Divergence\"\n  )) |>\n  knitr::kable(caption = \"Distance based metrics\", align = \"c\") |>\n  kableExtra::kable_styling(\n    bootstrap_options = c(\"striped\", \"hover\"),\n    full_width = FALSE)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n<caption>Distance based metrics</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:center;\"> Metric </th>\n   <th style=\"text-align:center;\"> Value </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:center;\"> Frobenius Distance </td>\n   <td style=\"text-align:center;\"> 0.0396 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> Manhattan Distance </td>\n   <td style=\"text-align:center;\"> 0.0608 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> Max Difference </td>\n   <td style=\"text-align:center;\"> 0.0292 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> Mean Absolute Difference </td>\n   <td style=\"text-align:center;\"> 0.0068 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> Root Mean Square Error </td>\n   <td style=\"text-align:center;\"> 0.0132 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> Correlation Distance </td>\n   <td style=\"text-align:center;\"> 0.0006 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> Kullback-Leibler Divergence </td>\n   <td style=\"text-align:center;\"> 0.0019 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\n\n## Visualisation\n\nLet's visualize the distance metrics between the observed and estimated transition matrices (@fig-metrics).\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Check out my code\"}\ncaption = stringr::str_glue(\n  \"**RMSE:** Root Mean Squared Error\\n\n   **KL:** Kullback-Leibler Divergence\\n\n   **Correlation:** 1 - Pearson Correlation Coefficient\")\n\ndistances |>\n  ggplot(aes(x = reorder(Metric, -Value), y = Value, fill = Metric)) +\n  geom_col(colour = \"black\") +\n  geom_text(aes(label = Value), vjust = -0.5) +\n  ggokabeito::scale_fill_okabe_ito() +\n  scale_y_continuous(expand = expansion(mult = c(0.075, 0.075))) +\n  labs(\n    title = \"Distance Between Transition Matrices\",\n    x = \"Distance Metric\",\n    y = \"Value\",\n    caption = caption) +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(hjust = 0.5, size = 14, face = \"bold\"),\n    axis.title = element_text(face = \"bold\", size = 12),\n    plot.caption = ggtext::element_markdown(size = 10),\n    legend.position = \"none\")\n```\n\n::: {.cell-output-display}\n![Distance metrics between observed and estimated transition matrices.](discrete-markov_files/figure-html/fig-metrics-1.png){#fig-metrics width=1152}\n:::\n:::\n",
    "supporting": [
      "discrete-markov_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}
{
  "hash": "39dd647afae96122190a8dcf2cbb90ff",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Discrete Time Markov Model\"\n---\n\n\n\n\n# Setting up\n\n## Loading packages\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Check out my packages\"}\n# Packages ---------------------------------------------------------------------\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(ggplot2)\nlibrary(patchwork)\n```\n:::\n\n\n\n\n## Loading functions\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Check out my functions\"}\n# Functions --------------------------------------------------------------------\nextract_years <- function(data, years, impute = TRUE, cog_total = FALSE, absorbing = TRUE) {\n  # Extracts cognitive function data for specified years from a dataset.\n  # Converts numeric cognitive status codes (1, 2, 3) into descriptive labels\n  # (\"Normal Cognition\", \"MCI\", \"Dementia\") for easier interpretation.\n  # Arguments:\n  #   - data: The input dataset containing cognitive function data.\n  #   - years: A vector of years for which data should be extracted.\n  # Returns:\n  #   - A dataset with ID and cognitive status columns for the specified years.\n  \n  # Create dynamic column names based on the years provided\n  cogfunction_cols <- paste0(\"cogfunction\", years)\n  cogtotal_cols    <- paste0(\"cogtot27_imp\", years)\n  \n  if(cog_total == FALSE) {\n    data <- data |>\n      # Select only the ID column and cognitive function columns for the specified years\n      select(ID, any_of(cogfunction_cols)) |>\n      mutate(across(!c(ID), ~ case_when(\n        .x == 1 ~ \"Normal Cognition\",\n        .x == 2 ~ \"MCI\",\n        .x == 3 ~ \"Dementia\",\n        TRUE ~ NA_character_  # To handle missing/other cases\n      )))\n  } else {\n    data <- data |>\n      # Select only the ID column and cognitive function columns for the specified years\n      select(ID, any_of(cogtotal_cols)) |>\n      rename_with( .cols = !ID, .fn = ~ stringr::str_replace(\n        string = .x,\n        pattern = \"cogtot27_imp\", \n        replacement = \"cog_score_\"))\n  }\n  \n  if(impute == TRUE){\n    data <- data |>\n      tidyr::pivot_longer(\n        cols = !ID,\n        names_to = \"Wave\",\n        values_to = \"Status\") |>\n      group_by(ID) |>\n      tidyr::fill(Status, .direction = \"down\") |>\n      ungroup() |>\n      tidyr::pivot_wider(names_from = \"Wave\", values_from = \"Status\")\n  }\n  \n  if(absorbing == TRUE) {\n    data <- data |>\n      tidyr::pivot_longer(\n        cols = !ID,\n        names_to = \"Wave\",\n        values_to = \"Status\") |>\n      group_by(ID) |>\n      mutate(Status = ifelse(cumany(Status == \"Dementia\"), \"Dementia\", Status)) |>\n      ungroup() |>\n      tidyr::pivot_wider(names_from = \"Wave\", values_from = \"Status\")\n  }\n  \n  return(data)\n}\n\npivot_and_factorise <- function(data) {\n  # Converts cognitive function data from wide to long format and factorizes key variables.\n  # Pivots multiple cogfunction columns into wave/status pairs and converts categorical\n  # variables (Gender, Education, status) to factors with meaningful labels.\n  # Arguments:\n  #   - data: Dataset containing cognitive function variables in wide format\n  # Returns:\n  #   - Long-format dataset with factorized variables, ordered by ID and wave\n  # \n  data |>\n    tidyr::pivot_longer(\n      cols = starts_with(\"cogfunction\"), names_to = \"wave\",\n      names_prefix = \"cogfunction\", values_to = \"status\") |>\n    mutate(\n      Gender = factor(Gender, levels = c(0, 1)),\n      Education_tri = factor(Education_tri, levels = c(0, 1, 2)),\n      wave = factor(wave),\n      status = factor(status, \n                      levels = c(\"Normal Cognition\", \"MCI\", \"Dementia\"),\n                      labels = c(1, 2, 3))) |>\n    relocate(wave, .after = ID) |>\n    relocate(status, .after = wave)\n}\n\ncreate_transition_table <- function(year_to, year_from) {\n  # Creates a transition frequency table between two specified years of cognitive status data.\n  # Calculates row sums and total observations for transition analysis.\n  # Arguments:\n  #   - year_to: Target year for transitions (character or numeric)\n  #   - year_from: Origin year for transitions (character or numeric)\n  # Returns:\n  #   - List containing: \n  #     - transition frequency table\n  #     - row sums\n  #     - total observations\n  # \n  tbl <- table(\n    table_data[[paste0(\"HRS_\", year_to)]],\n    table_data[[paste0(\"HRS_\", year_from)]],\n    dnn = c(year_to, year_from)\n  )\n  \n  # Calculate row sums and total\n  row_sums <- rowSums(tbl)\n  total <- sum(row_sums)\n  \n  # Return as a list with both the table and summary stats\n  list(\n    table = tbl,\n    row_sums = row_sums,\n    total = total\n  )\n}\n\ncreate_transition_dataset <- function(data, transition_results) {\n  # Combines multiple transition tables into a single analysis-ready dataset.\n  # Formats period labels, ensures consistent factor levels, and structures data for visualization.\n  # Arguments:\n  #   - data: List of year pairs to process (e.g., list(c(2016,2018)))\n  #   - transition_results: List containing transition tables from create_transition_table()\n  # Returns:\n  #   - Tidy dataset with transition frequencies between all specified periods\n  # \n  data |>\n    purrr::map_dfr(~ {\n      period_name <- paste(.x[2], .x[1], sep = \" - \")\n      tbl <- transition_results[[paste(.x[2], .x[1], sep = \"-\")]]$table\n      \n      as.data.frame(tbl) |>\n        rename(t_minus_1 = 1, t = 2) %>%  # Positional renaming\n        mutate(Period = period_name, .before = t_minus_1)\n    }) |>\n    mutate(\n      Period = stringr::str_replace(Period, \"(\\\\d+) - (\\\\d+)\", \"\\\\2 - \\\\1\"),\n      Period = factor(Period, levels = c(\"2016 - 2018\", \"2018 - 2020\", \"2020 - 2022\")),\n      t_minus_1 = factor(t_minus_1, levels = c(\"Normal Cognition\", \"MCI\", \"Dementia\")),\n      t = factor(t, levels = c(\"Normal Cognition\", \"MCI\", \"Dementia\"))\n    )\n}\n\ncreate_transitions <- function(data, absorbing = FALSE){\n  # Reshapes data from wide to long format to track cognitive status transitions over time.\n  # Calculates the next wave's cognitive status for each individual and creates a transition column.\n  # Optionally treats \"Dementia\" as an absorbing state, meaning once an individual is classified\n  # with dementia, their status cannot change in subsequent waves.\n  # Arguments:\n  #   - data: The dataset containing cognitive status data.\n  #   - absorbing: A logical flag indicating whether \"Dementia\" should be treated \n  #   as an absorbing state.\n  # Returns:\n  #   - A dataset with transition information, including current and next wave statuses.\n  \n  # Reshape the data from wide to long format to track cognitive status over waves\n  data <- data |>\n    select(ID, starts_with(\"cogfunction\")) |>\n    tidyr::pivot_longer(cols = !ID,\n                        names_to = \"Wave\",\n                        values_to = \"Status\") |>\n    mutate(Wave = as.factor(stringr::str_replace(Wave, \"cogfunction\", \"\"))) |>\n    # Arrange by ID and Wave to prepare for transition calculation\n    arrange(ID, Wave) |>\n    group_by(ID) |>\n    # Get the next wave's cognitive status for each person\n    mutate(next_wave_status = lead(Status)) |>\n    ungroup()\n  \n  # We can optionally specify dementia as an absorbing state\n  # Once an individual is classified with dementia they cannot be classified\n  # with anything else \n  if(absorbing == TRUE) {\n    data <- data |>\n      group_by(ID) |>\n      mutate(\n        Status = ifelse(cumany(Status == \"Dementia\"), \"Dementia\", Status),\n        next_wave_status = ifelse(cumany(Status == \"Dementia\"), \"Dementia\", next_wave_status),\n        transition = paste(Status, next_wave_status, sep = \" to \")\n      ) |>\n      filter(Wave %in% c(2016, 2018, 2020))\n  }\n  \n  # Filter out rows where either the current or next status is missing\n  data <- data |>\n    group_by(ID) |>\n    filter(!is.na(Status), !is.na(next_wave_status)) |>\n    ungroup() |>\n    # Create a new column representing the transition from one status to the next\n    mutate(\n      transition = paste(Status, next_wave_status, sep = \" to \"),\n      transition = factor(\n        transition, \n        levels = c(\"Normal Cognition to Normal Cognition\", \"Normal Cognition to MCI\",\n                   \"Normal Cognition to Dementia\", \"MCI to Normal Cognition\", \"MCI to MCI\",\n                   \"MCI to Dementia\", \"Dementia to Dementia\") \n      ))\n  \n  return(data)\n}\n\nobserved_transition_matrix <- function(data) {\n  # Converts transition data into a properly formatted probability transition matrix.\n  # Ensures consistent state ordering and converts proportions to matrix format suitable\n  # for multi-state modeling and visualization.\n  # Arguments:\n  #   - data: Transition dataset from create_transitions()\n  # Returns:\n  #   - Square transition probability matrix with states as row/column names\n  # \n  # The order I want my matrix in\n  state_order <- c(\"Normal Cognition\", \"MCI\", \"Dementia\")\n  \n  data |>\n    group_by(Status, next_wave_status) |>\n    summarise(freq = n(),  .groups = \"drop\") |>\n    group_by(Status) |>\n    mutate(freq = round(proportions(freq), 3)) |>\n    ungroup() |>\n    complete(Status, next_wave_status, fill = list(freq = 0)) |>\n    tidyr::pivot_wider(names_from = next_wave_status, values_from = freq, names_sort = TRUE) |>\n    tibble::column_to_rownames(\"Status\") |>\n    select(all_of(state_order)) |>\n    _[state_order, ] |>\n    as.matrix()\n}\n\nnormalise <- function(x) {\n  # Normalizes a matrix so that each row sums to 1.\n  # Arguments:\n  #   - x: The input matrix to normalize.\n  # Returns:\n  #   - A normalized matrix where each row sums to 1.\n  x / rowSums(x)\n}\n\nreshape_matrix <- function(matrix) {\n  # Converts a transition probability matrix into a tidy format suitable for visualization.\n  # Transforms the matrix into long format with explicit factor levels for cognitive states,\n  # preserving the original ordering while preparing for ggplot compatibility.\n  # Arguments:\n  #   - matrix: A square transition probability matrix with states as row/column names\n  # Returns:\n  #   - Tidy data frame with columns:\n  #     * from_state: Factor indicating origin cognitive state\n  #     * to_state: Factor indicating destination cognitive state (reversed for plotting)\n  #     * probability: Numeric transition probability values\n  \n  matrix |>\n    as.data.frame() |>\n    mutate(\n      from_state = factor(c(\n        \"Normal cognition\", \"MCI\", \"Dementia\"),\n        levels = c(\"Normal cognition\", \"MCI\", \"Dementia\"))\n    ) |>\n    reshape2::melt(\n      id.vars = \"from_state\", \n      variable.name = \"to_state\", \n      value.name = \"probability\") |>\n    mutate(to_state = factor(to_state, levels = rev(levels(to_state))))\n}\n\nplot_transition_matrix <- function(matrix, observed = TRUE) {\n  # Creates a heatmap visualization of cognitive state transition probabilities.\n  # Generates either observed or estimated transition plots with consistent formatting,\n  # including labeled probability values and a diverging color scale for emphasis.\n  # Arguments:\n  #   - matrix: Tidy transition matrix from reshape_matrix()\n  #   - observed: Logical flag indicating whether data represents observed (TRUE) \n  #               or estimated (FALSE) transitions\n  # Returns:\n  #   - ggplot heatmap object with:\n  #     * State transitions as cells\n  #     * Probability values displayed numerically\n  #     * Custom color scale and axis formatting\n  \n  if(observed == TRUE) {\n    subtitle <- \"Observed state transitions between assessment waves\"\n  } else {\n    subtitle <- \"Estimated state transitions between assessment waves\"\n  }\n  \n  matrix |>\n    ggplot(aes(x = from_state, y = to_state, fill = probability)) +\n    geom_tile(color = \"white\", linewidth = 0.5) +\n    geom_text(\n      aes(label = format(round(probability, 3), nsmall = 3)),\n      size = 4.5, \n      color = \"#212427\",\n      fontface = \"bold\") +\n    colorspace::scale_fill_continuous_diverging(\n      palette = \"Blue-Red 3\", mid = 0.50, alpha = 0.5, \n      limits = c(0, 1), name = \"Transition \\nProbability\") +\n    labs(title = \"Transition Probabilities Across Cognitive States\",\n         subtitle = subtitle,\n         x = \"Previous State (t - 1)\", \n         y = \"Current State (t)\") +\n    theme(\n      axis.text = element_text(size = 10),\n      axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1),\n      legend.position = \"right\",\n      legend.text = element_text(size = 9),\n      panel.grid = element_blank()\n    )\n}\n\ntran_stack_graph <- function(data) {\n  # Creates stacked bar charts visualizing cognitive state transitions across time periods.\n  # Shows composition of current states by previous state, faceted by observation period.\n  # Arguments:\n  #   - data: Transition dataset from create_transition_dataset()\n  # Returns:\n  #   - ggplot object showing stacked transition proportions\n  # \n  data |>\n    ggplot(aes(x = t_minus_1, y = Freq, fill = t)) +\n    geom_col(position = \"stack\", colour = \"black\") +\n    facet_wrap(~ Period, ncol = 3) +\n    labs(\n      x = \"Previous State (t-1)\", \n      y = \"Count\",\n      title = \"Outcomes by Prior Cognitive State\",\n      fill = \"Current State (t)\"\n    ) +\n    ggokabeito::scale_fill_okabe_ito() +\n    ggeasy::easy_move_legend(\"bottom\")\n}\n\ntran_heat_map <- function(data) {\n  # Generates heatmap visualization of transition frequencies between cognitive states.\n  # Uses color intensity and labeled values to show transition patterns across time periods.\n  # Arguments:\n  #   - data: Transition dataset from create_transition_dataset()\n  # Returns:\n  #   - ggplot heatmap with state transitions as cells\n  # \n  data |>\n    ggplot(aes(x = t_minus_1, y = t, fill = Freq)) +\n    geom_tile(color = \"white\") +\n    geom_text(aes(label = Freq), color = \"black\", size = 3.5) +  # Add counts\n    scale_fill_gradient(low = \"white\", high = \"steelblue\") +\n    facet_wrap(~ Period, ncol = 3) +  # Split by time period\n    labs(\n      x = \"Previous State (t-1)\", \n      y = \"Current State (t)\",\n      title = \"Cognitive State Transitions Between Time Periods\",\n      fill = \"Frequency\"\n    ) +\n    theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n    ggeasy::easy_move_legend(\"bottom\")\n}\n\ntidy_output <- function(fit) {\n  output <- broom::tidy(fit, conf.int = TRUE) |>\n    filter(term != \"(Intercept)\") |>\n    mutate(\n      term = case_when(\n      term == \"Gender1\" ~ \"Being female\",\n      term == \"Education_tri1\" ~ \"High school degree vs. No education\",\n      term == \"Education_tri2\" ~ \"Further education vs. No education\",\n      term == \"Total_dep_2016\" ~ \"Depression Scores (2016)\",\n      term == \"Total_p\" ~ \"Procrastination\",\n      term == \"status_prev2\" ~ \"Previous state: MCI\",\n      term == \"status_prev3\" ~ \"Previous state: Dementia\",\n      term == \"wave\" ~ \"Time\",\n      TRUE ~ term)) |>\n  mutate(across(c(estimate:p.value), ~ round(x = ., digits = 3)))\n  \n  if(any(output$y.level == \"1\")) {\n    output |>\n      mutate(y.level = case_when(\n      y.level == \"1\" ~ \"MCI - NC\",\n      y.level == \"3\" ~ \"MCI - Dementia\"))\n  } else {\n    output |>\n      mutate(y.level = case_when(\n      y.level == \"2\" ~ \"NC - MCI\",\n      y.level == \"3\" ~ \"NC - Dementia\"))\n  }\n}\n\ntidy_predictions <- function(predictions) {\n  # Restructures model prediction matrices into tidy format for visualization.\n  # Converts numeric codes to factor labels and reshapes multiple prediction columns\n  # into key-value pairs suitable for ggplot.\n  # Arguments:\n  #   - predictions: Raw prediction matrix from model output\n  # Returns:\n  #   - Long-format dataset with probabilities for each cognitive state\n  #   \n  predictions |>\n    as.matrix() |>\n    as_tibble() |>\n    mutate(\n      Gender = factor(ifelse(Gender == 0, \"Male\", \"Female\"), levels = c(\"Male\", \"Female\")),\n      status_prev = case_when(\n        status_prev == 1 ~ \"Normal Cognition\",\n        status_prev == 2 ~ \"MCI\",\n        status_prev == 3 ~ \"Dementia\",\n      ),\n      status_prev = factor(status_prev, levels = c(\"Normal Cognition\", \"MCI\", \"Dementia\")),\n      Total_p = as.numeric(Total_p),\n      across(c(pred.1:pred.3), as.numeric)) |>\n    tidyr::pivot_longer(cols = c(pred.1:pred.3), names_to = \"status\", values_to = \"prob\") |>\n    mutate(status = case_when(\n      status == \"pred.1\" ~ \"Normal Cognition\",\n      status == \"pred.2\" ~ \"MCI\",\n      status == \"pred.3\" ~ \"Dementia\"\n    ),\n    status = factor(status, levels = c(\"Normal Cognition\", \"MCI\", \"Dementia\")),\n    status_prev = factor(status_prev, levels = c(\"Normal Cognition\", \"MCI\", \"Dementia\")))\n}\n\nplot_predictions_stationary <- function(predictions, variable, x_axis) {\n  # Visualizes predicted transition probabilities from stationary multi-state models.\n  # Shows probability curves by procrastination level, stratified by baseline state.\n  # Arguments:\n  #   - predictions: Tidy predictions from tidy_predictions()\n  # Returns:\n  #   - Faceted ggplot showing predicted probability curves\n  # \n  predictions |>\n    ggplot(aes(x = {{variable}}, y = prob, colour = status_prev)) +\n    geom_line(linewidth = 1) +\n    ggokabeito::scale_colour_okabe_ito() +\n    labs(\n      title = \"Predicted transition probabilities (stationary model)\",\n      x = x_axis, y = \"Probability\", colour = \"Previous State\") +\n    facet_wrap(~ status, labeller = labeller(\n      status = function(x){paste0(\"Transition to: \", x)}\n    ))\n}\n\nget_time_varying_matrix <- function(model, time_point) {\n  expand.grid(\n    Gender = factor(0),\n    Age = mean(data_stack$Age),\n    Education_tri = factor(0),\n    Total_dep_2016 = mean(data_stack$Total_dep_2016),\n    Total_p = mean(data_stack$Total_p),\n    status_prev = factor(1:3),\n    wave = time_point) |> \n    modelr::add_predictions(model, var = \"prob\", type = \"probs\") |> \n    select(status_prev, starts_with(\"prob\")) |> \n    mutate(\n      status_prev = factor(status_prev, labels = state_names),\n      across(starts_with(\"prob\"), ~round(., 3))) |>\n    tibble::column_to_rownames(\"status_prev\") |>\n    as.matrix() |> `colnames<-`(state_names)\n}\n```\n:::\n\n\n\n\n## Setting theme\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Check out my theme\"}\ncolour <- \"#212427\"\n\ntheme_set(\n  theme_minimal() +\n    theme(\n      plot.title = element_text(hjust = 0.5, size = 14, colour = colour, face = \"bold\"),\n      plot.subtitle = element_text(hjust = 0.5, size = 12, colour = colour),\n      axis.title = element_text(size = 10, colour = colour, face = \"bold\"),\n      strip.text = element_text(size = 10, colour = colour, face = \"bold\"),\n      legend.title = element_text(hjust = 0.5, colour = colour, face = \"bold\"),\n      ))\n```\n:::\n\n\n\n\n\n## Reading in data {.unnumbered}\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata <- read.csv(here::here(\"analysis/data/data.csv\"))\n```\n:::\n\n\n\n\n# Data Preparation\n\nBefore preparing the data, we want to create a vector of covariates that we are interested in using in our analysis\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncols <- c(\"ID\", \"Gender\", \"Age\", \"Education_tri\", \"Cardio_risk_16\", \"Total_dep_2016\", \"Total_p\")\n```\n:::\n\n\n\n\nFollowing this, we can now use the `extract_years()` function to extract the cognitive function data for the years 2016, 2018, and 2020. \n\n- We will also impute some missing values `impute = TRUE` using logical reasoning (if a respondent has an NA value in 2018, but has a classification of \"normal cognition\" in 2020, then the missing 2018 value becomes \"normal cognition\").\n- We will also treat dementia as an absorbing state `absorbing = TRUE`.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata_stack <- data |> extract_years(years = seq(2016, 2022, by = 2), impute = TRUE, absorbing = TRUE) |> na.omit()\n\nhead(data_stack)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 5\n     ID cogfunction2016  cogfunction2018  cogfunction2020  cogfunction2022 \n  <int> <chr>            <chr>            <chr>            <chr>           \n1     1 Normal Cognition Normal Cognition Normal Cognition Normal Cognition\n2     2 Normal Cognition Normal Cognition Normal Cognition Normal Cognition\n3     3 Dementia         Dementia         Dementia         Dementia        \n4     4 Normal Cognition Normal Cognition Normal Cognition Normal Cognition\n5     5 MCI              Normal Cognition Normal Cognition Normal Cognition\n6     6 Normal Cognition Normal Cognition Normal Cognition Normal Cognition\n```\n\n\n:::\n:::\n\n\n\n\n## Creating a stacked dataset\n\nFor each respondent we will now add in their relevant covariate data. Following this, we transform the data to long format and convert categorical variables to factors using the `pivot_and_factorise()` function. Additionally, we will fix the `Age` column to properly represent the age of the respondent at each time point\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata_stack <- data_stack |>\n  inner_join(data[, cols], by = \"ID\") |>\n  pivot_and_factorise() |>\n  group_by(ID) |>\n  mutate(Age = Age - (2022 - as.numeric(as.character(wave))))\n\nhead(data_stack)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 9\n# Groups:   ID [2]\n     ID wave  status Gender   Age Education_tri Cardio_risk_16 Total_dep_2016\n  <int> <fct> <fct>  <fct>  <dbl> <fct>                  <int>          <int>\n1     1 2016  1      1         72 2                          0              0\n2     1 2018  1      1         74 2                          0              0\n3     1 2020  1      1         76 2                          0              0\n4     1 2022  1      1         78 2                          0              0\n5     2 2016  1      1         75 2                          1              2\n6     2 2018  1      1         77 2                          1              2\n# ℹ 1 more variable: Total_p <int>\n```\n\n\n:::\n:::\n\n\n\n\nFinally, we will create a new variable `status_prev` that notes the cognitive status of the respondent in the previous wave $(t - 1)$. This will be done by using the `lag` function from the `dplyr` package.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata_stack <- data_stack |>\n  mutate(status_prev = lag(status), .after = status) |>\n  ungroup() |> \n  filter(wave != 2016, !is.na(Total_p), Age >= 50)\n\nhead(data_stack)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 10\n     ID wave  status status_prev Gender   Age Education_tri Cardio_risk_16\n  <int> <fct> <fct>  <fct>       <fct>  <dbl> <fct>                  <int>\n1     1 2018  1      1           1         74 2                          0\n2     1 2020  1      1           1         76 2                          0\n3     1 2022  1      1           1         78 2                          0\n4     2 2018  1      1           1         77 2                          1\n5     2 2020  1      1           1         79 2                          1\n6     2 2022  1      1           1         81 2                          1\n# ℹ 2 more variables: Total_dep_2016 <int>, Total_p <int>\n```\n\n\n:::\n:::\n\n\n\n\n# Transition frequencies\n\nWe will now calculate the transition frequencies between cognitive states for each time period. We will use the `create_transition_table()` function to create a transition table for each time period. This will be done with the help of the `map()` function from the `purrr` package. Finally, to combine all the transition tables into one dataset, we will use the `create_transition_dataset()` function.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Creating a table dataset\ntable_data <- data |>\n  extract_years(seq(2016, 2022, by = 2)) |>\n  rename_with(~ gsub(\"cogfunction\", \"HRS_\", .)) |>\n  mutate(\n    across(c(HRS_2016:HRS_2022), ~ factor(.x, levels = c(\"Normal Cognition\", \"MCI\", \"Dementia\")))\n  )\n\n# Creating transition frequencies ---------------------------------------------\n## These are the time periods we are interested in\ntime_periods <- list(\n  c(\"2016\", \"2018\"),\n  c(\"2018\", \"2020\"), \n  c(\"2020\", \"2022\")\n)\n\n# Applying function\ntransition_results <- purrr::map(time_periods, ~ create_transition_table(.x[1], .x[2]))\nnames(transition_results) <- purrr::map_chr(time_periods, ~ paste(.x[2], .x[1], sep = \"-\"))\n\n### Creating one dataset\ntransition_frequencies <- time_periods |>\n  create_transition_dataset(transition_results = transition_results)\n\nhead(transition_frequencies)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       Period        t_minus_1                t Freq\n1 2016 - 2018 Normal Cognition Normal Cognition  713\n2 2016 - 2018              MCI Normal Cognition   76\n3 2016 - 2018         Dementia Normal Cognition    0\n4 2016 - 2018 Normal Cognition              MCI   58\n5 2016 - 2018              MCI              MCI   49\n6 2016 - 2018         Dementia              MCI    0\n```\n\n\n:::\n:::\n\n\n\n\n## Observed transition matrix\n\nThe probability distribution of transitions from one state to another can be represented into a transition matrix $P = (p_{ij})_{i,j}$ where each element of position $(i, j)$ represents the transition probability $p_{ij}$. \n\nIn order to create this matrix we will use both the `create_transitions()` and `observed_transition_matrix()` functions.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Creating observed transition matrix -----------------------------------------\ntransition_matrix_observed <- data |>\n  extract_years(seq(2016, 2022, by = 2)) |>\n  create_transitions() |>\n  observed_transition_matrix()\n\ntransition_matrix_observed\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                 Normal Cognition   MCI Dementia\nNormal Cognition            0.895 0.096    0.009\nMCI                         0.530 0.376    0.094\nDementia                    0.000 0.000    1.000\n```\n\n\n:::\n:::\n\n\n\n\n## Visualisation\n\nLet's visualize both the transition frequencies (@fig-frequencies) and matrix (@fig-matrix).\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Check out my code\"}\nfig_1 <- transition_frequencies |> tran_stack_graph()\nfig_2 <- transition_frequencies |> tran_heat_map()\n\nfig_1 / fig_2\n```\n\n::: {.cell-output-display}\n![Transition frequencies between cognitive states for each time period.](discrete-markov_files/figure-html/fig-frequencies-1.png){#fig-frequencies width=1152}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Check out my code\"}\nfig_3 <- transition_matrix_observed |>\n  reshape_matrix() |>\n  plot_transition_matrix()\n\nfig_3\n```\n\n::: {.cell-output-display}\n![Observed transition matrix between cognitive states for the years 2016 - 2022.](discrete-markov_files/figure-html/fig-matrix-1.png){#fig-matrix width=1152}\n:::\n:::\n\n\n\n\n# Modelling\n\n## Markov Process Fundamentals\n\nDiscrete-time Markov models belong to a class of stochastic processes that satisfy the **Markov property**, which can be formally expressed as:\n\n$$\nP(X_{t+1} = j \\vert X_t = i, X_{t-1} = i_{t-1}, \\dots X_0 = i_0) = P(X_{t+1} = j \\vert X_t = i)\n$$ {#eq-markov}\n\nThis property establishes that the future state $X_{t+1}$ depends only on the current state $X_t$, not on the entire history of states.\n\n### Transition Probability Matrix\n\nFor our three-state system (Normal Cognition, Mild Cognitive Impairment [MCI], Dementia), the transition matrix $P$ captures all possible transition probabilities:\n\n$$\nP = \\begin{bmatrix} \np_{11} & p_{12} & p_{13} \\\\\np_{21} & p_{22} & p_{23} \\\\\np_{31} & p_{32} & p_{33} \\\\\n\\end{bmatrix}\n$$ {#eq-t-matrix}\n\nwhere:\n\n- $p_{ij} = P(X_{t+1} = j \\vert X_t = i)$ represents the probability of transitioning from state $i$ to state $j$.\n- Each row sums to 1, $\\sum^3_{j=1} p_{ij} = 1 \\quad  \\forall_i \\in \\{1, 2, 3\\}$\n\n### Multinomial Logistic Regression Formulation\n\nWe model the transition probabilities using **multinomial logistic regression**, where the log-odds of each transition relative to a reference state are linear functions of covariates.\n\nFor a system with $K$ states (using state $K$ as reference), we have:\n\n$$\nlog \\left( \\frac{P(Y = j \\vert x)}{P(Y = k \\vert x)} \\right) = \\beta_{j0} + \\beta_j^Tx \\qquad \\text{for } j = 1, \\dots K-1\n$$ {#eq-multinomial}\n\nFor non-reference states $j = 1, \\dots, K - 1$\n\n$$\nP(Y = j \\vert x) = \\frac{e^{\\beta_{0j} + \\beta_j^Tx}}{1 + \\sum^{k - 1}_{k = 1} e^{\\beta_{0k} + \\beta_k^Tx}}\n$$ {#eq-non-reference}\n\nFor the reference state $K$:\n\n$$\nP(Y = k \\vert x) = \\frac{1}{1 + \\sum^{k - 1}_{k = 1} e^{\\beta_{0k} + \\beta_j^Tx }}\n$$ {#eq-reference}\n\n### Time-Homogeneous Approach\n\nOur implementation assumes time-homogeneous transitions, but the framework can be extended to time-varying probabilities:\n\n$$\nP^{(t)} = \\begin{bmatrix} \np_{11}^{(t)} & p_{12}^{(t)} & \\cdots & p_{1n}^{(t)} \\\\\np_{21}^{(t)} & p_{22}^{(t)} & \\cdots & p_{2n}^{(t)} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\np_{n1}^{(t)} & \\cdots & \\cdots & p_{nn}^{(t)} \\\\\n\\end{bmatrix}\n$$ {#eq-non-stationary}\n\nOur primary analysis assumes the transition matrix remains fixed:\n\n$$\nP^{(t)} \\equiv P \\qquad \\forall \\; t\n$$ {#eq-assumption}\n\n### Absorbing State Specification\n\nWe model Dementia as an absorbing state:\n\n$$\np_{3j} = \\begin{cases} \n1 \\qquad \\text{if } j = 3 \\\\\n0 \\qquad \\text{otherwise} \\end{cases}\n$$ {#eq-dementia}\n\nyielding the constrained transition matrix:\n\n$$\nP = \\begin{bmatrix} \np_{11} & p_{12} & p_{13} \\\\\np_{21} & p_{22} & p_{23} \\\\\n0      & 0      & 1      \\\\\n\\end{bmatrix}\n$$ {#eq-t-matrix-constrained}\n\n## Stationary model\n\nWe estimate three progressively complex stationary models using `nnet::multinom()`\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Check out my models\"}\n# Baseline model (only gender; reference: NC)\nfit_1a <- nnet::multinom(\n  status ~ Gender + Age + Education_tri + Total_dep_2016, family = multinomial, \n  data = data_stack, trace = FALSE)\n\n# Baseline model (only gender; reference: MCI)\nfit_1b <- nnet::multinom(\n  status ~ Gender + Age + Education_tri + Total_dep_2016, family = multinomial, \n  data = data_stack |> mutate(status = relevel(status, ref = 2)), \n  trace = FALSE)\n\n# With procrastination (reference: NC)\nfit_2a <- nnet::multinom(\n  status ~ Gender + Age + Education_tri + Total_dep_2016 + Total_p, family = multinomial, \n  data = data_stack, trace = FALSE)\n\n# With procrastination (reference: MCI)\nfit_2b <- nnet::multinom(\n  status ~ Gender + Age + Education_tri + Total_dep_2016 + Total_p, family = multinomial, \n  data = data_stack |> mutate(status = relevel(status, ref = 2)), \n  trace = FALSE)\n\n# Full model with previous state (reference NC)\nfit_3a <- nnet::multinom(\n  status ~ Gender + Age + Education_tri + Total_dep_2016 + Total_p + status_prev, family = multinomial, \n  data = data_stack, trace = FALSE)\n\n# Full model with previous state (reference MCI)\nfit_3b <- nnet::multinom(\n  status ~ Gender + Age + Education_tri + Total_dep_2016 + Total_p + status_prev, family = multinomial, \n  data = data_stack |> mutate(status = relevel(status, ref = 2)), \n  trace = FALSE)\n```\n:::\n\n\n\n\n### Model comparison\n\nWe evaluate model improvement using likelihood ratio tests:\n\n$$\nD = -2 \\times \\ell_{\\text{reduced}} - \\ell_{\\text{full}}\n$$ {#eq-liklihood}\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nanova(fit_1a, fit_2a, fit_3a) |>\n  knitr::kable(caption = \"Nested Model Comparison\") |>\n  kableExtra::kable_styling(\n    bootstrap_options = c(\"striped\", \"hover\"),\n    full_width = FALSE)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n<caption>Nested Model Comparison</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Model </th>\n   <th style=\"text-align:right;\"> Resid. df </th>\n   <th style=\"text-align:right;\"> Resid. Dev </th>\n   <th style=\"text-align:left;\"> Test </th>\n   <th style=\"text-align:right;\"> Df </th>\n   <th style=\"text-align:right;\"> LR stat. </th>\n   <th style=\"text-align:right;\"> Pr(Chi) </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> Gender + Age + Education_tri + Total_dep_2016 </td>\n   <td style=\"text-align:right;\"> 5100 </td>\n   <td style=\"text-align:right;\"> 2661.692 </td>\n   <td style=\"text-align:left;\">  </td>\n   <td style=\"text-align:right;\"> NA </td>\n   <td style=\"text-align:right;\"> NA </td>\n   <td style=\"text-align:right;\"> NA </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Gender + Age + Education_tri + Total_dep_2016 + Total_p </td>\n   <td style=\"text-align:right;\"> 5098 </td>\n   <td style=\"text-align:right;\"> 2653.172 </td>\n   <td style=\"text-align:left;\"> 1 vs 2 </td>\n   <td style=\"text-align:right;\"> 2 </td>\n   <td style=\"text-align:right;\"> 8.519494 </td>\n   <td style=\"text-align:right;\"> 0.0141259 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Gender + Age + Education_tri + Total_dep_2016 + Total_p + status_prev </td>\n   <td style=\"text-align:right;\"> 5094 </td>\n   <td style=\"text-align:right;\"> 2070.128 </td>\n   <td style=\"text-align:left;\"> 2 vs 3 </td>\n   <td style=\"text-align:right;\"> 4 </td>\n   <td style=\"text-align:right;\"> 583.043942 </td>\n   <td style=\"text-align:right;\"> 0.0000000 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\n\n### Estimated parameters\n\nBelow we present the estimated parameters for the stationary models. We will transform the estimates to odds ratios and code them based on significance.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Check out my code\"}\nstationary_results <- rbind(tidy_output(fit_3a), tidy_output(fit_3b)) |>\n  mutate(\n    # Transforming to odds ratios\n    estimate = exp(estimate),\n    conf.low = exp(conf.low),\n    conf.high = exp(conf.high),\n    \n    # Mutating to factors\n    y.level = factor(\n      y.level, \n      levels = c(\"NC - MCI\", \"MCI - NC\", \n                 \"NC - Dementia\", \"MCI - Dementia\")),\n    term = factor(\n      term, \n      levels = c(\"Being female\", \"Age\", \"High school degree vs. No education\",\n                 \"Further education vs. No education\", \"Depression Scores (2016)\",\n                 \"Procrastination\", \"Previous state: MCI\", \"Previous state: Dementia\")),\n    \n    # Creating a colour code\n    positive = case_when(\n      estimate > 1 & p.value < 0.05 ~ \"Positive\",\n      estimate < 1 & p.value < 0.05 ~ \"Negative\",\n      TRUE ~ \"NS\"),\n    \n    positive = factor(positive, levels = c(\"Positive\", \"Negative\", \"NS\"))\n    )\n\nhead(stationary_results)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 9\n  y.level term  estimate std.error statistic p.value conf.low conf.high positive\n  <fct>   <fct>    <dbl>     <dbl>     <dbl>   <dbl>    <dbl>     <dbl> <fct>   \n1 NC - M… Bein…    0.882     0.133    -0.936   0.349    0.680     1.15  NS      \n2 NC - M… Age      1.04      0.006     5.65    0        1.02      1.05  Positive\n3 NC - M… High…    0.472     0.161    -4.67    0        0.344     0.647 Negative\n4 NC - M… Furt…    0.303     0.192    -6.23    0        0.208     0.441 Negative\n5 NC - M… Depr…    1.08      0.031     2.39    0.017    1.01      1.14  Positive\n6 NC - M… Proc…    1.01      0.006     2.09    0.037    1.00      1.02  Positive\n```\n\n\n:::\n:::\n\n\n\n\n### Model visualisation\n\nLet's visualise the estimated odds ratios (@fig-odds-ratio) and the predicted transition probabilities (@fig-model-predictions) for the stationary model .\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Check out my code\"}\nfig_4a <- stationary_results |>\n  filter(!term %in% c(\"Previous state: MCI\", \"Previous state: Dementia\")) |>\n  ggplot(aes(x = estimate, y = y.level, colour = positive)) +\n  geom_vline(xintercept = 1, linetype = \"dashed\", color = \"gray50\") +\n  ggstance::geom_pointrangeh(\n    aes(xmin = conf.low, xmax = conf.high),\n    position = ggstance::position_dodgev(height = 0.5),\n    size = 1.25,\n    fatten = 3) +\n  scale_colour_manual(values = c(\n    \"Positive\" = \"#0072B2\", \n    \"Negative\" = \"#E69F00\", \n    \"NS\"       = \"#B2BEB5\")) +\n  labs(title = \"Odds Ratios from Multinomial Model\",\n       x = \"Odds Ratio\", y = \"Predictor\") +\n  guides(colour = \"none\") +\n  facet_wrap(~ term, scales = \"free_x\") +\n  theme_bw() +\n  theme(\n    plot.title = element_text(hjust = 0.5, size = 14, face = \"bold\"),\n    axis.title = element_text(size = 12, face = \"bold\"),\n    strip.text = element_text(size = 10, face = \"bold\"),\n    panel.grid.major.y = element_blank(),\n    panel.grid.minor.y = element_blank())\n\nfig_4a\n```\n\n::: {.cell-output-display}\n![Estimated odds ratios for the stationary model.](discrete-markov_files/figure-html/fig-odds-ratio-1.png){#fig-odds-ratio width=1152}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Check out my code\"}\n## Making a prediction dataset -------------------------------------------------\npred_data <- expand.grid(\n  Gender = factor(0),\n  Age = mean(data_stack$Age),\n  Education_tri = factor(0),\n  Total_dep_2016 = mean(data_stack$Total_dep_2016),\n  status_prev = levels(data_stack$status_prev),\n  Total_p = seq(0, 60, length = 200))\n\n## Plotting predictions\nfig_4b <- pred_data |>\n  modelr::add_predictions(model = fit_3a, var = \"pred\", type = \"probs\") |>\n  tidy_predictions() |>\n  plot_predictions_stationary(variable = Total_p, x_axis = \"Total Procrastination\")\n\nfig_4b\n```\n\n::: {.cell-output-display}\n![Predicted transition probabilities from the stationary model.](discrete-markov_files/figure-html/fig-model-predictions-1.png){#fig-model-predictions width=1152}\n:::\n:::\n\n\n\n\n### Estimated transition matrix\n\nFinally, we can compare the observed and predicted transition matrices. We will use the estimated probabilities from the model to fill in the transition matrix.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Get all unique states\nnames <- c(\"Normal Cognition\", \"MCI\", \"Dementia\")\nstates <- sort(unique(data_stack$status))\nn_states <- length(states)\n\n# Create empty transition matrix\ntransition_matrix_estimated <- matrix(\n  0, nrow = n_states, ncol = n_states,\n  dimnames = list(paste(\"From\", names), paste(\"To\", names))\n  )\n\n# Getting estimated probabilities\nestimated_probs <- expand.grid(\n  Gender = factor(0),\n  Age = mean(data_stack$Age),\n  Education_tri = factor(0),\n  Total_dep_2016 = mean(data_stack$Total_dep_2016),\n  Total_p = mean(data_stack$Total_p),\n  status_prev = states) |>\n  modelr::add_predictions(model = fit_3a, var = \"pred\", type = \"probs\")\n\n# Filling in matrix\nfor(i in 1:n_states) {\n  transition_matrix_estimated[i, ] <- estimated_probs$pred[i, ]\n}\n\ntransition_matrix_estimated |> round(digits = 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                      To Normal Cognition To MCI To Dementia\nFrom Normal Cognition               0.786  0.188       0.025\nFrom MCI                            0.398  0.449       0.153\nFrom Dementia                       0.000  0.000       1.000\n```\n\n\n:::\n:::\n\n\n\n\nLet's plot this and then compare with our observed matrix\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Check out my code\"}\nfig_5 <- transition_matrix_estimated |>\n  reshape_matrix() |>\n  plot_transition_matrix(observed = FALSE)\n\nfig_3 + fig_5 + plot_layout(axis_titles = \"collect\", guides = \"collect\")\n```\n\n::: {.cell-output-display}\n![Comparison of observed and estimated transition matrices.](discrete-markov_files/figure-html/fig-matrix-comparison-1.png){#fig-matrix-comparison width=1152}\n:::\n:::\n\n\n\n\n## Non-stationary model\n\nWe can also estimate a non-stationary model (@eq-non-stationary) by incorporating time `(wave)` into our model. This model allows for time-varying transition probabilities $p^{(t)}_{ij}$.\n\nWe estimate three progressively complex non-stationary models:\n\n- Additive time effects `(fit_4)`: Baseline covariates + wave\n- State-specific time effects `(fit_5)`: Interaction between previous state and wave\n- Full time interactions `(fit_6)`: All covariates interacting with wave\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Check out my models\"}\n## Small processing to fix wave column\ndata_stack <- data_stack |>\n  mutate(wave = case_when(\n    wave == \"2016\" ~ 1,\n    wave == \"2018\" ~ 2,\n    wave == \"2020\" ~ 3,\n    wave == \"2022\" ~ 4\n  ))\n\n# Model 4: Additive time effects\nfit_4a <- nnet::multinom(\n  status ~ Gender + Age + Education_tri + Total_dep_2016 + Total_p + status_prev + wave, family = multinomial, \n  data = data_stack, trace = FALSE)\n\nfit_4b <- nnet::multinom(\n  status ~ Gender + Age + Education_tri + Total_dep_2016 + Total_p + status_prev + wave, family = multinomial, \n  data = data_stack |> mutate(status = relevel(status, ref = 2)), \n  trace = FALSE)\n\n# Model 5: State-specific time effects\nfit_5a <- nnet::multinom(\n  status ~ Gender + Age + Education_tri + Total_dep_2016 + Total_p + (status_prev * wave), family = multinomial, \n  data = data_stack, trace = FALSE)\n\nfit_5b <- nnet::multinom(\n  status ~ Gender + Age + Education_tri + Total_dep_2016 + Total_p + (status_prev * wave), family = multinomial, \n  data = data_stack |> mutate(status = relevel(status, ref = 2)), \n  trace = FALSE)\n\n# Model 6: Full time interactions\nfit_6a <- nnet::multinom(\n  status ~ (Gender + Age + Education_tri + Total_dep_2016 + Total_p + status_prev) * wave, family = multinomial, \n  data = data_stack, trace = FALSE)\n\nfit_6b <- nnet::multinom(\n  status ~ (Gender + Age + Education_tri + Total_dep_2016 + Total_p + status_prev) * wave, family = multinomial, \n  data = data_stack |> mutate(status = relevel(status, ref = 2)), \n  trace = FALSE)\n```\n:::\n\n\n\n\n### Model comparison\n\nAgain, we will evaluate model improvement using likelihood ratio tests (@eq-liklihood). However, this time, we will also compare the best fitted non-stationary models `fit_3`.\n\n\n\n\n::: {.cell layout-nrow=\"2\"}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Check out my code\"}\n# Fit statistics\nmodels <- list(\n  \"Stationary\" = fit_3a,\n  \"Additive Time\" = fit_4a,\n  \"State-Time Interaction\" = fit_5a,\n  \"Full Interactions\" = fit_6a\n)\n\n# Create comparison table\ncomparison_table <- purrr::map_dfr(models, broom::glance, .id = \"Model\") |>\n  select(edf:AIC) |>\n  mutate(across(where(is.numeric), \\(x) round(x, digits = 1)))\n\n# Outputting as table\nanova(fit_3a, fit_4a, fit_5a, fit_6a) |>\n  mutate(\n    Model = c(\"Stationary\", \"Additive\", \"State-Time Interactions\", \"Full Interactions\"),\n    `Resid. Dev` = round(`Resid. Dev`, digits = 3),\n    `LR stat.` = round(`LR stat.`, digits = 3),\n    `Pr(Chi)` = round(`Pr(Chi)`, digits = 3)\n    ) |>\n  cbind(comparison_table) |>\n  DT::datatable(\n    options = list(\n      columnDefs = list(list(className = 'dt-center', targets = \"_all\"))\n    ),\n    rownames = FALSE,\n    caption = \"Likelihood Ratio Tests\"\n  )\n```\n\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"datatables html-widget html-fill-item\" id=\"htmlwidget-a7ef0eb0aa4349a900b8\" style=\"width:100%;height:auto;\"></div>\n<script type=\"application/json\" data-for=\"htmlwidget-a7ef0eb0aa4349a900b8\">{\"x\":{\"filter\":\"none\",\"vertical\":false,\"caption\":\"<caption>Likelihood Ratio Tests<\\/caption>\",\"data\":[[\"Stationary\",\"Additive\",\"State-Time Interactions\",\"Full Interactions\"],[5094,5092,5088,5076],[2070.128,2056.018,2051.782,2014.379],[\"\",\"1 vs 2\",\"2 vs 3\",\"3 vs 4\"],[null,2,4,12],[null,14.11,4.236,37.403],[null,0.001,0.375,0],[18,20,24,36],[2070.1,2056,2051.8,2014.4],[2106.1,2096,2099.8,2086.4]],\"container\":\"<table class=\\\"display\\\">\\n  <thead>\\n    <tr>\\n      <th>Model<\\/th>\\n      <th>Resid. df<\\/th>\\n      <th>Resid. Dev<\\/th>\\n      <th>Test<\\/th>\\n      <th>   Df<\\/th>\\n      <th>LR stat.<\\/th>\\n      <th>Pr(Chi)<\\/th>\\n      <th>edf<\\/th>\\n      <th>deviance<\\/th>\\n      <th>AIC<\\/th>\\n    <\\/tr>\\n  <\\/thead>\\n<\\/table>\",\"options\":{\"columnDefs\":[{\"className\":\"dt-center\",\"targets\":\"_all\"},{\"name\":\"Model\",\"targets\":0},{\"name\":\"Resid. df\",\"targets\":1},{\"name\":\"Resid. Dev\",\"targets\":2},{\"name\":\"Test\",\"targets\":3},{\"name\":\"   Df\",\"targets\":4},{\"name\":\"LR stat.\",\"targets\":5},{\"name\":\"Pr(Chi)\",\"targets\":6},{\"name\":\"edf\",\"targets\":7},{\"name\":\"deviance\",\"targets\":8},{\"name\":\"AIC\",\"targets\":9}],\"order\":[],\"autoWidth\":false,\"orderClasses\":false}},\"evals\":[],\"jsHooks\":[]}</script>\n```\n\n:::\n:::\n\n\n\n\n**Looks like adding in time as an additive term improved things**\n\n### Estimated parameters\n\nKey coefficients from the selected non-stationary model `fit_4`\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnon_stationary_results <- rbind(tidy_output(fit_4a), tidy_output(fit_4b))\n\nhead(non_stationary_results)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 8\n  y.level  term          estimate std.error statistic p.value conf.low conf.high\n  <chr>    <chr>            <dbl>     <dbl>     <dbl>   <dbl>    <dbl>     <dbl>\n1 NC - MCI Being female    -0.122     0.133    -0.915   0.36  -3.84e-1    0.139 \n2 NC - MCI Age              0.033     0.007     5.08    0      2.03e-2    0.0458\n3 NC - MCI High school …   -0.756     0.161    -4.70    0     -1.07e+0   -0.441 \n4 NC - MCI Further educ…   -1.22      0.192    -6.33    0     -1.59e+0   -0.840 \n5 NC - MCI Depression S…    0.072     0.031     2.35    0.019  1.20e-2    0.132 \n6 NC - MCI Procrastinat…    0.012     0.006     2.05    0.041  4.96e-4    0.0227\n```\n\n\n:::\n:::\n\n\n\n\n### Model visualisation\n\nLet's visualize the predicted transition probabilities from the non-stationary model @fig-non-stationary. We will show probability curves by procrastination level \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Check our my code\"}\nexpand.grid(\n  Gender = factor(0),\n  Age = mean(data_stack$Age),\n  Education_tri = factor(0),\n  Total_dep_2016 = mean(data_stack$Total_dep_2016),\n  status_prev = levels(data_stack$status_prev),\n  Total_p = seq(0, 60, length = 200),\n  wave = unique(data_stack$wave)) |>\n  modelr::add_predictions(model = fit_4a, var = \"pred\", type = \"probs\") |>\n  tidy_predictions() |>\n  mutate(wave = factor(wave)) |>\n  ggplot(aes(x = Total_p, y = prob, color = status_prev)) +\n  geom_line(linewidth = 1) +\n  ggokabeito::scale_color_okabe_ito() +\n  labs(\n    title = \"Time-Varying Transition Probabilities\",\n    x = \"Total Procrastination\", \n    y = \"Predicted Probability\", color = \"Previous State\") +\n  facet_grid(wave ~ status, labeller = labeller(\n    wave = function(x) paste(\"Years since baseline:\", x),\n    status = function(x) paste(\"Transition to:\", x)\n  )) +\n  theme(panel.spacing = unit(1, \"lines\"))\n```\n\n::: {.cell-output-display}\n![Predicted transition probabilities from the non-stationary model.](discrete-markov_files/figure-html/fig-non-stationary-1.png){#fig-non-stationary width=1152}\n:::\n:::\n\n\n\n\n### Estimated transition matrices\n\nLet's visualize the estimated time-varying transition matrices @fig-non-stationary-matrix-plot\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Check out my code\"}\n# Create prediction grid for each time point\ntime_points <- unique(data_stack$wave)\nstate_names <- c(\"Normal Cognition\", \"MCI\", \"Dementia\")\n\n# Get matrices for all time points\ntime_varying_matrices <- purrr::map(\n  setNames(time_points, paste(time_points, \"Years\")),\n  ~ get_time_varying_matrix(fit_4a, .x)\n)\n\n# Converting into a tidy data frame\nnon_stationary_matrices <- purrr::imap_dfr(\n  time_varying_matrices,\n  ~ as.data.frame(.x) |> \n    tibble::rownames_to_column(\"From\") |> \n    pivot_longer(-From, names_to = \"To\", values_to = \"probability\") |> \n    mutate(Time = .y),\n  .id = \"Time_point\"\n) |> \n  mutate(\n    From = factor(From, levels = state_names),\n    To = factor(To, levels = rev(state_names)),\n    Time_point = forcats::fct_inorder(Time_point)\n  )\n\n# Plotting \nnon_stationary_matrices |>\nggplot(aes(x = From, y = To, fill = probability)) +\n  geom_tile(color = \"white\", linewidth = 0.5) +\n  geom_text(\n    aes(label = format(round(probability, 3), nsmall = 3)),\n    size = 4.5, \n    color = \"#212427\",\n    fontface = \"bold\") +\n    colorspace::scale_fill_continuous_diverging(\n    palette = \"Blue-Red 3\", mid = 0.50, alpha = 0.5, \n    limits = c(0, 1), name = \"Transition \\nProbability\") +\n  labs(\n    title = \"Estimated Time-Varying Transition Matrices\",\n    subtitle = \"Showing changes in transition probabilities over time\",\n    x = \"Previous State (t-1)\",\n    y = \"Next State (t)\",\n    fill = \"Probability\"\n  ) +\n  facet_wrap(~ Time_point, ncol = 3, labeller = labeller(\n    Time_point = function(x){\n      case_when(x == \"2 Years\" ~ \"2018\",\n                x == \"3 Years\" ~ \"2020\",\n                x == \"4 Years\" ~ \"2022\")\n    })) +\n  theme(\n    axis.text = element_text(size = 10),\n    axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1),\n    legend.position = \"right\",\n    legend.text = element_text(size = 9),\n    panel.grid = element_blank()\n  )\n```\n\n::: {.cell-output-display}\n![Estimated time-varying transition matrices.](discrete-markov_files/figure-html/fig-non-stationary-matrix-plot-1.png){#fig-non-stationary-matrix-plot width=1152}\n:::\n:::\n\n\n\n\n# Matrix distance metrics\n\nGiven two matrices $P = (p_{ij})$ and $\\hat{P} = (\\hat{p}_{ij})$ of size $m \\times n$, we define the following distance measures\n\n**Frobenius Norm (Matrix Euclidean Distance)**\n\n$$D_{\\text{Frobenius}}(P, \\hat{P}) = \\|P - \\hat{P}\\|_F = \\sqrt{\\sum_{i=1}^{m}\\sum_{j=1}^{n} |p_{ij} - \\hat{p}_{ij}|^2}$$\n \n- Measures the Euclidean distance in matrix space\n- Sensitive to large differences due to squaring\n- Equivalent to the vector 2-norm of the flattened matrix\n\n**Manhattan Distance (L1 Norm)**\n\n$$D_{\\text{Manhattan}}(P, \\hat{P}) = \\sum_{i=1}^{m}\\sum_{j=1}^{n} |p_{ij} - \\hat{p}_{ij}|$$\n\n- Sum of absolute differences between corresponding elements\n- Less sensitive to outliers than Frobenius norm\n- Useful when sparse differences are important\n\n**Maximum Difference (Infinity Norm)**\n\n$$D_{\\text{Max}}(A, B) = \\max_{\\substack{1 \\leq i \\leq m \\\\ 1 \\leq j \\leq n}} |a_{ij} - b_{ij}|$$\n\n- Captures the single largest difference between elements\n- Useful for worst-case analysis\n- Ignores the distribution of other differences\n\n**Mean Absolute Difference**\n\n$$D_{\\text{MeanAbs}}(P, \\hat{P}) = \\frac{1}{mn}\\sum_{i=1}^{m}\\sum_{j=1}^{n} |p_{ij} - \\hat{p}_{ij}|$$\n\n- Average absolute difference across all elements\n- Scales with matrix size (unlike Manhattan distance)\n- Easy to interpret as average error per element\n\n**Root Mean Square Error (RMSE)**\n\n$$D_{\\text{RMSE}}(P, \\hat{P}) = \\sqrt{\\frac{1}{mn}\\sum_{i=1}^{m}\\sum_{j=1}^{n} (p_{ij} - \\hat{p}_{ij})^2}$$\n\n- Similar to Frobenius but normalized by matrix size\n-  Sensitive to large errors due to squaring\n- Common in statistical and machine learning applications\n\n**Correlation-Based Distance**\n\n$$D_{\\text{Corr}}(P, \\hat{P}) = 1 - \\frac{\\sum_{i=1}^{m}\\sum_{j=1}^{n} (p_{ij} - \\bar{P})(\\hat{p}_{ij} - \\bar{\\hat{P}})}{\\sqrt{\\sum_{i=1}^{m}\\sum_{j=1}^{n} (p_{ij} - \\bar{P})^2 \\sum_{i=1}^{m}\\sum_{j=1}^{n} (\\hat{p}_{ij} - \\bar{\\hat{p}})^2}}$$\n\n- Measures linear relationship between matrix elements\n- $\\bar{P} = \\frac{1}{mn}\\sum_{i,j}p_{ij}$ (mean of all elements in $P$)\n- $\\bar{\\hat{P}} = \\frac{1}{mn}\\sum_{i,j}\\hat{p}_{ij}$ (mean of all elements in $\\hat{P}$)\n- Range: [0,2] where 0 = perfect positive correlation\n\n**Kullback-Leibler Divergence**\n\nFor matrices where each row sums to 1 ($\\sum_j p_{ij} = \\sum_j \\hat{P}_{ij} = 1$) and $p_{ij}, \\hat{p}_{ij} > 0$:\n\n$$\nD_{\\text{KL}}(P \\parallel \\hat{P}) = \\sum_{i=1}^{m}\\sum_{j=1}^{n} p_{ij} \\log\\left(\\frac{p_{ij}}{\\hat{p}_{ij}}\\right)\n$$\n\n- Measures information loss when $\\hat{P}$ approximates $P$\n- Asymmetric: $D_{\\text{KL}}(P \\parallel \\hat{P}) \\neq D_{\\text{KL}}(\\hat{P} \\parallel P)$\n- $0\\log0 = 0$ by convention\n- In practice, add $\\epsilon > 0$ (e.g., $10^{-10}$) to avoid zeros\n\n## Implementation\n\nLet's calculate the distance metrics between the observed $P$ and estimated transition matrices $\\hat{P}$.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\np       <- transition_matrix_observed\np_hat   <- transition_matrix_estimated\nepsilon <- 1e-10\n\n# Creating tibble of distance metrics\ndistances <- tibble(\n  Metric = c(\"Frobenius\", \"Manhattan\", \"Max\", \"MeanAbs\", \"RMSE\", \"Correlation\", \"KL\"),\n  Value = c(\n    norm(p - p_hat, type = \"F\"),\n    sum(abs(p - p_hat)),\n    max(abs(p - p_hat)),\n    mean(abs(p - p_hat)),\n    sqrt(mean((p - p_hat)^2)),\n    1 - cor(c(p), c(p_hat)),\n    sum((p + epsilon) * log((p + epsilon) / (p_hat + epsilon)))\n  )) |>\n  mutate(Value = round(Value, 4))\n\ndistances |>\n  mutate(Metric = case_when(\n    Metric == \"Frobenius\" ~ \"Frobenius Distance\",\n    Metric == \"Manhattan\" ~ \"Manhattan Distance\",\n    Metric == \"Max\" ~ \"Max Difference\",\n    Metric == \"MeanAbs\" ~ \"Mean Absolute Difference\",\n    Metric == \"RMSE\" ~ \"Root Mean Square Error\",\n    Metric == \"Correlation\" ~ \"Correlation Distance\",\n    Metric == \"KL\" ~ \"Kullback-Leibler Divergence\"\n  )) |>\n  knitr::kable(caption = \"Distance based metrics\", align = \"c\") |>\n  kableExtra::kable_styling(\n    bootstrap_options = c(\"striped\", \"hover\"),\n    full_width = FALSE)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n<caption>Distance based metrics</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:center;\"> Metric </th>\n   <th style=\"text-align:center;\"> Value </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:center;\"> Frobenius Distance </td>\n   <td style=\"text-align:center;\"> 0.2165 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> Manhattan Distance </td>\n   <td style=\"text-align:center;\"> 0.4814 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> Max Difference </td>\n   <td style=\"text-align:center;\"> 0.1320 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> Mean Absolute Difference </td>\n   <td style=\"text-align:center;\"> 0.0535 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> Root Mean Square Error </td>\n   <td style=\"text-align:center;\"> 0.0722 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> Correlation Distance </td>\n   <td style=\"text-align:center;\"> 0.0166 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> Kullback-Leibler Divergence </td>\n   <td style=\"text-align:center;\"> 0.0811 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\n\n## Visualisation\n\nLet's visualize the distance metrics between the observed and estimated transition matrices (@fig-metrics).\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Check out my code\"}\ncaption = stringr::str_glue(\n  \"**RMSE:** Root Mean Squared Error\\n\n   **KL:** Kullback-Leibler Divergence\\n\n   **Correlation:** 1 - Pearson Correlation Coefficient\")\n\ndistances |>\n  ggplot(aes(x = reorder(Metric, -Value), y = Value, fill = Metric)) +\n  geom_col(colour = \"black\") +\n  geom_text(aes(label = Value), vjust = -0.5) +\n  ggokabeito::scale_fill_okabe_ito() +\n  scale_y_continuous(expand = expansion(mult = c(0.075, 0.075))) +\n  labs(\n    title = \"Distance Between Transition Matrices\",\n    x = \"Distance Metric\",\n    y = \"Value\",\n    caption = caption) +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(hjust = 0.5, size = 14, face = \"bold\"),\n    axis.title = element_text(face = \"bold\", size = 12),\n    plot.caption = ggtext::element_markdown(size = 10),\n    legend.position = \"none\")\n```\n\n::: {.cell-output-display}\n![Distance metrics between observed and estimated transition matrices.](discrete-markov_files/figure-html/fig-metrics-1.png){#fig-metrics width=1152}\n:::\n:::\n",
    "supporting": [
      "discrete-markov_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n<link href=\"../site_libs/htmltools-fill-0.5.8.1/fill.css\" rel=\"stylesheet\" />\n<script src=\"../site_libs/htmlwidgets-1.6.4/htmlwidgets.js\"></script>\n<link href=\"../site_libs/datatables-css-0.0.0/datatables-crosstalk.css\" rel=\"stylesheet\" />\n<script src=\"../site_libs/datatables-binding-0.33/datatables.js\"></script>\n<script src=\"../site_libs/jquery-3.6.0/jquery-3.6.0.min.js\"></script>\n<link href=\"../site_libs/dt-core-1.13.6/css/jquery.dataTables.min.css\" rel=\"stylesheet\" />\n<link href=\"../site_libs/dt-core-1.13.6/css/jquery.dataTables.extra.css\" rel=\"stylesheet\" />\n<script src=\"../site_libs/dt-core-1.13.6/js/jquery.dataTables.min.js\"></script>\n<link href=\"../site_libs/crosstalk-1.2.1/css/crosstalk.min.css\" rel=\"stylesheet\" />\n<script src=\"../site_libs/crosstalk-1.2.1/js/crosstalk.min.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}
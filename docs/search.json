[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Procrastination and Dementia",
    "section": "",
    "text": "Abstract\nThis will come eventually"
  },
  {
    "objectID": "analysis/hypothesis.html",
    "href": "analysis/hypothesis.html",
    "title": "Hypotheses",
    "section": "",
    "text": "Primary Hypothesis\nWe hypothesize that:\n\nH1: Higher levels of procrastination are associated with:\n\nIncreased risk of transitioning from Normal Cognition to MCI (\\beta = x, p &lt; .05)\nIncreased risk of transitioning from MCI to Dementia (\\beta = y, p &lt; .05)\n\nH0: There is no association between procrastination and cognitive decline transitions\n\nIn order to test this hypothesis we will be using a discrete time Markov Model",
    "crumbs": [
      "Analysis",
      "Hypothesis",
      "Hypotheses"
    ]
  },
  {
    "objectID": "analysis/data-overview.html",
    "href": "analysis/data-overview.html",
    "title": "Data Overview",
    "section": "",
    "text": "The Health and Retirement Study (HRS) collects an extensive array of data related to cognitive health, physical well-being, economic status, and psychosocial factors. Among the information gathered, specific variables are used to assess and classify individuals into distinct categories of cognitive functioning. These classifications help to better understand the progression of cognitive decline, enabling researchers to track trends and identify factors that may influence cognitive health over time.\n\n\n\nNormal Cognition: Individuals in this category show no significant signs of cognitive impairment and are able to function independently in daily activities.\nMild Cognitive Impairment (MCI): This stage reflects a slight but noticeable decline in cognitive abilities, such as memory or thinking skills, that goes beyond what would be expected with normal aging but does not yet interfere significantly with daily life.\nDementia: This classification is marked by more severe cognitive deficits, impacting memory, reasoning, and the ability to perform everyday tasks. Dementia encompasses various neurodegenerative conditions, with Alzheimer’s disease being the most common.\n\nBy tracking transitions between these categories, researchers can gain insights into the factors that contribute to cognitive decline and identify potential interventions to promote healthy aging.",
    "crumbs": [
      "Data",
      "Data Overview"
    ]
  },
  {
    "objectID": "analysis/data-overview.html#overview",
    "href": "analysis/data-overview.html#overview",
    "title": "Data Overview",
    "section": "",
    "text": "The Health and Retirement Study (HRS) collects an extensive array of data related to cognitive health, physical well-being, economic status, and psychosocial factors. Among the information gathered, specific variables are used to assess and classify individuals into distinct categories of cognitive functioning. These classifications help to better understand the progression of cognitive decline, enabling researchers to track trends and identify factors that may influence cognitive health over time.\n\n\n\nNormal Cognition: Individuals in this category show no significant signs of cognitive impairment and are able to function independently in daily activities.\nMild Cognitive Impairment (MCI): This stage reflects a slight but noticeable decline in cognitive abilities, such as memory or thinking skills, that goes beyond what would be expected with normal aging but does not yet interfere significantly with daily life.\nDementia: This classification is marked by more severe cognitive deficits, impacting memory, reasoning, and the ability to perform everyday tasks. Dementia encompasses various neurodegenerative conditions, with Alzheimer’s disease being the most common.\n\nBy tracking transitions between these categories, researchers can gain insights into the factors that contribute to cognitive decline and identify potential interventions to promote healthy aging.",
    "crumbs": [
      "Data",
      "Data Overview"
    ]
  },
  {
    "objectID": "analysis/data-overview.html#langa-weir-classifications",
    "href": "analysis/data-overview.html#langa-weir-classifications",
    "title": "Data Overview",
    "section": "Langa-Weir Classifications",
    "text": "Langa-Weir Classifications\nFor previous waves of HRS data (1995 - 2020) there is a researcher contributed dataset of dementia classifications [@langa2023]. Researchers have used this dataset to study the trajectories of cognitive aging, dementia risk, and related health outcomes in older adults. However, with the recent release of the 2022 HRS data, these classifications have yet to be updated\n\nLWC2022 Package\nIn order to address this we developed the LWC2022 package [@Monaghan2024] to replicate the methodology of @langa2023. This package automates the classification process, ensuring consistency with previous waves and providing researchers with an up-to-date resource for studying cognitive decline and dementia across all available HRS waves. Figure 1 illustrates the LWC workflow.\n\n\n\n\n\n\nFigure 1: LWC Workflow",
    "crumbs": [
      "Data",
      "Data Overview"
    ]
  },
  {
    "objectID": "analysis/data-exploration.html",
    "href": "analysis/data-exploration.html",
    "title": "Exploratory Data Analysis",
    "section": "",
    "text": "Check our my packages\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(ggplot2)\nlibrary(ggalluvial)\n\n\n\n\n\n\n\nCheck our my functions\ncount_transitions &lt;- function(data, years, absorbing = FALSE) {\n  # Counts the occurrences of cognitive status transitions across specified \n  # years.\n  # Converts numeric cognitive status codes (1, 2, 3) into descriptive labels\n  # (\"Normal Cognition\", \"MCI\", \"Dementia\") and handles missing or unexpected values.\n  # Aggregates the data to count transitions and reshapes it into a long format for analysis.\n  # Arguments:\n  #    - data: The input dataset containing cognitive function data.\n  #    - years: A vector of years for which transitions should be counted.\n  # Returns:\n  #   - A dataset with counts of cognitive status transitions, including\n  #   \"Missing\" and \"Other\" categories.\n  \n  # Create dynamic column names based on the years provided\n  cogfunction_cols &lt;- paste0(\"cogfunction\", years)\n  \n  data &lt;- data |&gt;\n    select(ID, all_of(cogfunction_cols)) |&gt;\n    na.omit() |&gt;\n    tidyr::pivot_longer(\n      cols = !ID,\n      names_to = \"Wave\",\n      values_to = \"Classification\"\n    ) |&gt;\n    mutate(\n      Wave = stringr::str_replace(Wave, \"cogfunction\", \"HRS \"),\n      Wave = factor(Wave, levels = c(paste0(\"HRS \", years))),\n      \n      Classification = case_when(\n        Classification == 1 ~ \"Normal Cognition\",\n        Classification == 2 ~ \"MCI\",\n        Classification == 3 ~ \"Dementia\")\n    )\n  \n  if(absorbing == TRUE){\n    data &lt;- data |&gt;\n      group_by(ID) |&gt;\n      mutate(\n        Classification = ifelse(\n          cumany(Classification == \"Dementia\"), \"Dementia\", Classification)) |&gt;\n      ungroup()\n  }\n  \n  data &lt;- data |&gt;\n    mutate(Classification = factor(\n      Classification,\n      levels = c(\"Normal Cognition\", \"MCI\", \"Dementia\")))\n  \n  return(data)\n}\n\nplot_cognitive_scores &lt;- function(data, year) {\n  # Plots the distribution of cognitive scores over a range of years.\n  # Converts the data from wide to long format and generates histograms for each wave.\n  # Arguments:\n  #   - data: The dataset containing cognitive scores.\n  #   - year: The starting year for the range of cognitive scores to plot.\n  # Returns:\n  #   - A ggplot object showing the distribution of cognitive scores across waves.\n  # Plotting dementia transitions\n  data |&gt;\n    select(ID, any_of(paste0(\"cogtot27_imp\", year:2022))) |&gt;\n    na.omit() |&gt;\n    tidyr::pivot_longer(cols = !ID,\n                        names_to = \"Wave\",\n                        values_to = \"Score\") |&gt;\n    mutate(Wave = as.double(stringr::str_replace(Wave, \"cogtot27_imp\", \"\"))) |&gt;\n    ggplot(aes(x = Score)) +\n    geom_histogram(fill = \"#56B4E9\",\n                   colour = \"black\",\n                   alpha = 0.5) +\n    scale_x_continuous(breaks = seq(0, 27, by = 3)) +\n    labs(\n      title = paste0(\"Distribution of cognitive scores \", year, \"- 2022\"),\n      x = \"Cognitive Score\", y = \"\") +\n    facet_wrap( ~ Wave)\n}\n\nplot_transitions &lt;- function(data, size) {\n  # Visualizes cognitive status transitions over time using an alluvial plot.\n  # Represents the flow of individuals between cognitive states across waves.\n  # Arguments:\n  #   - data: The dataset containing transition data.\n  #   - size: The font size for labels in the plot.\n  # Returns:\n  #   - A ggplot object showing transitions between cognitive states over time.\n  \n  require(ggalluvial)\n  \n  data |&gt;\n    ggplot(aes(x = Wave, y = n, stratum = Classification, \n               fill = Classification, alluvium = ID\n    )) +\n    geom_stratum(alpha = 0.5, width = 0.5) +\n    geom_flow(width = 0.5) +\n    geom_text(\n      stat = \"stratum\",\n      aes(label = stringr::str_wrap(Classification, width = 10)),\n      hjust = 0.5,\n      vjust = 0.5,\n      size = size\n    ) +\n    labs(title = \"Dementia transitions across time\", \n         x = \"\", y = \"Frequency\") +\n    scale_fill_viridis_d(direction = -1) +\n    theme(axis.text = element_text(size = 10), \n          text = element_text(size = 10)) +\n    ggeasy::easy_remove_legend()\n}\n\n\n\n\n\n\n\nCheck our my theme\ncolour = \"#212427\"\n\ntheme_set(\ntheme_minimal() +\n  theme(\n    panel.grid = element_blank(),\n    plot.title = element_text(hjust = 0.5, size = 14, face = \"bold\", colour = colour),\n    plot.subtitle = element_text(hjust = 0.5, size = 10, colour = colour),\n    axis.title = element_text(size = 10, face = \"bold\", colour = colour),\n    strip.text = element_text(size = 10, face = \"bold\", colour = colour)\n    ))\n\n\n\n\n\n\ndata &lt;- read.csv(here::here(\"analysis/data/data.csv\"))",
    "crumbs": [
      "Data",
      "Exploration",
      "Exploratory Data Analysis"
    ]
  },
  {
    "objectID": "analysis/data-exploration.html#setting-up",
    "href": "analysis/data-exploration.html#setting-up",
    "title": "Exploratory Data Analysis",
    "section": "",
    "text": "Check our my packages\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(ggplot2)\nlibrary(ggalluvial)\n\n\n\n\n\n\n\nCheck our my functions\ncount_transitions &lt;- function(data, years, absorbing = FALSE) {\n  # Counts the occurrences of cognitive status transitions across specified \n  # years.\n  # Converts numeric cognitive status codes (1, 2, 3) into descriptive labels\n  # (\"Normal Cognition\", \"MCI\", \"Dementia\") and handles missing or unexpected values.\n  # Aggregates the data to count transitions and reshapes it into a long format for analysis.\n  # Arguments:\n  #    - data: The input dataset containing cognitive function data.\n  #    - years: A vector of years for which transitions should be counted.\n  # Returns:\n  #   - A dataset with counts of cognitive status transitions, including\n  #   \"Missing\" and \"Other\" categories.\n  \n  # Create dynamic column names based on the years provided\n  cogfunction_cols &lt;- paste0(\"cogfunction\", years)\n  \n  data &lt;- data |&gt;\n    select(ID, all_of(cogfunction_cols)) |&gt;\n    na.omit() |&gt;\n    tidyr::pivot_longer(\n      cols = !ID,\n      names_to = \"Wave\",\n      values_to = \"Classification\"\n    ) |&gt;\n    mutate(\n      Wave = stringr::str_replace(Wave, \"cogfunction\", \"HRS \"),\n      Wave = factor(Wave, levels = c(paste0(\"HRS \", years))),\n      \n      Classification = case_when(\n        Classification == 1 ~ \"Normal Cognition\",\n        Classification == 2 ~ \"MCI\",\n        Classification == 3 ~ \"Dementia\")\n    )\n  \n  if(absorbing == TRUE){\n    data &lt;- data |&gt;\n      group_by(ID) |&gt;\n      mutate(\n        Classification = ifelse(\n          cumany(Classification == \"Dementia\"), \"Dementia\", Classification)) |&gt;\n      ungroup()\n  }\n  \n  data &lt;- data |&gt;\n    mutate(Classification = factor(\n      Classification,\n      levels = c(\"Normal Cognition\", \"MCI\", \"Dementia\")))\n  \n  return(data)\n}\n\nplot_cognitive_scores &lt;- function(data, year) {\n  # Plots the distribution of cognitive scores over a range of years.\n  # Converts the data from wide to long format and generates histograms for each wave.\n  # Arguments:\n  #   - data: The dataset containing cognitive scores.\n  #   - year: The starting year for the range of cognitive scores to plot.\n  # Returns:\n  #   - A ggplot object showing the distribution of cognitive scores across waves.\n  # Plotting dementia transitions\n  data |&gt;\n    select(ID, any_of(paste0(\"cogtot27_imp\", year:2022))) |&gt;\n    na.omit() |&gt;\n    tidyr::pivot_longer(cols = !ID,\n                        names_to = \"Wave\",\n                        values_to = \"Score\") |&gt;\n    mutate(Wave = as.double(stringr::str_replace(Wave, \"cogtot27_imp\", \"\"))) |&gt;\n    ggplot(aes(x = Score)) +\n    geom_histogram(fill = \"#56B4E9\",\n                   colour = \"black\",\n                   alpha = 0.5) +\n    scale_x_continuous(breaks = seq(0, 27, by = 3)) +\n    labs(\n      title = paste0(\"Distribution of cognitive scores \", year, \"- 2022\"),\n      x = \"Cognitive Score\", y = \"\") +\n    facet_wrap( ~ Wave)\n}\n\nplot_transitions &lt;- function(data, size) {\n  # Visualizes cognitive status transitions over time using an alluvial plot.\n  # Represents the flow of individuals between cognitive states across waves.\n  # Arguments:\n  #   - data: The dataset containing transition data.\n  #   - size: The font size for labels in the plot.\n  # Returns:\n  #   - A ggplot object showing transitions between cognitive states over time.\n  \n  require(ggalluvial)\n  \n  data |&gt;\n    ggplot(aes(x = Wave, y = n, stratum = Classification, \n               fill = Classification, alluvium = ID\n    )) +\n    geom_stratum(alpha = 0.5, width = 0.5) +\n    geom_flow(width = 0.5) +\n    geom_text(\n      stat = \"stratum\",\n      aes(label = stringr::str_wrap(Classification, width = 10)),\n      hjust = 0.5,\n      vjust = 0.5,\n      size = size\n    ) +\n    labs(title = \"Dementia transitions across time\", \n         x = \"\", y = \"Frequency\") +\n    scale_fill_viridis_d(direction = -1) +\n    theme(axis.text = element_text(size = 10), \n          text = element_text(size = 10)) +\n    ggeasy::easy_remove_legend()\n}\n\n\n\n\n\n\n\nCheck our my theme\ncolour = \"#212427\"\n\ntheme_set(\ntheme_minimal() +\n  theme(\n    panel.grid = element_blank(),\n    plot.title = element_text(hjust = 0.5, size = 14, face = \"bold\", colour = colour),\n    plot.subtitle = element_text(hjust = 0.5, size = 10, colour = colour),\n    axis.title = element_text(size = 10, face = \"bold\", colour = colour),\n    strip.text = element_text(size = 10, face = \"bold\", colour = colour)\n    ))\n\n\n\n\n\n\ndata &lt;- read.csv(here::here(\"analysis/data/data.csv\"))",
    "crumbs": [
      "Data",
      "Exploration",
      "Exploratory Data Analysis"
    ]
  },
  {
    "objectID": "analysis/data-exploration.html#dementia-dataset",
    "href": "analysis/data-exploration.html#dementia-dataset",
    "title": "Exploratory Data Analysis",
    "section": "Dementia Dataset",
    "text": "Dementia Dataset\nOur updated dataset contains 13 columns of cognitive classifications spanning from 1996 to 2022. These columns reflect dementia status across each wave, using the same criteria and structure as the original Langa-Weir dataset, now extended to include the most recent 2022 wave.\n\ndementia_data &lt;- data |&gt;\n  count_transitions(years = seq(1996, 2022, by = 2))\n\nglimpse(dementia_data)\n\nRows: 2,296\nColumns: 3\n$ ID             &lt;int&gt; 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3…\n$ Wave           &lt;fct&gt; HRS 1996, HRS 1998, HRS 2000, HRS 2002, HRS 2004, HRS 2…\n$ Classification &lt;fct&gt; Normal Cognition, Normal Cognition, Normal Cognition, N…\n\n\n\nMissing data\nSince the participant pool is drawn from the 2020 wave of the HRS data, any analysis that looks back at previous waves will inevitably encounter missing data. Not all participants were included in earlier waves, leading to gaps in the data. Figure 1 displays the frequency of missing cognitive test data across each HRS wave.\n\n# Dynamic colours\ncolours &lt;- c(rep(\"#2e2e2e\", times = 12), \"red\", \"#2e2e2e\")\n\ndata |&gt;\n  select(any_of(paste0(\"cogtot27_imp\", 1996:2022))) |&gt;\n  rename_with( ~ stringr::str_replace(., \"cogtot27_imp\", \"\"), starts_with(\"cogtot27\")) |&gt;\n  visdat::vis_dat() +\n  labs(title = \"Missing data across HRS Waves (1996 - 2022)\",\n       subtitle = \"Total Cognitive Scores\") +\n  theme(\n    plot.title = element_text(hjust = 0.5, size = 14, face = \"bold\", colour = colour),\n    plot.subtitle = element_text(hjust = 0.5, size = 12, face = \"bold\", colour = colour),\n    panel.grid = element_blank(),\n    axis.text.x = element_text(colour = colours)) +\n  ggeasy::easy_remove_legend() +\n  ggeasy::easy_x_axis_labels_size(size = 9)\n\n\n\n\n\n\n\nFigure 1: Occurance of missing data across HRS waves (participants were gathered from the 2020 HRS wave [in red])\n\n\n\n\n\nThe HRS had its most recent participant intake in 2016, which explains the notable decline in missing data occurrences from that point onward. As new participants were not added after 2016, the dataset becomes more complete in subsequent waves, with fewer missing values.\nGiven this shift, we will conduct our analysis the reduced dataset (2016 - 2022) (Figure 2) along with removing the missing values from 2016 and 2018.\n\ndata |&gt;\n  select(any_of(paste0(\"cogtot27_imp\", 2016:2022))) |&gt;\n  rename_with( ~ stringr::str_replace(., \"cogtot27_imp\", \"\"), starts_with(\"cogtot27\")) |&gt;\n  na.omit() |&gt;\n  visdat::vis_dat() +\n  labs(\n    title = \"Complete dataset across HRS Waves (2016 - 2022)\",\n    subtitle = \"Total Cognitive Scores\") +\n    theme(\n    plot.title = element_text(hjust = 0.5, size = 14, face = \"bold\", colour = colour),\n    plot.subtitle = element_text(hjust = 0.5, size = 12, face = \"bold\", colour = colour),\n    panel.grid = element_blank()) +\n  ggeasy::easy_remove_legend() +\n  ggeasy::easy_x_axis_labels_size(size = 9)\n\n\n\n\n\n\n\nFigure 2: HRS dataset after processing\n\n\n\n\n\n\n\nExploratory Data Analysis\n\nCognitive Test Scores\nInitially, we will plot a distribution of the cognitive test scores (ranging from 0 - 27) across time for all HRS participants.\n\nplot_cognitive_scores(data = data, year = 2016)\n\n\n\n\n\n\n\nFigure 3: Cognitive test scores (2016 - 2022)\n\n\n\n\n\n\n\nClassification proportion per year\nFigure 4 shows the proportion of dementia classifications from HRS 2016 - 2022. The variable Missing represents the procrastination HRS respondents who were not yet interviewed by the HRS. Since the analysis focuses on participants included in the 2020 HRS wave, any retroactive analysis of prior waves may result in missing data for certain individuals\n\n# Plotting proportions --------------------------------------------------------\ndata |&gt;\n  count_transitions(years = seq(2016, 2022, by = 2), absorbing = TRUE) |&gt;\n  ggplot(aes(x = Wave, fill = Classification)) +\n  geom_bar(position = \"fill\", alpha = 0.5, colour = \"black\") +\n  scale_y_continuous(labels = scales::percent) +\n  labs(title = \"Proportion of Cognitive Status Classifications (2016 - 2022)\", \n       x = \"\", y = \"Percentage\") +\n  scale_fill_viridis_d(direction = -1) +\n  theme(\n    axis.text = element_text(size = 10),\n    text = element_text(size = 10)) +\n  ggeasy::easy_move_legend(\"bottom\") +\n  ggeasy::easy_remove_legend_title()\n\n\n\n\n\n\n\nFigure 4: Proportion of dementia classifications per year\n\n\n\n\n\n\n\nDementia transitions per year\nFigure 5 is an alluvial graph illustrating the transitions in cognitive classifications from one HRS wave to the next.\n\ndata |&gt;\n  count_transitions(years = seq(2016, 2022, by = 2)) |&gt;\n  group_by(ID, Wave) |&gt;\n  reframe(plyr::count(Classification)) |&gt;\n  rename(Classification = x, n = freq) |&gt;\n  plot_transitions(size = 2.5)\n\n\n\n\n\n\n\nFigure 5: Dementia transitions (2016 - 2022)\n\n\n\n\n\nFrom this figure we can see that some individuals classified with dementia in one wave transition out of dementia in a subsequent wave. Let’s fix this by adding an additional parameter to our count_transitions() function to turn dementia into an absorbing state (Figure 6). We can do this by using the cumany() function from the dplyr [@Wickham2023] package.\n\ndata |&gt;\n  count_transitions(years = seq(2016, 2022, by = 2), absorbing = TRUE) |&gt;\n  group_by(ID, Wave) |&gt;\n  reframe(plyr::count(Classification)) |&gt;\n  rename(Classification = x, n = freq) |&gt;\n  plot_transitions(size = 2.5)\n\n\n\n\n\n\n\nFigure 6: Dementia transitions with dementia as an absorbing state (2016 - 2022)",
    "crumbs": [
      "Data",
      "Exploration",
      "Exploratory Data Analysis"
    ]
  },
  {
    "objectID": "analysis/continous-markov.html",
    "href": "analysis/continous-markov.html",
    "title": "Continous Time Markov Model",
    "section": "",
    "text": "Check our my packages\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(ggplot2)\n\n\n\n\n\n\n\nCheck our my functions\nextract_years &lt;- function(data, years, impute = TRUE, cog_total = FALSE, absorbing = TRUE) {\n  # Extracts cognitive function data for specified years from a dataset.\n  # Converts numeric cognitive status codes (1, 2, 3) into descriptive labels\n  # (\"Normal Cognition\", \"MCI\", \"Dementia\") for easier interpretation.\n  # Arguments:\n  #   - data: The input dataset containing cognitive function data.\n  #   - years: A vector of years for which data should be extracted.\n  # Returns:\n  #   - A dataset with ID and cognitive status columns for the specified years.\n  \n  # Create dynamic column names based on the years provided\n  cogfunction_cols &lt;- paste0(\"cogfunction\", years)\n  cogtotal_cols    &lt;- paste0(\"cogtot27_imp\", years)\n  \n  if(cog_total == FALSE) {\n  data &lt;- data |&gt;\n    # Select only the ID column and cognitive function columns for the specified years\n    select(ID, any_of(cogfunction_cols)) |&gt;\n    mutate(across(!c(ID), ~ case_when(\n      .x == 1 ~ \"Normal Cognition\",\n      .x == 2 ~ \"MCI\",\n      .x == 3 ~ \"Dementia\",\n      TRUE ~ NA_character_  # To handle missing/other cases\n    )))\n  } else {\n    data &lt;- data |&gt;\n      # Select only the ID column and cognitive function columns for the specified years\n      select(ID, any_of(cogtotal_cols)) |&gt;\n      rename_with( .cols = !ID, .fn = ~ stringr::str_replace(\n        string = .x,\n        pattern = \"cogtot27_imp\", \n        replacement = \"cog_score_\"))\n  }\n  \n  if(impute == TRUE){\n    data &lt;- data |&gt;\n      tidyr::pivot_longer(\n        cols = !ID,\n        names_to = \"Wave\",\n        values_to = \"Status\") |&gt;\n      group_by(ID) |&gt;\n      tidyr::fill(Status, .direction = \"down\") |&gt;\n      ungroup() |&gt;\n      tidyr::pivot_wider(names_from = \"Wave\", values_from = \"Status\")\n  }\n  \n  if(absorbing == TRUE) {\n    data &lt;- data |&gt;\n      tidyr::pivot_longer(\n        cols = !ID,\n        names_to = \"Wave\",\n        values_to = \"Status\") |&gt;\n      group_by(ID) |&gt;\n      mutate(Status = ifelse(cumany(Status == \"Dementia\"), \"Dementia\", Status)) |&gt;\n      ungroup() |&gt;\n      tidyr::pivot_wider(names_from = \"Wave\", values_from = \"Status\")\n  }\n  \n  return(data)\n}\n\ncreate_transitions &lt;- function(data, absorbing = FALSE){\n  # Reshapes data from wide to long format to track cognitive status transitions over time.\n  # Calculates the next wave's cognitive status for each individual and creates a transition column.\n  # Optionally treats \"Dementia\" as an absorbing state, meaning once an individual is classified\n  # with dementia, their status cannot change in subsequent waves.\n  # Arguments:\n  #   - data: The dataset containing cognitive status data.\n  #   - absorbing: A logical flag indicating whether \"Dementia\" should be treated \n  #   as an absorbing state.\n  # Returns:\n  #   - A dataset with transition information, including current and next wave statuses.\n  \n  # Reshape the data from wide to long format to track cognitive status over waves\n  data &lt;- data |&gt;\n    select(ID, starts_with(\"cogfunction\")) |&gt;\n    tidyr::pivot_longer(cols = !ID,\n                        names_to = \"Wave\",\n                        values_to = \"Status\") |&gt;\n    mutate(Wave = as.factor(stringr::str_replace(Wave, \"cogfunction\", \"\"))) |&gt;\n    # Arrange by ID and Wave to prepare for transition calculation\n    arrange(ID, Wave) |&gt;\n    group_by(ID) |&gt;\n    # Get the next wave's cognitive status for each person\n    mutate(next_wave_status = lead(Status)) |&gt;\n    ungroup()\n  \n  # We can optionally specify dementia as an absorbing state\n  # Once an individual is classified with dementia they cannot be classified\n  # with anything else \n  if(absorbing == TRUE) {\n    data &lt;- data |&gt;\n      group_by(ID) |&gt;\n      mutate(\n        Status = ifelse(cumany(Status == \"Dementia\"), \"Dementia\", Status),\n        next_wave_status = ifelse(cumany(Status == \"Dementia\"), \"Dementia\", next_wave_status),\n        transition = paste(Status, next_wave_status, sep = \" to \")\n      ) |&gt;\n      filter(Wave %in% c(2016, 2018, 2020))\n  }\n  \n  # Filter out rows where either the current or next status is missing\n  data &lt;- data |&gt;\n    group_by(ID) |&gt;\n    filter(!is.na(Status), !is.na(next_wave_status)) |&gt;\n    ungroup() |&gt;\n    # Create a new column representing the transition from one status to the next\n    mutate(\n      transition = paste(Status, next_wave_status, sep = \" to \"),\n      transition = factor(\n        transition, \n        levels = c(\"Normal Cognition to Normal Cognition\", \"Normal Cognition to MCI\",\n                   \"Normal Cognition to Dementia\", \"MCI to Normal Cognition\", \"MCI to MCI\",\n                   \"MCI to Dementia\", \"Dementia to Dementia\") \n        ))\n  \n  return(data)\n}\n\ncalculate_probabilties &lt;- function(data) {\n  # Calculates the proportion of each cognitive status transition in the dataset.\n  # Counts the occurrences of each transition and computes their relative probabilities.\n  # Arguments:\n  #   - data: The dataset containing transition information.\n  # Returns:\n  #   - A dataset with transition probabilities, split into \"from\" and \"to\" states.\n  \n  # Calculate the proportion of each transition by dividing by the total count\n  data |&gt;\n    count(transition) |&gt;\n    mutate(prop = n / sum(n)) |&gt;\n    tidyr::separate(transition, into = c(\"from\", \"to\"), sep = \" to \")\n}\n\ntransition_matrix &lt;- function(data, longitudinal = FALSE) {\n  # Constructs a transition matrix from the calculated transition probabilities.\n  # The matrix represents the probability of moving from one cognitive state to another.\n  # Arguments:\n  #   - data: The dataset containing transition probabilities.\n  #   - longitudinal: A TRUE/FALSE statement indicating if the probabilities are from multiple waves\n  # Returns:\n  #   - A transition matrix with rows representing \"from\" states and columns \n  #   representing \"to\" states.\n  \n  if(longitudinal == FALSE) {\n    # Defining empty matrix matrix\n    states &lt;- c(\"Normal Cognition\", \"MCI\", \"Dementia\")\n    \n    transition_matrix &lt;- matrix(\n      0,\n      nrow = length(states),\n      ncol = length(states),\n      dimnames = list(from_state = states, to_state = states))\n    \n    # Fill the transition matrix with probabilities\n    for (i in 1:nrow(data)) {\n      from &lt;- data$from[i]\n      to &lt;- data$to[i]\n      prob &lt;- data$prop[i]\n      \n      transition_matrix[from, to] &lt;- prob\n    }\n  } else if(longitudinal == TRUE){\n    \n    # Aggregate by 'from' and 'to' states to sum transition probabilities\n    data_agg &lt;- data |&gt;\n      group_by(from, to) |&gt;\n      summarise(transition_prob = sum(prop), .groups = \"drop\")\n    \n    transition_matrix &lt;- data_agg |&gt;\n      tidyr::pivot_wider(names_from = to, values_from = transition_prob, values_fill = 0) |&gt;\n      tibble::column_to_rownames(\"from\") |&gt;\n      as.matrix()\n  }\n  \n  return(transition_matrix)\n}\n\nplot_matrix &lt;- function(data, year, ts = FALSE) {\n  # Visualizes the transition matrix as a heatmap.\n  # Uses color gradients to represent transition probabilities and includes labels for clarity.\n  # Arguments:\n  #   - data: The transition matrix or dataset to plot.\n  #   - year: The year or time period associated with the data.\n  #   - ts: A logical flag indicating whether the title should include a time series label.\n  # Returns:\n  #   - A ggplot object representing the transition probabilities as a heatmap.\n  \n  if(ts == TRUE) {\n    title &lt;- paste0(\"Transition Probabilities Across Cognitive States - \", year)\n  } else {\n    title &lt;- paste0(\"Transition Probabilities Across Cognitive States (\", year, \"-2022)\")\n  }\n  \n  # Reshaping data for plotting\n  data &lt;- data |&gt;\n    as.data.frame(row.names = FALSE) |&gt;\n    mutate(from_state = c(\"Normal Cognition\", \"MCI\", \"Dementia\")) |&gt;\n    reshape2::melt(id.vars = \"from_state\", variable.name = \"to_state\", value.name = \"probability\")\n  \n  # Plotting probabilities\n  data |&gt;\n    ggplot(aes(x = from_state, y = to_state, fill = probability)) +\n    geom_tile() +\n    scale_fill_viridis_c(alpha = 0.8) +\n    labs(title = title,\n         x = \"To\", y = \"From\", fill = \"Prob\") +\n    geom_text(aes(label = round(probability, digits = 3)), size = 5) +\n    theme_minimal() +\n    theme(plot.title = element_text(hjust = 0.5, size = 12, face = \"bold\"),\n          axis.title = element_text(size = 10),\n          axis.text = element_text(size = 8),\n          panel.grid = element_blank()\n    )\n}\n\nnormalise &lt;- function(x) {\n  # Normalizes a matrix so that each row sums to 1.\n  # Arguments:\n  #   - x: The input matrix to normalize.\n  # Returns:\n  #   - A normalized matrix where each row sums to 1.\n  x / rowSums(x)\n}\n\nreshape_matrix &lt;- function(matrix, wave) {\n  # Reshapes a transition matrix into a long format for easier analysis and visualization.\n  # Adds a \"Wave\" column to identify the time period associated with the matrix.\n  # Arguments:\n  #   - matrix: The transition matrix to reshape.\n  #   - wave: The wave or time period associated with the matrix.\n  # Returns:\n  #   - A long-format dataset with \"from\", \"to\", and \"transition_prob\" columns.\n  \n  matrix |&gt;\n    as.data.frame() |&gt;\n    tibble::rownames_to_column(var = \"from\") |&gt;\n    tidyr::pivot_longer(cols = -from, names_to = \"to\", values_to = \"transition_prob\") |&gt;\n    mutate(Wave = wave)\n}\n\nplot_transition_wave &lt;- function(data, wave) {\n  # Plots transition probabilities for a specific wave as a heatmap.\n  # Filters the data to include only the main transitions and adds labels for clarity.\n  # Arguments:\n  #   - data: The dataset containing transition probabilities.\n  #   - wave: The wave or time period to plot.\n  # Returns:\n  #   - A ggplot object representing the transition probabilities for the \n  #   specified wave.\n  \n  # Main transitions per wave\n  filter_data &lt;- data.frame(\n    from = c(\"Normal Cognition\", \"Normal Cognition\", \"Normal Cognition\",  \"MCI\", \"MCI\", \"MCI\", \"Dementia\", \"Dementia\", \"Dementia\"),\n    to = c(\"Normal Cognition\", \"MCI\", \"Dementia\", \"Normal Cognition\", \"MCI\", \"Dementia\", \"Normal Cognition\", \"MCI\", \"Dementia\")\n  )\n  \n  data |&gt;\n    semi_join(filter_data, by = c(\"from\", \"to\")) |&gt;\n    filter(Wave == wave) |&gt;\n    ggplot(aes(x = to, y = from, fill = transition_prob)) +\n    geom_tile() +\n    geom_text(aes(label = transition_prob), size = 5) +\n    scale_fill_viridis_c(alpha = 0.8)+\n    labs(title = paste0(\"Transition Probabilities Across Cognitive States (\", wave, \"-\", wave + 2, \")\"),\n         x = \"To\", y = \"From\", fill = \"Prob\") +\n    theme_light() +\n    theme(\n      plot.title = element_text(hjust = 0.5, size = 12, face = \"bold\"),\n      axis.title = element_text(size = 10),\n      axis.text = element_text(size = 8),\n      panel.grid = element_blank(),\n      panel.border = element_blank()\n    )\n}\n\nbacktrack_age &lt;- function(data, base_year, current_year) {\n  # Back calculates an individual's age by 2-year intervals\n  # Arguments:\n  #   - data: The dataset containing the age variable and a 'Wave' column indicating the year of the wave\n  #   - current_year: The year for which the age is measured (e.g., 2022)\n  # Returns:\n  #   - A dataset where the age is subtracted by intervals of 2 for each respective year\n  \n  # Map Wave values (1-10) to their corresponding years\n  wave_to_year &lt;- function(wave) {\n    base_year + (as.numeric(wave) - 1) * 2\n  }\n  \n  data |&gt;\n    group_by(ID) |&gt;\n    mutate(Age = Age - (current_year - wave_to_year(Wave))) |&gt;\n    ungroup()\n}\n\npivot_data &lt;- function(data, cog_total = FALSE) {\n  # Reshapes the input dataset by pivoting cardiovascular, depression, and cognitive data\n  # into long format for analysis. Handles two scenarios: one for cognitive status and\n  # another for total cognitive scores. Combines the pivoted data into a final dataset\n  # for further analysis.\n  # Arguments:\n  #   - data: The input dataset containing cardiovascular, depression, and cognitive data.\n  #   - cog_total: A logical flag indicating whether to pivot total cognitive scores (TRUE)\n  #               or cognitive status (FALSE).\n  # Returns:\n  #   - A reshaped dataset in long format with combined cardiovascular, depression, and\n  #     cognitive data, ready for analysis.\n\n  # Pivot cardio dataset\n  data_cardio &lt;- data |&gt;\n    tidyr::pivot_longer(\n      cols = starts_with(\"Cardio_risk\"),\n      names_to = \"Cardio_Year\",\n      values_to = \"Cardio_risk\"\n    ) |&gt;\n    select(!any_of(c(\n      \"Cardio_Year\", \n      paste0(\"cogfunction\", 2016:2022), \n      paste0(\"cog_score_\", 2016:2022)\n      )))\n  \n  # Pivot dementia dataset\n  data_dep &lt;- data |&gt;\n    tidyr::pivot_longer(\n      cols = starts_with(\"Total_dep\"),\n      names_to = \"Dep_Year\",\n      values_to = \"Depression_score\"\n    ) |&gt;\n    select(ID, Depression_score)\n           \n  if(cog_total == FALSE) {\n    \n    # Pivot cognition dataset\n    data_cog &lt;- data |&gt;\n      tidyr::pivot_longer(\n        cols = starts_with(\"cogfunction\"),\n        names_to = \"Wave\",\n        values_to = \"Status\"\n      ) |&gt;\n      select(!any_of(c(\n        paste0(\"Cardio_risk_\", 16:22), \n        paste0(\"Total_dep_20\", 16:22))\n        ))\n  \n  # Adding cardio data to cognition data\n  combine_data &lt;- data_cog |&gt;\n    mutate(Cardio_risk = data_cardio$Cardio_risk, .after = Education_tri) |&gt;\n    mutate(Depression = data_dep$Depression_score, .after = Cardio_risk)\n  \n  # Producing final dataset\n  final_data &lt;- combine_data |&gt;\n    mutate(\n      Wave = stringr::str_replace(Wave, \"cogfunction\", \"HRS_\"),\n      Wave = factor(\n        Wave,\n        levels = c(\"HRS_2016\", \"HRS_2018\", \"HRS_2020\", \"HRS_2022\"),\n        labels = c(1, 2, 3, 4)\n      )) |&gt;\n    group_by(ID) |&gt;\n    mutate(\n      Status = ifelse(cumany(Status == \"Dementia\"), \"Dementia\", Status),\n      Status = factor(\n        Status,\n        levels = c(\"Normal Cognition\", \"MCI\", \"Dementia\"),\n        labels = c(1, 2, 3)\n      )) |&gt;\n    ungroup() |&gt;\n    mutate(\n      Gender = factor(Gender, levels = c(0, 1)),\n      Education_tri = factor(Education_tri, levels = c(0, 1, 2)),\n      Wave = as.numeric(Wave),\n      Status = as.numeric(Status)\n    )\n  } else {\n    \n    # Pivot cog total data\n    data_score &lt;- data |&gt;\n      tidyr::pivot_longer(\n        cols = starts_with(\"cog_score\"),\n        names_to = \"Wave\",\n        values_to = \"Score\"\n      ) |&gt;\n      mutate(\n        Wave = stringr::str_replace(Wave, \"cog_score_\", \"\"),\n        Wave = factor(\n          Wave, \n          levels = c(\"2016\", \"2018\", \"2020\", \"2022\"),\n          labels = c(1, 2, 3, 4)),\n        \n        Gender = as.factor(Gender),\n        Education_tri = as.factor(Education_tri)\n      ) |&gt;\n      select(!any_of(c(\n        paste0(\"Cardio_risk_\", 16:22), \n        paste0(\"Total_dep_20\", 16:22))\n      ))\n    \n    # Combine cardio and cog total data\n    final_data &lt;- data_score |&gt;\n      mutate(Cardio_risk = data_cardio$Cardio_risk, .after = Education_tri) |&gt;\n      mutate(Depression = data_dep$Depression_score, .after = Cardio_risk)\n    }\n  \n  return(final_data)\n}\n\ngentleman_test &lt;- function(data, model) {\n  # Compares observed and expected prevalence of cognitive states (Normal Cognition, MCI, Dementia)\n  # over time. Reshapes the observed and expected data into a long format and generates a\n  # faceted line plot to visualize the comparison.\n  # Arguments:\n  #   - data: A list containing observed and expected prevalence data.\n  #   - model: A string representing the model name, used in the plot title.\n  # Returns:\n  #   - A ggplot object displaying the observed vs. expected prevalence of cognitive states\n  #     over time.\n\n  # Reshaping observed prevalence\n  do1 &lt;- as_tibble(row.names(data$Observed)) |&gt;\n    rename(time = value) |&gt;\n    mutate(time = as.numeric(time))\n  \n  do2 &lt;- as_tibble(data$Observed) |&gt; \n    mutate(type = \"observed\")\n  \n  do &lt;- cbind(do1, do2) |&gt;\n    select(-Total) |&gt;\n    tidyr::gather(state, number, -c(time, type)) |&gt;\n    mutate(state = case_when(state == \"State 1\" ~ \"Normal Cognition\",\n                             state == \"State 2\" ~ \"MCI\",\n                             state == \"State 3\" ~ \"Dementia\"))\n  \n  # Reshaping expected prevalence\n  de1 &lt;- as_tibble(row.names(data$Expected)) |&gt;\n    rename(time = value) |&gt;\n    mutate(time = as.numeric(time))\n  \n  de2 &lt;- as_tibble(data$Expected) |&gt;\n    mutate(type = \"expected\")\n  \n  de &lt;- cbind(de1,de2) |&gt;\n    select(-Total) |&gt;\n    tidyr::gather(state, number, -c(time, type))\n  \n  # Turn into single data frame and plotting\n  rbind(do, de) |&gt;\n    mutate(type = factor(type),\n           state = factor(state, levels = c(\"Normal Cognition\", \"MCI\", \"Dementia\")),\n           time = round(time,3)) |&gt;\n    group_by(state) |&gt;\n    ggplot(aes(x = time, y = number, colour = type)) +\n    geom_line(linewidth = 1) +\n    labs(title = paste0(\"Observed vs Fitted Values: \", model), x = \"Time\", y = \"\") +\n    facet_wrap(~ state) +\n    theme_bw() +\n    ggeasy::easy_remove_legend_title()\n}\n\nprocess_hr &lt;- function(data, fix_upper = TRUE) {\n  # Processes hazard ratio (HR) data by cleaning and reshaping it for visualization.\n  # Converts covariate names into descriptive labels and ensures proper formatting\n  # of transitions and confidence intervals. Optionally fixes upper confidence intervals\n  # that exceed a specified threshold.\n  # Arguments:\n  #   - data: The input dataset containing hazard ratio data.\n  #   - fix_upper: A logical flag indicating whether to fix upper confidence intervals\n  #                that exceed a threshold (default: TRUE).\n  # Returns:\n  #   - A cleaned and reshaped dataset ready for hazard ratio visualization.\n  \n  data &lt;- do.call(rbind.data.frame, data) |&gt;\n    tibble::rownames_to_column(var = \"Covariate\") |&gt;\n    tidyr::separate_wider_delim(cols = Covariate, \n                                delim = \".\", \n                                names = c(\"Covariate\", \"Transition\")) |&gt;\n    mutate(Covariate = case_when(\n      Covariate == \"Gender1\" ~ \"Female\",\n      Covariate == \"Education_tri1\" ~ \"High School\",\n      Covariate == \"Education_tri2\" ~ \"College\",\n      Covariate == \"Cardio_risk\" ~ \"Cardiovascular Risk\",\n      Covariate == \"Depression\" ~ \"Depression\",\n      Covariate == \"Total_p\" ~ \"Total Procrastination\",\n      Covariate == \"Depression:Total_p\" ~ \"Depression x Procrastination\",\n      TRUE ~ Covariate),\n      \n      Covariate = factor(\n        Covariate, \n        levels = c(\"Female\", \"Age\", \"High School\", \"College\", \n                   \"Cardiovascular Risk\", \"Depression\", \n                   \"Total Procrastination\", \"Depression x Procrastination\"))\n      ) |&gt;\n    mutate(Transition = factor(\n      Transition, \n      levels = c(\"Normal Cognition - MCI\", \n                 \"Normal Cognition - Dementia\",\n                 \"MCI - Normal Cognition\",\n                 \"MCI - Dementia\")))\n  \n  if(fix_upper == TRUE){\n    data &lt;- data |&gt;\n      mutate(U = case_when(\n        U &gt;= 5 & Transition == \"Normal Cognition - Dementia\" ~ HR,\n        # U &gt;= 5 & HR &lt; 1 ~ 1,\n        TRUE ~ U\n      ))\n  }\n  \n  return(data)\n}\n\ncalculate_p_value &lt;- function(data) {\n  # Calculates p-values for hazard ratios (HR) based on log-transformed HR values and\n  # their confidence intervals. Adds the calculated p-values to the input dataset.\n  # Arguments:\n  #   - data: The input dataset containing hazard ratios and confidence intervals.\n  # Returns:\n  #   - The input dataset with an additional column for p-values\n  \n  log_HR &lt;- log(data$HR)\n  log_lower_CI &lt;- log(data$L)\n  log_upper_CI &lt;- log(data$U)\n  \n  SE &lt;- (log_upper_CI - log_lower_CI) / (2 * 1.96)\n  Z &lt;- log_HR / SE\n  p_value &lt;- 2 * (1 - pnorm(abs(Z)))\n  \n  data$pval &lt;- p_value |&gt; round(digits = 3)\n  \n  return(data)\n}\n\nplot_hr &lt;- function(data) {\n  # Generates a forest plot of hazard ratios (HR) for cognitive transitions, including\n  # confidence intervals and significance stars. Customizes the plot based on covariate\n  # labels and ensures proper formatting for visualization.\n  # Arguments:\n  #   - data: The input dataset containing hazard ratios, confidence intervals, and p-values.\n  # Returns:\n  #   - A ggplot object displaying hazard ratios for cognitive transitions, faceted by covariate.\n  \n  # Making a plot customization\n  labeller &lt;- c(\n    Female = \"Being female vs. Male\",\n    `High School` = \"Having a highshool education vs. No education\",\n    College = \"Having a further education vs. No education\",\n    `Cardiovascular Risk` = \"Total number of cardiovascular risk factors\",\n    Depression = \"Depression\",\n    Total_p = \"Procrastination\",\n    `Depression x Procrastination` = \"Depression x Procrastination\"\n  )\n  \n  # Add a column for significance stars\n  data &lt;- data |&gt;\n    mutate(\n      stars = case_when(\n        pval &lt; 0.001 ~ \"***\",\n        pval &lt; 0.01 ~ \"**\",\n        pval &lt; 0.05 ~ \"*\",\n        pval &lt; 0.10 ~ \"+\",\n        TRUE ~ \"\" \n      ))\n  \n  # Plotting  \n  haz_plot &lt;- data |&gt;\n    ggplot(aes(x = HR, y = forcats::fct_rev(Transition), colour = HR &gt; 1)) +\n    geom_point(size = 4) +\n    geom_linerange(aes(xmin = L, xmax = U), linewidth = 1.5, alpha = 0.5) +\n    geom_vline(xintercept = 1, colour = \"gray75\", linewidth = 0.75, linetype = \"dashed\") +\n    geom_text(aes(label = stars), vjust = -0.5, hjust = 0.5, size = 5, color = \"black\") +\n    labs(title = \"Hazard Ratio for dementia transitions\",\n         x = \"Hazard Ratio (95% Confidence Interval)\", \n         y = \"\") +\n    scale_color_manual(values = c(\"#E69F00\", \"#56B4E9\"), guide = \"none\") +\n    guides(colour = \"none\") +\n    theme_bw() +\n    theme(\n      plot.title = element_text(hjust = 0.5, size = 14, face = \"bold\"),\n      axis.title.x = element_text(size = 12),\n      strip.text = element_text(size = 10)\n      )\n  \n  if(nrow(data) == 32){\n  # Centering the bottom facet because I am pedantic\n    haz_plot &lt;- haz_plot + ggh4x::facet_manual(\n    ~ Covariate,\n    scales = \"free_x\",\n    labeller = labeller(Covariate = labeller),\n    design = c(\n    \"\n    AABBCC\n    DDEEFF\n    #GGHH#\n    \"\n    ))\n  } else {\n    # Centering the bottom facet because I am pedantic\n    haz_plot &lt;- haz_plot + ggh4x::facet_manual(\n      ~ Covariate,\n      scales = \"free_x\",\n      labeller = labeller(Covariate = labeller),\n      design = c(\n      \"\n      AABBCC\n      DDEEFF\n      ##GG##\n      \"\n      ))\n  }\n  \n  return(haz_plot)\n}\n\n\n\n\n\n\nset.seed(34521)\n\ndata &lt;- read.csv(here::here(\"analysis/data/data.csv\"))",
    "crumbs": [
      "Analysis",
      "Models",
      "Continous Time Markov Model"
    ]
  },
  {
    "objectID": "analysis/continous-markov.html#setting-up",
    "href": "analysis/continous-markov.html#setting-up",
    "title": "Continous Time Markov Model",
    "section": "",
    "text": "Check our my packages\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(ggplot2)\n\n\n\n\n\n\n\nCheck our my functions\nextract_years &lt;- function(data, years, impute = TRUE, cog_total = FALSE, absorbing = TRUE) {\n  # Extracts cognitive function data for specified years from a dataset.\n  # Converts numeric cognitive status codes (1, 2, 3) into descriptive labels\n  # (\"Normal Cognition\", \"MCI\", \"Dementia\") for easier interpretation.\n  # Arguments:\n  #   - data: The input dataset containing cognitive function data.\n  #   - years: A vector of years for which data should be extracted.\n  # Returns:\n  #   - A dataset with ID and cognitive status columns for the specified years.\n  \n  # Create dynamic column names based on the years provided\n  cogfunction_cols &lt;- paste0(\"cogfunction\", years)\n  cogtotal_cols    &lt;- paste0(\"cogtot27_imp\", years)\n  \n  if(cog_total == FALSE) {\n  data &lt;- data |&gt;\n    # Select only the ID column and cognitive function columns for the specified years\n    select(ID, any_of(cogfunction_cols)) |&gt;\n    mutate(across(!c(ID), ~ case_when(\n      .x == 1 ~ \"Normal Cognition\",\n      .x == 2 ~ \"MCI\",\n      .x == 3 ~ \"Dementia\",\n      TRUE ~ NA_character_  # To handle missing/other cases\n    )))\n  } else {\n    data &lt;- data |&gt;\n      # Select only the ID column and cognitive function columns for the specified years\n      select(ID, any_of(cogtotal_cols)) |&gt;\n      rename_with( .cols = !ID, .fn = ~ stringr::str_replace(\n        string = .x,\n        pattern = \"cogtot27_imp\", \n        replacement = \"cog_score_\"))\n  }\n  \n  if(impute == TRUE){\n    data &lt;- data |&gt;\n      tidyr::pivot_longer(\n        cols = !ID,\n        names_to = \"Wave\",\n        values_to = \"Status\") |&gt;\n      group_by(ID) |&gt;\n      tidyr::fill(Status, .direction = \"down\") |&gt;\n      ungroup() |&gt;\n      tidyr::pivot_wider(names_from = \"Wave\", values_from = \"Status\")\n  }\n  \n  if(absorbing == TRUE) {\n    data &lt;- data |&gt;\n      tidyr::pivot_longer(\n        cols = !ID,\n        names_to = \"Wave\",\n        values_to = \"Status\") |&gt;\n      group_by(ID) |&gt;\n      mutate(Status = ifelse(cumany(Status == \"Dementia\"), \"Dementia\", Status)) |&gt;\n      ungroup() |&gt;\n      tidyr::pivot_wider(names_from = \"Wave\", values_from = \"Status\")\n  }\n  \n  return(data)\n}\n\ncreate_transitions &lt;- function(data, absorbing = FALSE){\n  # Reshapes data from wide to long format to track cognitive status transitions over time.\n  # Calculates the next wave's cognitive status for each individual and creates a transition column.\n  # Optionally treats \"Dementia\" as an absorbing state, meaning once an individual is classified\n  # with dementia, their status cannot change in subsequent waves.\n  # Arguments:\n  #   - data: The dataset containing cognitive status data.\n  #   - absorbing: A logical flag indicating whether \"Dementia\" should be treated \n  #   as an absorbing state.\n  # Returns:\n  #   - A dataset with transition information, including current and next wave statuses.\n  \n  # Reshape the data from wide to long format to track cognitive status over waves\n  data &lt;- data |&gt;\n    select(ID, starts_with(\"cogfunction\")) |&gt;\n    tidyr::pivot_longer(cols = !ID,\n                        names_to = \"Wave\",\n                        values_to = \"Status\") |&gt;\n    mutate(Wave = as.factor(stringr::str_replace(Wave, \"cogfunction\", \"\"))) |&gt;\n    # Arrange by ID and Wave to prepare for transition calculation\n    arrange(ID, Wave) |&gt;\n    group_by(ID) |&gt;\n    # Get the next wave's cognitive status for each person\n    mutate(next_wave_status = lead(Status)) |&gt;\n    ungroup()\n  \n  # We can optionally specify dementia as an absorbing state\n  # Once an individual is classified with dementia they cannot be classified\n  # with anything else \n  if(absorbing == TRUE) {\n    data &lt;- data |&gt;\n      group_by(ID) |&gt;\n      mutate(\n        Status = ifelse(cumany(Status == \"Dementia\"), \"Dementia\", Status),\n        next_wave_status = ifelse(cumany(Status == \"Dementia\"), \"Dementia\", next_wave_status),\n        transition = paste(Status, next_wave_status, sep = \" to \")\n      ) |&gt;\n      filter(Wave %in% c(2016, 2018, 2020))\n  }\n  \n  # Filter out rows where either the current or next status is missing\n  data &lt;- data |&gt;\n    group_by(ID) |&gt;\n    filter(!is.na(Status), !is.na(next_wave_status)) |&gt;\n    ungroup() |&gt;\n    # Create a new column representing the transition from one status to the next\n    mutate(\n      transition = paste(Status, next_wave_status, sep = \" to \"),\n      transition = factor(\n        transition, \n        levels = c(\"Normal Cognition to Normal Cognition\", \"Normal Cognition to MCI\",\n                   \"Normal Cognition to Dementia\", \"MCI to Normal Cognition\", \"MCI to MCI\",\n                   \"MCI to Dementia\", \"Dementia to Dementia\") \n        ))\n  \n  return(data)\n}\n\ncalculate_probabilties &lt;- function(data) {\n  # Calculates the proportion of each cognitive status transition in the dataset.\n  # Counts the occurrences of each transition and computes their relative probabilities.\n  # Arguments:\n  #   - data: The dataset containing transition information.\n  # Returns:\n  #   - A dataset with transition probabilities, split into \"from\" and \"to\" states.\n  \n  # Calculate the proportion of each transition by dividing by the total count\n  data |&gt;\n    count(transition) |&gt;\n    mutate(prop = n / sum(n)) |&gt;\n    tidyr::separate(transition, into = c(\"from\", \"to\"), sep = \" to \")\n}\n\ntransition_matrix &lt;- function(data, longitudinal = FALSE) {\n  # Constructs a transition matrix from the calculated transition probabilities.\n  # The matrix represents the probability of moving from one cognitive state to another.\n  # Arguments:\n  #   - data: The dataset containing transition probabilities.\n  #   - longitudinal: A TRUE/FALSE statement indicating if the probabilities are from multiple waves\n  # Returns:\n  #   - A transition matrix with rows representing \"from\" states and columns \n  #   representing \"to\" states.\n  \n  if(longitudinal == FALSE) {\n    # Defining empty matrix matrix\n    states &lt;- c(\"Normal Cognition\", \"MCI\", \"Dementia\")\n    \n    transition_matrix &lt;- matrix(\n      0,\n      nrow = length(states),\n      ncol = length(states),\n      dimnames = list(from_state = states, to_state = states))\n    \n    # Fill the transition matrix with probabilities\n    for (i in 1:nrow(data)) {\n      from &lt;- data$from[i]\n      to &lt;- data$to[i]\n      prob &lt;- data$prop[i]\n      \n      transition_matrix[from, to] &lt;- prob\n    }\n  } else if(longitudinal == TRUE){\n    \n    # Aggregate by 'from' and 'to' states to sum transition probabilities\n    data_agg &lt;- data |&gt;\n      group_by(from, to) |&gt;\n      summarise(transition_prob = sum(prop), .groups = \"drop\")\n    \n    transition_matrix &lt;- data_agg |&gt;\n      tidyr::pivot_wider(names_from = to, values_from = transition_prob, values_fill = 0) |&gt;\n      tibble::column_to_rownames(\"from\") |&gt;\n      as.matrix()\n  }\n  \n  return(transition_matrix)\n}\n\nplot_matrix &lt;- function(data, year, ts = FALSE) {\n  # Visualizes the transition matrix as a heatmap.\n  # Uses color gradients to represent transition probabilities and includes labels for clarity.\n  # Arguments:\n  #   - data: The transition matrix or dataset to plot.\n  #   - year: The year or time period associated with the data.\n  #   - ts: A logical flag indicating whether the title should include a time series label.\n  # Returns:\n  #   - A ggplot object representing the transition probabilities as a heatmap.\n  \n  if(ts == TRUE) {\n    title &lt;- paste0(\"Transition Probabilities Across Cognitive States - \", year)\n  } else {\n    title &lt;- paste0(\"Transition Probabilities Across Cognitive States (\", year, \"-2022)\")\n  }\n  \n  # Reshaping data for plotting\n  data &lt;- data |&gt;\n    as.data.frame(row.names = FALSE) |&gt;\n    mutate(from_state = c(\"Normal Cognition\", \"MCI\", \"Dementia\")) |&gt;\n    reshape2::melt(id.vars = \"from_state\", variable.name = \"to_state\", value.name = \"probability\")\n  \n  # Plotting probabilities\n  data |&gt;\n    ggplot(aes(x = from_state, y = to_state, fill = probability)) +\n    geom_tile() +\n    scale_fill_viridis_c(alpha = 0.8) +\n    labs(title = title,\n         x = \"To\", y = \"From\", fill = \"Prob\") +\n    geom_text(aes(label = round(probability, digits = 3)), size = 5) +\n    theme_minimal() +\n    theme(plot.title = element_text(hjust = 0.5, size = 12, face = \"bold\"),\n          axis.title = element_text(size = 10),\n          axis.text = element_text(size = 8),\n          panel.grid = element_blank()\n    )\n}\n\nnormalise &lt;- function(x) {\n  # Normalizes a matrix so that each row sums to 1.\n  # Arguments:\n  #   - x: The input matrix to normalize.\n  # Returns:\n  #   - A normalized matrix where each row sums to 1.\n  x / rowSums(x)\n}\n\nreshape_matrix &lt;- function(matrix, wave) {\n  # Reshapes a transition matrix into a long format for easier analysis and visualization.\n  # Adds a \"Wave\" column to identify the time period associated with the matrix.\n  # Arguments:\n  #   - matrix: The transition matrix to reshape.\n  #   - wave: The wave or time period associated with the matrix.\n  # Returns:\n  #   - A long-format dataset with \"from\", \"to\", and \"transition_prob\" columns.\n  \n  matrix |&gt;\n    as.data.frame() |&gt;\n    tibble::rownames_to_column(var = \"from\") |&gt;\n    tidyr::pivot_longer(cols = -from, names_to = \"to\", values_to = \"transition_prob\") |&gt;\n    mutate(Wave = wave)\n}\n\nplot_transition_wave &lt;- function(data, wave) {\n  # Plots transition probabilities for a specific wave as a heatmap.\n  # Filters the data to include only the main transitions and adds labels for clarity.\n  # Arguments:\n  #   - data: The dataset containing transition probabilities.\n  #   - wave: The wave or time period to plot.\n  # Returns:\n  #   - A ggplot object representing the transition probabilities for the \n  #   specified wave.\n  \n  # Main transitions per wave\n  filter_data &lt;- data.frame(\n    from = c(\"Normal Cognition\", \"Normal Cognition\", \"Normal Cognition\",  \"MCI\", \"MCI\", \"MCI\", \"Dementia\", \"Dementia\", \"Dementia\"),\n    to = c(\"Normal Cognition\", \"MCI\", \"Dementia\", \"Normal Cognition\", \"MCI\", \"Dementia\", \"Normal Cognition\", \"MCI\", \"Dementia\")\n  )\n  \n  data |&gt;\n    semi_join(filter_data, by = c(\"from\", \"to\")) |&gt;\n    filter(Wave == wave) |&gt;\n    ggplot(aes(x = to, y = from, fill = transition_prob)) +\n    geom_tile() +\n    geom_text(aes(label = transition_prob), size = 5) +\n    scale_fill_viridis_c(alpha = 0.8)+\n    labs(title = paste0(\"Transition Probabilities Across Cognitive States (\", wave, \"-\", wave + 2, \")\"),\n         x = \"To\", y = \"From\", fill = \"Prob\") +\n    theme_light() +\n    theme(\n      plot.title = element_text(hjust = 0.5, size = 12, face = \"bold\"),\n      axis.title = element_text(size = 10),\n      axis.text = element_text(size = 8),\n      panel.grid = element_blank(),\n      panel.border = element_blank()\n    )\n}\n\nbacktrack_age &lt;- function(data, base_year, current_year) {\n  # Back calculates an individual's age by 2-year intervals\n  # Arguments:\n  #   - data: The dataset containing the age variable and a 'Wave' column indicating the year of the wave\n  #   - current_year: The year for which the age is measured (e.g., 2022)\n  # Returns:\n  #   - A dataset where the age is subtracted by intervals of 2 for each respective year\n  \n  # Map Wave values (1-10) to their corresponding years\n  wave_to_year &lt;- function(wave) {\n    base_year + (as.numeric(wave) - 1) * 2\n  }\n  \n  data |&gt;\n    group_by(ID) |&gt;\n    mutate(Age = Age - (current_year - wave_to_year(Wave))) |&gt;\n    ungroup()\n}\n\npivot_data &lt;- function(data, cog_total = FALSE) {\n  # Reshapes the input dataset by pivoting cardiovascular, depression, and cognitive data\n  # into long format for analysis. Handles two scenarios: one for cognitive status and\n  # another for total cognitive scores. Combines the pivoted data into a final dataset\n  # for further analysis.\n  # Arguments:\n  #   - data: The input dataset containing cardiovascular, depression, and cognitive data.\n  #   - cog_total: A logical flag indicating whether to pivot total cognitive scores (TRUE)\n  #               or cognitive status (FALSE).\n  # Returns:\n  #   - A reshaped dataset in long format with combined cardiovascular, depression, and\n  #     cognitive data, ready for analysis.\n\n  # Pivot cardio dataset\n  data_cardio &lt;- data |&gt;\n    tidyr::pivot_longer(\n      cols = starts_with(\"Cardio_risk\"),\n      names_to = \"Cardio_Year\",\n      values_to = \"Cardio_risk\"\n    ) |&gt;\n    select(!any_of(c(\n      \"Cardio_Year\", \n      paste0(\"cogfunction\", 2016:2022), \n      paste0(\"cog_score_\", 2016:2022)\n      )))\n  \n  # Pivot dementia dataset\n  data_dep &lt;- data |&gt;\n    tidyr::pivot_longer(\n      cols = starts_with(\"Total_dep\"),\n      names_to = \"Dep_Year\",\n      values_to = \"Depression_score\"\n    ) |&gt;\n    select(ID, Depression_score)\n           \n  if(cog_total == FALSE) {\n    \n    # Pivot cognition dataset\n    data_cog &lt;- data |&gt;\n      tidyr::pivot_longer(\n        cols = starts_with(\"cogfunction\"),\n        names_to = \"Wave\",\n        values_to = \"Status\"\n      ) |&gt;\n      select(!any_of(c(\n        paste0(\"Cardio_risk_\", 16:22), \n        paste0(\"Total_dep_20\", 16:22))\n        ))\n  \n  # Adding cardio data to cognition data\n  combine_data &lt;- data_cog |&gt;\n    mutate(Cardio_risk = data_cardio$Cardio_risk, .after = Education_tri) |&gt;\n    mutate(Depression = data_dep$Depression_score, .after = Cardio_risk)\n  \n  # Producing final dataset\n  final_data &lt;- combine_data |&gt;\n    mutate(\n      Wave = stringr::str_replace(Wave, \"cogfunction\", \"HRS_\"),\n      Wave = factor(\n        Wave,\n        levels = c(\"HRS_2016\", \"HRS_2018\", \"HRS_2020\", \"HRS_2022\"),\n        labels = c(1, 2, 3, 4)\n      )) |&gt;\n    group_by(ID) |&gt;\n    mutate(\n      Status = ifelse(cumany(Status == \"Dementia\"), \"Dementia\", Status),\n      Status = factor(\n        Status,\n        levels = c(\"Normal Cognition\", \"MCI\", \"Dementia\"),\n        labels = c(1, 2, 3)\n      )) |&gt;\n    ungroup() |&gt;\n    mutate(\n      Gender = factor(Gender, levels = c(0, 1)),\n      Education_tri = factor(Education_tri, levels = c(0, 1, 2)),\n      Wave = as.numeric(Wave),\n      Status = as.numeric(Status)\n    )\n  } else {\n    \n    # Pivot cog total data\n    data_score &lt;- data |&gt;\n      tidyr::pivot_longer(\n        cols = starts_with(\"cog_score\"),\n        names_to = \"Wave\",\n        values_to = \"Score\"\n      ) |&gt;\n      mutate(\n        Wave = stringr::str_replace(Wave, \"cog_score_\", \"\"),\n        Wave = factor(\n          Wave, \n          levels = c(\"2016\", \"2018\", \"2020\", \"2022\"),\n          labels = c(1, 2, 3, 4)),\n        \n        Gender = as.factor(Gender),\n        Education_tri = as.factor(Education_tri)\n      ) |&gt;\n      select(!any_of(c(\n        paste0(\"Cardio_risk_\", 16:22), \n        paste0(\"Total_dep_20\", 16:22))\n      ))\n    \n    # Combine cardio and cog total data\n    final_data &lt;- data_score |&gt;\n      mutate(Cardio_risk = data_cardio$Cardio_risk, .after = Education_tri) |&gt;\n      mutate(Depression = data_dep$Depression_score, .after = Cardio_risk)\n    }\n  \n  return(final_data)\n}\n\ngentleman_test &lt;- function(data, model) {\n  # Compares observed and expected prevalence of cognitive states (Normal Cognition, MCI, Dementia)\n  # over time. Reshapes the observed and expected data into a long format and generates a\n  # faceted line plot to visualize the comparison.\n  # Arguments:\n  #   - data: A list containing observed and expected prevalence data.\n  #   - model: A string representing the model name, used in the plot title.\n  # Returns:\n  #   - A ggplot object displaying the observed vs. expected prevalence of cognitive states\n  #     over time.\n\n  # Reshaping observed prevalence\n  do1 &lt;- as_tibble(row.names(data$Observed)) |&gt;\n    rename(time = value) |&gt;\n    mutate(time = as.numeric(time))\n  \n  do2 &lt;- as_tibble(data$Observed) |&gt; \n    mutate(type = \"observed\")\n  \n  do &lt;- cbind(do1, do2) |&gt;\n    select(-Total) |&gt;\n    tidyr::gather(state, number, -c(time, type)) |&gt;\n    mutate(state = case_when(state == \"State 1\" ~ \"Normal Cognition\",\n                             state == \"State 2\" ~ \"MCI\",\n                             state == \"State 3\" ~ \"Dementia\"))\n  \n  # Reshaping expected prevalence\n  de1 &lt;- as_tibble(row.names(data$Expected)) |&gt;\n    rename(time = value) |&gt;\n    mutate(time = as.numeric(time))\n  \n  de2 &lt;- as_tibble(data$Expected) |&gt;\n    mutate(type = \"expected\")\n  \n  de &lt;- cbind(de1,de2) |&gt;\n    select(-Total) |&gt;\n    tidyr::gather(state, number, -c(time, type))\n  \n  # Turn into single data frame and plotting\n  rbind(do, de) |&gt;\n    mutate(type = factor(type),\n           state = factor(state, levels = c(\"Normal Cognition\", \"MCI\", \"Dementia\")),\n           time = round(time,3)) |&gt;\n    group_by(state) |&gt;\n    ggplot(aes(x = time, y = number, colour = type)) +\n    geom_line(linewidth = 1) +\n    labs(title = paste0(\"Observed vs Fitted Values: \", model), x = \"Time\", y = \"\") +\n    facet_wrap(~ state) +\n    theme_bw() +\n    ggeasy::easy_remove_legend_title()\n}\n\nprocess_hr &lt;- function(data, fix_upper = TRUE) {\n  # Processes hazard ratio (HR) data by cleaning and reshaping it for visualization.\n  # Converts covariate names into descriptive labels and ensures proper formatting\n  # of transitions and confidence intervals. Optionally fixes upper confidence intervals\n  # that exceed a specified threshold.\n  # Arguments:\n  #   - data: The input dataset containing hazard ratio data.\n  #   - fix_upper: A logical flag indicating whether to fix upper confidence intervals\n  #                that exceed a threshold (default: TRUE).\n  # Returns:\n  #   - A cleaned and reshaped dataset ready for hazard ratio visualization.\n  \n  data &lt;- do.call(rbind.data.frame, data) |&gt;\n    tibble::rownames_to_column(var = \"Covariate\") |&gt;\n    tidyr::separate_wider_delim(cols = Covariate, \n                                delim = \".\", \n                                names = c(\"Covariate\", \"Transition\")) |&gt;\n    mutate(Covariate = case_when(\n      Covariate == \"Gender1\" ~ \"Female\",\n      Covariate == \"Education_tri1\" ~ \"High School\",\n      Covariate == \"Education_tri2\" ~ \"College\",\n      Covariate == \"Cardio_risk\" ~ \"Cardiovascular Risk\",\n      Covariate == \"Depression\" ~ \"Depression\",\n      Covariate == \"Total_p\" ~ \"Total Procrastination\",\n      Covariate == \"Depression:Total_p\" ~ \"Depression x Procrastination\",\n      TRUE ~ Covariate),\n      \n      Covariate = factor(\n        Covariate, \n        levels = c(\"Female\", \"Age\", \"High School\", \"College\", \n                   \"Cardiovascular Risk\", \"Depression\", \n                   \"Total Procrastination\", \"Depression x Procrastination\"))\n      ) |&gt;\n    mutate(Transition = factor(\n      Transition, \n      levels = c(\"Normal Cognition - MCI\", \n                 \"Normal Cognition - Dementia\",\n                 \"MCI - Normal Cognition\",\n                 \"MCI - Dementia\")))\n  \n  if(fix_upper == TRUE){\n    data &lt;- data |&gt;\n      mutate(U = case_when(\n        U &gt;= 5 & Transition == \"Normal Cognition - Dementia\" ~ HR,\n        # U &gt;= 5 & HR &lt; 1 ~ 1,\n        TRUE ~ U\n      ))\n  }\n  \n  return(data)\n}\n\ncalculate_p_value &lt;- function(data) {\n  # Calculates p-values for hazard ratios (HR) based on log-transformed HR values and\n  # their confidence intervals. Adds the calculated p-values to the input dataset.\n  # Arguments:\n  #   - data: The input dataset containing hazard ratios and confidence intervals.\n  # Returns:\n  #   - The input dataset with an additional column for p-values\n  \n  log_HR &lt;- log(data$HR)\n  log_lower_CI &lt;- log(data$L)\n  log_upper_CI &lt;- log(data$U)\n  \n  SE &lt;- (log_upper_CI - log_lower_CI) / (2 * 1.96)\n  Z &lt;- log_HR / SE\n  p_value &lt;- 2 * (1 - pnorm(abs(Z)))\n  \n  data$pval &lt;- p_value |&gt; round(digits = 3)\n  \n  return(data)\n}\n\nplot_hr &lt;- function(data) {\n  # Generates a forest plot of hazard ratios (HR) for cognitive transitions, including\n  # confidence intervals and significance stars. Customizes the plot based on covariate\n  # labels and ensures proper formatting for visualization.\n  # Arguments:\n  #   - data: The input dataset containing hazard ratios, confidence intervals, and p-values.\n  # Returns:\n  #   - A ggplot object displaying hazard ratios for cognitive transitions, faceted by covariate.\n  \n  # Making a plot customization\n  labeller &lt;- c(\n    Female = \"Being female vs. Male\",\n    `High School` = \"Having a highshool education vs. No education\",\n    College = \"Having a further education vs. No education\",\n    `Cardiovascular Risk` = \"Total number of cardiovascular risk factors\",\n    Depression = \"Depression\",\n    Total_p = \"Procrastination\",\n    `Depression x Procrastination` = \"Depression x Procrastination\"\n  )\n  \n  # Add a column for significance stars\n  data &lt;- data |&gt;\n    mutate(\n      stars = case_when(\n        pval &lt; 0.001 ~ \"***\",\n        pval &lt; 0.01 ~ \"**\",\n        pval &lt; 0.05 ~ \"*\",\n        pval &lt; 0.10 ~ \"+\",\n        TRUE ~ \"\" \n      ))\n  \n  # Plotting  \n  haz_plot &lt;- data |&gt;\n    ggplot(aes(x = HR, y = forcats::fct_rev(Transition), colour = HR &gt; 1)) +\n    geom_point(size = 4) +\n    geom_linerange(aes(xmin = L, xmax = U), linewidth = 1.5, alpha = 0.5) +\n    geom_vline(xintercept = 1, colour = \"gray75\", linewidth = 0.75, linetype = \"dashed\") +\n    geom_text(aes(label = stars), vjust = -0.5, hjust = 0.5, size = 5, color = \"black\") +\n    labs(title = \"Hazard Ratio for dementia transitions\",\n         x = \"Hazard Ratio (95% Confidence Interval)\", \n         y = \"\") +\n    scale_color_manual(values = c(\"#E69F00\", \"#56B4E9\"), guide = \"none\") +\n    guides(colour = \"none\") +\n    theme_bw() +\n    theme(\n      plot.title = element_text(hjust = 0.5, size = 14, face = \"bold\"),\n      axis.title.x = element_text(size = 12),\n      strip.text = element_text(size = 10)\n      )\n  \n  if(nrow(data) == 32){\n  # Centering the bottom facet because I am pedantic\n    haz_plot &lt;- haz_plot + ggh4x::facet_manual(\n    ~ Covariate,\n    scales = \"free_x\",\n    labeller = labeller(Covariate = labeller),\n    design = c(\n    \"\n    AABBCC\n    DDEEFF\n    #GGHH#\n    \"\n    ))\n  } else {\n    # Centering the bottom facet because I am pedantic\n    haz_plot &lt;- haz_plot + ggh4x::facet_manual(\n      ~ Covariate,\n      scales = \"free_x\",\n      labeller = labeller(Covariate = labeller),\n      design = c(\n      \"\n      AABBCC\n      DDEEFF\n      ##GG##\n      \"\n      ))\n  }\n  \n  return(haz_plot)\n}\n\n\n\n\n\n\nset.seed(34521)\n\ndata &lt;- read.csv(here::here(\"analysis/data/data.csv\"))",
    "crumbs": [
      "Analysis",
      "Models",
      "Continous Time Markov Model"
    ]
  },
  {
    "objectID": "analysis/continous-markov.html#markov-modelling",
    "href": "analysis/continous-markov.html#markov-modelling",
    "title": "Continous Time Markov Model",
    "section": "Markov Modelling",
    "text": "Markov Modelling\nIn this section, we apply Markov modelling to analyze the transitions between cognitive states (Normal Cognition, Mild Cognitive Impairment [MCI], and Dementia) using longitudinal data from the Health and Retirement Study (HRS) from 2016 to 2022. By modeling these transitions, we aim to understand the probabilities of moving between different cognitive states over time.\n\nData preparation\nThe first step is to prepare the transition dataset. We start by transforming the data to create a record of transitions from one cognitive state to another between consecutive waves.\nOnce the transitions are identified, we calculate the probabilities of each state-to-state transition. These probabilities are computed by counting the occurrences of each transition and dividing by the total number of transitions.\n\ntran_prob &lt;- data |&gt;\n  extract_years(years = seq(2016, 2022, by = 2)) |&gt;\n  create_transitions(absorbing = TRUE) |&gt;\n  calculate_probabilties()\n\ntran_prob |&gt;\n  mutate(prop = round(prop, digits = 3)) |&gt;\n  head(n = 9) |&gt;\n  gt::gt() |&gt;\n  gtExtras::gt_theme_538() |&gt;\n  gt::cols_align(align = \"center\") |&gt;\n  gt::tab_header(title = \"Overall Transition Probabilties (2016 - 2022)\") |&gt;\n  gt::tab_options(table.width = gt::pct(100)) |&gt;\n  gt::opt_align_table_header(align = \"center\")\n\n\n\n\n\n\n\nOverall Transition Probabilties (2016 - 2022)\n\n\nfrom\nto\nn\nprop\n\n\n\n\nNormal Cognition\nNormal Cognition\n2090\n0.755\n\n\nNormal Cognition\nMCI\n224\n0.081\n\n\nNormal Cognition\nDementia\n20\n0.007\n\n\nMCI\nNormal Cognition\n186\n0.067\n\n\nMCI\nMCI\n132\n0.048\n\n\nMCI\nDementia\n33\n0.012\n\n\nDementia\nDementia\n84\n0.030\n\n\n\n\n\n\n\n\n\nCreating transition matrix\nThe probability distribution of transitions from one state to another can be represented into a transition matrix P = (p_{ij})_{i,j} where each element of position (i, j) represents the transition probability p_{ij}.\n\nP = \\begin{bmatrix}\np_{11} & p_{12} & p_{13} \\\\\np_{21} & p_{22} & p_{23} \\\\\np_{31} & p_{32} & p_{33} \\\\\n\\end{bmatrix}\n\n\ntran_matrix &lt;- tran_prob |&gt;\n  transition_matrix() |&gt;\n  normalise() |&gt;\n  round(digits = 3)\n\ntran_matrix\n\n                  to_state\nfrom_state         Normal Cognition   MCI Dementia\n  Normal Cognition            0.895 0.096    0.009\n  MCI                         0.530 0.376    0.094\n  Dementia                    0.000 0.000    1.000\n\n\nThis code creates a 3 \\times 3 matrix (for the three states: Normal Cognition, MCI, and Dementia) and populates it with the transition probabilities.\n\n\nVisualising the matrix\nTo make the transition matrix more interpretable we visualize the probabilities using a heat map (Figure 1)\n\nplot_matrix(data = t(tran_matrix), year = 2016)\n\n\n\n\n\n\n\nFigure 1: Heat map of transition probabilities (2016 - 2022)\n\n\n\n\n\nWe can also create and plot transition matrices for each wave separately allowing us to see how these transition probabilities change across multiple waves of data collection\n\ntran_prob_long &lt;- data |&gt;\n  extract_years(years = seq(2016, 2022, by = 2)) |&gt;\n  create_transitions(absorbing = TRUE) |&gt;\n  group_by(Wave) |&gt;\n  calculate_probabilties() |&gt;\n  group_map(~ transition_matrix(.x, longitudinal = TRUE), .keep = TRUE) |&gt;\n  lapply(function(mat) {\n    mat[c(\"Normal Cognition\", \"MCI\", \"Dementia\"), c(\"Normal Cognition\", \"MCI\", \"Dementia\")] |&gt;\n        normalise()\n    }) |&gt;\n  purrr::map2_df(.y = c(seq(2016, 2020, by = 2)), .f = reshape_matrix) |&gt;\n  mutate(\n    transition_prob = round(transition_prob, digits = 3),\n    from = factor(from, levels = c(\"Normal Cognition\", \"MCI\", \"Dementia\"))\n  )\n\nDT::datatable(\n  tran_prob_long,\n  filter = \"top\",\n  colnames = c(\"Probability\" = \"transition_prob\"),\n  options = list(pageLength = 6, autoWidth = TRUE)\n)\n\n\n\n\n\n\nfor(wave in c(seq(2016, 2020, by = 2))){\n  print(plot_transition_wave(data = tran_prob_long, wave = wave))\n}",
    "crumbs": [
      "Analysis",
      "Models",
      "Continous Time Markov Model"
    ]
  },
  {
    "objectID": "analysis/continous-markov.html#multi-state-markov-model",
    "href": "analysis/continous-markov.html#multi-state-markov-model",
    "title": "Continous Time Markov Model",
    "section": "Multi-State Markov Model",
    "text": "Multi-State Markov Model\nNow that we have an idea of the disease progression across time we are interested in the effect of different covariates on these transitions. For this, we can fit a multi-state Markov model. Multi-state models (MSMs) provide a comprehensive view of the disease process and make risk-factors analysis and long-term predictions more easily. The conditional distribution of the status of an individual participant at an arbitrary examination given their status at previous examinations was assumed to have the Markov property. That is the distribution of the forthcoming state X_{n+1} depends only on the current state X_n and doesn’t depend on the previous ones X_{n-1}, X_{n-2}, \\dots, X_1.\nPr(X_{n+1} = x_{n+1} \\; \\vert \\; X_1 = x_1, X_2 = x_2, \\dots, X_n = x_n) = Pr(X_{n+1} = x_{n+1} \\; \\vert \\; X_n = x_n)\n\nData preperation\nFor our model we are going to look at several different covariates:\n\nGender: 0 = \\text{Male;} \\; 1 = \\text{Female}\nAge: \\text{Range} \\; = 50 - 91\nEducation: 0 = \\text{No Degree;} \\; 1 = \\text{High School Degree;} \\; 2 = \\text{Further Education}\nNumber of cardiovascular risk factors: \\text{Range} \\; = 0 - 4\nProcrastination: \\text{Range} \\; = 4 - 60\n\n\ncols &lt;- c(\n  \"ID\", \"Gender\", \"Age\", \"Education_tri\", \n  paste0(\"Cardio_risk_\", seq(16, 22, by = 2)), \n  paste0(\"Total_dep_20\", seq(16, 22, by = 2)), \"Total_p\")\n\nmarkov_data &lt;- data |&gt;\n  extract_years(seq(2016, 2022, by = 2)) |&gt;\n  na.omit() |&gt;\n  inner_join(data[, cols], by = \"ID\") |&gt;\n  pivot_data() |&gt;\n  backtrack_age(base_year = 2016, current_year = 2022) |&gt;\n  group_by(ID) |&gt;\n  mutate(\n    Age = min(Age), # Baseline age\n    Cardio_risk = Cardio_risk[Wave == 1],\n    Depression = Depression[Wave == 1]\n    ) |&gt;\n  ungroup() |&gt;\n  filter(Age &gt;= 50) # Only looking at older adults\n\nDT::datatable(\n  markov_data,\n  filter = \"top\",\n  options = list(pageLength = 6, autoWidth = TRUE)\n)\n\n\n\n\n\nLet’s look at a state table to visualize the amount of transitions over time\n\nmarkov_data |&gt;\n  select(ID, Wave, Status) |&gt;\n  mutate(Status = case_when(\n    Status == 1 ~ \"Normal Cognition\", \n    Status == 2 ~ \"MCI\", \n    Status == 3 ~ \"Dementia\")) |&gt;\n  msm::statetable.msm(state = Status, subject = ID)\n\n                  to\nfrom               Dementia  MCI Normal Cognition\n  Dementia               79    0                0\n  MCI                    31  128              180\n  Normal Cognition       19  215             2000\n\n\n\n\nModelling\n\nDefining a q-matrix\nThe Q matrix (also known as the transition intensity matrix or generator matrix) defines the rates at which transitions occur between states in the model.\nIt is a square matrix where:\n\nEach row corresponds to a from state in the model.\nEach column corresponds to a to state in the model.\nThe off-diagonal elements q_{ij} represent the transition rate from state i to state j.\n\nFor a model with n states, the Q matrix has the following structure\n\nQ = \\begin{bmatrix}\nq_{11} & q_{12} & \\cdots & q_{1n} \\\\\nq_{21} & q_{22} & \\cdots & q_{2n} \\\\\n\\vdots & \\vdots & \\ddots &\\vdots  \\\\\nq_{n1} & q_{n2} & \\cdots & q_{nn}\n\\end{bmatrix}\n\n\n# Creating transition matrix\n# Define possible transitions\nstates &lt;- c(\"Normal Cognition\", \"MCI\", \"Dementia\")\n\n# Theoretical transition probabilities\nq_matrix &lt;- rbind(\n  c(0.75, 0.20, 0.05),  # From Normal, can transition to MCI or Dementia\n  c(0.25, 0.50, 0.25),  # From MCI, can transition to Normal or Dementia\n  c(0.00, 0.00, 1.00)         # From Dementia, no transitions (absorbing state)\n)\n\nrownames(q_matrix) &lt;- states\ncolnames(q_matrix) &lt;- states\n\nq_matrix\n\n                 Normal Cognition MCI Dementia\nNormal Cognition             0.75 0.2     0.05\nMCI                          0.25 0.5     0.25\nDementia                     0.00 0.0     1.00\n\n\n\n\n\nFitting\nWe will fit three different multi-state models\n\nA model with no covariates\nA multivariate model with covariates acting on all transitions\nA multivariate model with covariates (and interactions) acting on all transitions\nA multivariate model with covariates acting on only NC &lt;-&gt; MCI & MCI - Dementia\nA multivariate model with covariates (and interactions) acting on only NC &lt;-&gt; MCI & MCI - Dementia\n\n\n# Fitting model with no covariates\nmodel_1 &lt;- msm::msm(\n  formula = Status ~ Wave,\n  subject = ID,\n  data = markov_data,\n  qmatrix = q_matrix,\n  obstype = 1,\n  method = \"BFGS\", \n  gen.inits = TRUE,\n  control = list(\n    fnscale = 5000, \n    maxit = 2000 # To reach convergence\n  ))\n\n# Multivariate model: covariates acting on all transitions\nmodel_2 &lt;- msm::msm(\n  formula = Status ~ Wave,\n  subject = ID,\n  data = markov_data,\n  qmatrix = q_matrix,\n  covariates = ~ Gender + Age + Education_tri + Cardio_risk + Depression + Total_p,\n  obstype = 1,\n  gen.inits = TRUE,\n  method = \"BFGS\",\n  control = list(\n    fnscale = 6000, \n    maxit = 2000 # To reach convergence\n  ))\n\n# Multivariate model: covariates acting on all transitions (with interaction)\nmodel_3 &lt;- msm::msm(\n  formula = Status ~ Wave,\n  subject = ID,\n  data = markov_data,\n  qmatrix = q_matrix,\n  covariates = ~ Gender + Age + Education_tri + Cardio_risk + (Depression * Total_p),\n  obstype = 1,\n  gen.inits = TRUE,\n  method = \"BFGS\",\n  control = list(\n    fnscale = 5000, \n    maxit = 2000 # To reach convergence\n  ))\n\n# Multivariate model: covariates acting on NC &lt;-&gt; MCI and MCI -&gt; D\nmodel_4 &lt;- msm::msm(\n  formula = Status ~ Wave,\n  subject = ID,\n  data = markov_data,\n  qmatrix = q_matrix,\n  covariates = list(\n    \"1-2\" = ~ Gender + Age + Education_tri + Cardio_risk + Depression + Total_p,\n    \"2-1\" = ~ Gender + Age + Education_tri + Cardio_risk + Depression + Total_p,\n    \"2-3\" = ~ Gender + Age + Education_tri + Cardio_risk + Depression + Total_p\n  ),\n  obstype = 1,\n  gen.inits = TRUE,\n  method = \"BFGS\",\n  control = list(\n    fnscale = 5000, \n    maxit = 2000 # To reach convergence\n  ))\n\n\n# Multivariate model: covariates acting on NC &lt;-&gt; MCI and MCI -&gt; D (with interaction)\nmodel_5 &lt;- msm::msm(\n  formula = Status ~ Wave,\n  subject = ID,\n  data = markov_data,\n  qmatrix = q_matrix,\n  covariates = list(\n    \"1-2\" = ~ Gender + Age + Education_tri + Cardio_risk + (Depression * Total_p),\n    \"2-1\" = ~ Gender + Age + Education_tri + Cardio_risk + (Depression * Total_p),\n    \"2-3\" = ~ Gender + Age + Education_tri + Cardio_risk + (Depression * Total_p)\n  ),\n  obstype = 1,\n  gen.inits = TRUE,\n  method = \"BFGS\",\n  control = list(\n    fnscale = 5000, \n    maxit = 2000 # To reach convergence\n  ))\n\n\nModel Checking\nAfter fitting each of our models we can extract some goodness of fit criteria\n\nlog_l &lt;- c(logLik(model_1), \n           logLik(model_2), \n           logLik(model_3), \n           logLik(model_4), \n           logLik(model_5))\n\naic &lt;- AIC(model_1, model_2, model_3, model_4, model_5)\n\n# Very small difference between model 2 and 3 (makes sense)\ncbind(log_l, aic) |&gt;\n  tibble::rownames_to_column(\"Model\") |&gt;\n  mutate(Model = stringr::str_remove(Model, \"model_\"))\n\n  Model     log_l df      AIC\n1     1 -1128.003  4 2264.007\n2     2 -1006.632 32 2077.265\n3     3 -1000.512 36 2073.024\n4     4 -1008.524 25 2067.048\n5     5 -1002.455 28 2060.910\n\n# Likelihood ratio test\nlmtest::lrtest(model_1, model_2, model_3, model_4, model_5)\n\nLikelihood ratio test\n\nModel 1: Status ~ Wave\nModel 2: Status ~ Wave\nModel 3: Status ~ Wave\nModel 4: Status ~ Wave\nModel 5: Status ~ Wave\n  #Df  LogLik  Df   Chisq Pr(&gt;Chisq)    \n1   4 -1128.0                           \n2  32 -1006.6  28 242.742  &lt; 2.2e-16 ***\n3  36 -1000.5   4  12.241   0.015647 *  \n4  25 -1008.5 -11  16.025   0.140218    \n5  28 -1002.5   3  12.138   0.006925 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nWe can also look at a measure of how well the model fits the data using a test proposed by [@gentleman1994]. The function plots the observed numbers of individuals occupying a state at a series of times against forecasts from the fitted model, for each state (Figure 2).\n\n# Plotting fitted vs. observed values\ng1 &lt;- gentleman_test(data = msm::prevalence.msm(model_1), \n                     model = \"Model 1\")\ng2 &lt;- gentleman_test(data = msm::prevalence.msm(model_2), \n                     model = \"Model 2\")\ng3 &lt;- gentleman_test(data = msm::prevalence.msm(model_3), \n                     model = \"Model 3\")\ng4 &lt;- gentleman_test(data = msm::prevalence.msm(model_4), \n                     model = \"Model 4\")\ng5 &lt;- gentleman_test(data = msm::prevalence.msm(model_5), \n                     model = \"Model 5\")\n\nggpubr::ggarrange(g1, g2, g3, g4, g5, \n                  common.legend = TRUE, \n                  nrow = 5,\n                  heights = c(2, 2, 2, 2, 2), \n                  legend = \"bottom\")\n\n\n\n\n\n\n\nFigure 2: Fitted values versus observed values\n\n\n\n\n\n\n\nHazard ratios\nWe now present hazard ratios for each of our fitted models. These ratios represent how the instantaneous risk of making a particular transition is modified by the covariate.\n\nModel 2Model 3Model 4Model 5\n\n\nFigure 3 presents hazard ratios from model 2 (our multivariate model with covariates acting on all transitions) for each covariate.\n\n# Plotting hazard ratios\nmodel_2 |&gt;\n  msm::hazard.msm() |&gt;\n  process_hr() |&gt;\n  calculate_p_value() |&gt;\n  plot_hr()\n\n\n\n\n\n\n\nFigure 3: Ouputted hazard ratios from Markov model. Green bars represent a decreased risk of transition while red bars indicate an increased risk of transition.\n\n\n\n\n\n\n\nFigure 4 presents hazard ratios from model 3 (our multivariate model with covariates (and interactions) acting on all transitions) for each covariate.\n\n# Plotting hazard ratios\nmodel_3 |&gt;\n  msm::hazard.msm() |&gt;\n  process_hr() |&gt;\n  calculate_p_value() |&gt;\n  plot_hr()\n\n\n\n\n\n\n\nFigure 4: Ouputted hazard ratios from Markov model. Green bars represent a decreased risk of transition while red bars indicate an increased risk of transition.\n\n\n\n\n\n\n\nFigure 5 presents hazard ratios for model 4 (our multivariate model with covariates acting on only NC &lt;-&gt; MCI & MCI -&gt; Dementia) for each covariate\n\n# Plotting hazard ratios\nmodel_4 |&gt;\n  msm::hazard.msm() |&gt;\n  process_hr() |&gt;\n  calculate_p_value() |&gt;\n  plot_hr()\n\n\n\n\n\n\n\nFigure 5: Ouputted hazard ratios from Markov model. Green bars represent a decreased risk of transition while red bars indicate an increased risk of transition.\n\n\n\n\n\n\n\nFigure 6 presents hazard ratios for model 5 (our multivariate model with covariates (and interactions) acting on only NC &lt;-&gt; MCI & MCI -&gt; Dementia) for each covariate\n\n# Plotting hazard ratios\nmodel_5 |&gt;\n  msm::hazard.msm() |&gt;\n  process_hr() |&gt;\n  calculate_p_value() |&gt;\n  plot_hr()\n\n\n\n\n\n\n\nFigure 6: Ouputted hazard ratios from Markov model. Green bars represent a decreased risk of transition while red bars indicate an increased risk of transition.",
    "crumbs": [
      "Analysis",
      "Models",
      "Continous Time Markov Model"
    ]
  },
  {
    "objectID": "analysis/data-final.html",
    "href": "analysis/data-final.html",
    "title": "Download final data",
    "section": "",
    "text": "The cleaned data is available in three formats:\n\nCSV file for any program\n.rds file for R (load with df &lt;- readRDS(\"data.rds\"))\n.dta file for Stata (load with use \"data.dta\")\n\n\nData\n  data.csv     data.rds     data.dta",
    "crumbs": [
      "Data",
      "Download final data"
    ]
  },
  {
    "objectID": "analysis/discrete-markov.html",
    "href": "analysis/discrete-markov.html",
    "title": "Discrete Time Markov Model",
    "section": "",
    "text": "Check out my packages\n# Packages ---------------------------------------------------------------------\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(ggplot2)\nlibrary(patchwork)\n\n\n\n\n\n\n\nCheck out my functions\n# Functions --------------------------------------------------------------------\nextract_years &lt;- function(data, years, impute = TRUE, cog_total = FALSE, absorbing = TRUE) {\n  # Extracts cognitive function data for specified years from a dataset.\n  # Converts numeric cognitive status codes (1, 2, 3) into descriptive labels\n  # (\"Normal Cognition\", \"MCI\", \"Dementia\") for easier interpretation.\n  # Arguments:\n  #   - data: The input dataset containing cognitive function data.\n  #   - years: A vector of years for which data should be extracted.\n  # Returns:\n  #   - A dataset with ID and cognitive status columns for the specified years.\n  \n  # Create dynamic column names based on the years provided\n  cogfunction_cols &lt;- paste0(\"cogfunction\", years)\n  cogtotal_cols    &lt;- paste0(\"cogtot27_imp\", years)\n  \n  if(cog_total == FALSE) {\n    data &lt;- data |&gt;\n      # Select only the ID column and cognitive function columns for the specified years\n      select(ID, any_of(cogfunction_cols)) |&gt;\n      mutate(across(!c(ID), ~ case_when(\n        .x == 1 ~ \"Normal Cognition\",\n        .x == 2 ~ \"MCI\",\n        .x == 3 ~ \"Dementia\",\n        TRUE ~ NA_character_  # To handle missing/other cases\n      )))\n  } else {\n    data &lt;- data |&gt;\n      # Select only the ID column and cognitive function columns for the specified years\n      select(ID, any_of(cogtotal_cols)) |&gt;\n      rename_with( .cols = !ID, .fn = ~ stringr::str_replace(\n        string = .x,\n        pattern = \"cogtot27_imp\", \n        replacement = \"cog_score_\"))\n  }\n  \n  if(impute == TRUE){\n    data &lt;- data |&gt;\n      tidyr::pivot_longer(\n        cols = !ID,\n        names_to = \"Wave\",\n        values_to = \"Status\") |&gt;\n      group_by(ID) |&gt;\n      tidyr::fill(Status, .direction = \"down\") |&gt;\n      ungroup() |&gt;\n      tidyr::pivot_wider(names_from = \"Wave\", values_from = \"Status\")\n  }\n  \n  if(absorbing == TRUE) {\n    data &lt;- data |&gt;\n      tidyr::pivot_longer(\n        cols = !ID,\n        names_to = \"Wave\",\n        values_to = \"Status\") |&gt;\n      group_by(ID) |&gt;\n      mutate(Status = ifelse(cumany(Status == \"Dementia\"), \"Dementia\", Status)) |&gt;\n      ungroup() |&gt;\n      tidyr::pivot_wider(names_from = \"Wave\", values_from = \"Status\")\n  }\n  \n  return(data)\n}\n\npivot_and_factorise &lt;- function(data) {\n  # Converts cognitive function data from wide to long format and factorizes key variables.\n  # Pivots multiple cogfunction columns into wave/status pairs and converts categorical\n  # variables (Gender, Education, status) to factors with meaningful labels.\n  # Arguments:\n  #   - data: Dataset containing cognitive function variables in wide format\n  # Returns:\n  #   - Long-format dataset with factorized variables, ordered by ID and wave\n  # \n  \n  # Pivoting depression variables\n  # depression &lt;- data |&gt;\n  #   select(starts_with(\"Total_dep\")) |&gt;\n  #   tidyr::pivot_longer(\n  #     cols = everything(), names_to = \"Remove\", values_to = \"Depression\") |&gt;\n  #   select(Depression)\n\n  # Pivoting cardio variables\n  # cardio &lt;- data |&gt;\n  #   select(starts_with(\"Cardio_risk\")) |&gt;\n  #   tidyr::pivot_longer(\n  #     cols = everything(), names_to = \"Remove\", values_to = \"Cardio\") |&gt;\n  #   select(Cardio)\n\n\n  data |&gt;\n    # select(!starts_with(c(\"Total_dep\", \"Cardio_risk\"))) |&gt;\n    tidyr::pivot_longer(\n      cols = starts_with(\"cogfunction\"), names_to = \"wave\",\n      names_prefix = \"cogfunction\", values_to = \"status\") |&gt;\n    mutate(\n      Gender = factor(Gender, levels = c(0, 1)),\n      Education_tri = factor(Education_tri, levels = c(0, 1, 2)),\n      wave = factor(wave),\n      status = factor(status, \n                      levels = c(\"Normal Cognition\", \"MCI\", \"Dementia\"),\n                      labels = c(1, 2, 3))) |&gt;\n    relocate(wave, .after = ID) |&gt;\n    relocate(status, .after = wave)\n    #cbind(depression, cardio)\n}\n\ncreate_transition_table &lt;- function(year_to, year_from) {\n  # Creates a transition frequency table between two specified years of cognitive status data.\n  # Calculates row sums and total observations for transition analysis.\n  # Arguments:\n  #   - year_to: Target year for transitions (character or numeric)\n  #   - year_from: Origin year for transitions (character or numeric)\n  # Returns:\n  #   - List containing: \n  #     - transition frequency table\n  #     - row sums\n  #     - total observations\n  # \n  tbl &lt;- table(\n    table_data[[paste0(\"HRS_\", year_to)]],\n    table_data[[paste0(\"HRS_\", year_from)]],\n    dnn = c(year_to, year_from)\n  )\n  \n  # Calculate row sums and total\n  row_sums &lt;- rowSums(tbl)\n  total &lt;- sum(row_sums)\n  \n  # Return as a list with both the table and summary stats\n  list(\n    table = tbl,\n    row_sums = row_sums,\n    total = total\n  )\n}\n\ncreate_transition_dataset &lt;- function(data, transition_results) {\n  # Combines multiple transition tables into a single analysis-ready dataset.\n  # Formats period labels, ensures consistent factor levels, and structures data for visualization.\n  # Arguments:\n  #   - data: List of year pairs to process (e.g., list(c(2016,2018)))\n  #   - transition_results: List containing transition tables from create_transition_table()\n  # Returns:\n  #   - Tidy dataset with transition frequencies between all specified periods\n  # \n  data |&gt;\n    purrr::map_dfr(~ {\n      period_name &lt;- paste(.x[2], .x[1], sep = \" - \")\n      tbl &lt;- transition_results[[paste(.x[2], .x[1], sep = \"-\")]]$table\n      \n      as.data.frame(tbl) |&gt;\n        rename(t_minus_1 = 1, t = 2) %&gt;%  # Positional renaming\n        mutate(Period = period_name, .before = t_minus_1)\n    }) |&gt;\n    mutate(\n      Period = stringr::str_replace(Period, \"(\\\\d+) - (\\\\d+)\", \"\\\\2 - \\\\1\"),\n      Period = factor(Period, levels = c(\"2016 - 2018\", \"2018 - 2020\", \"2020 - 2022\")),\n      t_minus_1 = factor(t_minus_1, levels = c(\"Normal Cognition\", \"MCI\", \"Dementia\")),\n      t = factor(t, levels = c(\"Normal Cognition\", \"MCI\", \"Dementia\"))\n    )\n}\n\ncreate_transitions &lt;- function(data, absorbing = FALSE){\n  # Reshapes data from wide to long format to track cognitive status transitions over time.\n  # Calculates the next wave's cognitive status for each individual and creates a transition column.\n  # Optionally treats \"Dementia\" as an absorbing state, meaning once an individual is classified\n  # with dementia, their status cannot change in subsequent waves.\n  # Arguments:\n  #   - data: The dataset containing cognitive status data.\n  #   - absorbing: A logical flag indicating whether \"Dementia\" should be treated \n  #   as an absorbing state.\n  # Returns:\n  #   - A dataset with transition information, including current and next wave statuses.\n  \n  # Reshape the data from wide to long format to track cognitive status over waves\n  data &lt;- data |&gt;\n    select(ID, starts_with(\"cogfunction\")) |&gt;\n    tidyr::pivot_longer(cols = !ID,\n                        names_to = \"Wave\",\n                        values_to = \"Status\") |&gt;\n    mutate(Wave = as.factor(stringr::str_replace(Wave, \"cogfunction\", \"\"))) |&gt;\n    # Arrange by ID and Wave to prepare for transition calculation\n    arrange(ID, Wave) |&gt;\n    group_by(ID) |&gt;\n    # Get the next wave's cognitive status for each person\n    mutate(next_wave_status = lead(Status)) |&gt;\n    ungroup()\n  \n  # We can optionally specify dementia as an absorbing state\n  # Once an individual is classified with dementia they cannot be classified\n  # with anything else \n  if(absorbing == TRUE) {\n    data &lt;- data |&gt;\n      group_by(ID) |&gt;\n      mutate(\n        Status = ifelse(cumany(Status == \"Dementia\"), \"Dementia\", Status),\n        next_wave_status = ifelse(cumany(Status == \"Dementia\"), \"Dementia\", next_wave_status),\n        transition = paste(Status, next_wave_status, sep = \" to \")\n      ) |&gt;\n      filter(Wave %in% c(2016, 2018, 2020))\n  }\n  \n  # Filter out rows where either the current or next status is missing\n  data &lt;- data |&gt;\n    group_by(ID) |&gt;\n    filter(!is.na(Status), !is.na(next_wave_status)) |&gt;\n    ungroup() |&gt;\n    # Create a new column representing the transition from one status to the next\n    mutate(\n      transition = paste(Status, next_wave_status, sep = \" to \"),\n      transition = factor(\n        transition, \n        levels = c(\"Normal Cognition to Normal Cognition\", \"Normal Cognition to MCI\",\n                   \"Normal Cognition to Dementia\", \"MCI to Normal Cognition\", \"MCI to MCI\",\n                   \"MCI to Dementia\", \"Dementia to Dementia\") \n      ))\n  \n  return(data)\n}\n\nobserved_transition_matrix &lt;- function(data) {\n  # Converts transition data into a properly formatted probability transition matrix.\n  # Ensures consistent state ordering and converts proportions to matrix format suitable\n  # for multi-state modeling and visualization.\n  # Arguments:\n  #   - data: Transition dataset from create_transitions()\n  # Returns:\n  #   - Square transition probability matrix with states as row/column names\n  # \n  # The order I want my matrix in\n  state_order &lt;- c(\"Normal Cognition\", \"MCI\", \"Dementia\")\n  \n  data |&gt;\n    group_by(Status, next_wave_status) |&gt;\n    summarise(freq = n(),  .groups = \"drop\") |&gt;\n    group_by(Status) |&gt;\n    mutate(freq = round(proportions(freq), 3)) |&gt;\n    ungroup() |&gt;\n    complete(Status, next_wave_status, fill = list(freq = 0)) |&gt;\n    tidyr::pivot_wider(names_from = next_wave_status, values_from = freq, names_sort = TRUE) |&gt;\n    tibble::column_to_rownames(\"Status\") |&gt;\n    select(all_of(state_order)) |&gt;\n    _[state_order, ] |&gt;\n    as.matrix()\n}\n\nnormalise &lt;- function(x) {\n  # Normalizes a matrix so that each row sums to 1.\n  # Arguments:\n  #   - x: The input matrix to normalize.\n  # Returns:\n  #   - A normalized matrix where each row sums to 1.\n  x / rowSums(x)\n}\n\nreshape_matrix &lt;- function(matrix) {\n  # Converts a transition probability matrix into a tidy format suitable for visualization.\n  # Transforms the matrix into long format with explicit factor levels for cognitive states,\n  # preserving the original ordering while preparing for ggplot compatibility.\n  # Arguments:\n  #   - matrix: A square transition probability matrix with states as row/column names\n  # Returns:\n  #   - Tidy data frame with columns:\n  #     * from_state: Factor indicating origin cognitive state\n  #     * to_state: Factor indicating destination cognitive state (reversed for plotting)\n  #     * probability: Numeric transition probability values\n  \n  matrix |&gt;\n    as.data.frame() |&gt;\n    mutate(\n      from_state = factor(c(\n        \"Normal cognition\", \"MCI\", \"Dementia\"),\n        levels = c(\"Normal cognition\", \"MCI\", \"Dementia\"))\n    ) |&gt;\n    reshape2::melt(\n      id.vars = \"from_state\", \n      variable.name = \"to_state\", \n      value.name = \"probability\") |&gt;\n    mutate(to_state = factor(to_state, levels = rev(levels(to_state))))\n}\n\nplot_transition_matrix &lt;- function(matrix, observed = TRUE) {\n  # Creates a heatmap visualization of cognitive state transition probabilities.\n  # Generates either observed or estimated transition plots with consistent formatting,\n  # including labeled probability values and a diverging color scale for emphasis.\n  # Arguments:\n  #   - matrix: Tidy transition matrix from reshape_matrix()\n  #   - observed: Logical flag indicating whether data represents observed (TRUE) \n  #               or estimated (FALSE) transitions\n  # Returns:\n  #   - ggplot heatmap object with:\n  #     * State transitions as cells\n  #     * Probability values displayed numerically\n  #     * Custom color scale and axis formatting\n  \n  if(observed == TRUE) {\n    subtitle &lt;- \"Observed state transitions between assessment waves\"\n  } else {\n    subtitle &lt;- \"Estimated state transitions between assessment waves\"\n  }\n  \n  matrix |&gt;\n    ggplot(aes(x = from_state, y = to_state, fill = probability)) +\n    geom_tile(color = \"white\", linewidth = 0.5) +\n    geom_text(\n      aes(label = format(round(probability, 3), nsmall = 3)),\n      size = 4.5, \n      color = \"#212427\",\n      fontface = \"bold\") +\n    colorspace::scale_fill_continuous_diverging(\n      palette = \"Blue-Red 3\", mid = 0.50, alpha = 0.5, \n      limits = c(0, 1), name = \"Transition \\nProbability\") +\n    labs(title = \"Transition Probabilities Across Cognitive States\",\n         subtitle = subtitle,\n         x = \"Previous State (t - 1)\", \n         y = \"Current State (t)\") +\n    theme(\n      axis.text = element_text(size = 10),\n      axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1),\n      legend.position = \"right\",\n      legend.text = element_text(size = 9),\n      panel.grid = element_blank()\n    )\n}\n\ntran_stack_graph &lt;- function(data) {\n  # Creates stacked bar charts visualizing cognitive state transitions across time periods.\n  # Shows composition of current states by previous state, faceted by observation period.\n  # Arguments:\n  #   - data: Transition dataset from create_transition_dataset()\n  # Returns:\n  #   - ggplot object showing stacked transition proportions\n  # \n  data |&gt;\n    ggplot(aes(x = t_minus_1, y = Freq, fill = t)) +\n    geom_col(position = \"stack\", colour = \"black\") +\n    facet_wrap(~ Period, ncol = 3) +\n    labs(\n      x = \"Previous State (t-1)\", \n      y = \"Count\",\n      title = \"Outcomes by Prior Cognitive State\",\n      fill = \"Current State (t)\"\n    ) +\n    ggokabeito::scale_fill_okabe_ito() +\n    ggeasy::easy_move_legend(\"bottom\")\n}\n\ntran_heat_map &lt;- function(data) {\n  # Generates heatmap visualization of transition frequencies between cognitive states.\n  # Uses color intensity and labeled values to show transition patterns across time periods.\n  # Arguments:\n  #   - data: Transition dataset from create_transition_dataset()\n  # Returns:\n  #   - ggplot heatmap with state transitions as cells\n  # \n  data |&gt;\n    ggplot(aes(x = t_minus_1, y = t, fill = Freq)) +\n    geom_tile(color = \"white\") +\n    geom_text(aes(label = Freq), color = \"black\", size = 3.5) +  # Add counts\n    scale_fill_gradient(low = \"white\", high = \"steelblue\") +\n    facet_wrap(~ Period, ncol = 3) +  # Split by time period\n    labs(\n      x = \"Previous State (t-1)\", \n      y = \"Current State (t)\",\n      title = \"Cognitive State Transitions Between Time Periods\",\n      fill = \"Frequency\"\n    ) +\n    theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n    ggeasy::easy_move_legend(\"bottom\")\n}\n\ntidy_output &lt;- function(fit, multiplicative = FALSE) {\n  output &lt;- broom::tidy(fit, conf.int = TRUE) |&gt;\n    filter(term != \"(Intercept)\") |&gt;\n  mutate(across(c(estimate:p.value), ~ round(x = ., digits = 3)))\n  \n  if(any(output$y.level == \"1\")) {\n    output &lt;- output |&gt;\n      mutate(y.level = case_when(\n      y.level == \"1\" ~ \"MCI - NC\",\n      y.level == \"3\" ~ \"MCI - Dementia\"))\n  } else {\n    output &lt;- output |&gt;\n      mutate(y.level = case_when(\n      y.level == \"2\" ~ \"NC - MCI\",\n      y.level == \"3\" ~ \"NC - Dementia\"))\n  }\n  \n  if(multiplicative == FALSE) {\n    output &lt;- output |&gt;\n      mutate(\n      term = case_when(\n      term == \"Gender1\" ~ \"Being female\",\n      term == \"Education_tri1\" ~ \"High school degree vs. No education\",\n      term == \"Education_tri2\" ~ \"Further education vs. No education\",\n      term == \"Total_dep_2016\" ~ \"Depression Scores (2016)\",\n      term == \"Total_p\" ~ \"Procrastination (2020)\",\n      term == \"status_prev2\" ~ \"Previous state: MCI\",\n      term == \"status_prev3\" ~ \"Previous state: Dementia\",\n      term == \"wave\" ~ \"Time\",\n      TRUE ~ term))\n  } else {\n    output &lt;- output |&gt;\n      mutate(\n      term = case_when(\n      term == \"Gender1\" ~ \"Being female\",\n      term == \"Education_tri1\" ~ \"High school degree vs. No education\",\n      term == \"Education_tri2\" ~ \"Further education vs. No education\",\n      term == \"Depression\" ~ \"Depression Scores (2016)\",\n      term == \"Total_p\" ~ \"Procrastination (2020)\",\n      term == \"status_prev2\" ~ \"Previous state: MCI\",\n      term == \"status_prev3\" ~ \"Previous state: Dementia\",\n      term == \"wave\" ~ \"Time\",\n      term == \"Gender1:wave\" ~ \"Gender & Time\",\n      term == \"Age:wave\" ~ \"Age & Time\",\n      term == \"Education_tri1:wave\" ~ \"Education (0 - 1) & Time\",\n      term == \"Education_tri2:wave\" ~ \"Education (0 - 2) & Time\",\n      term == \"Depression:wave\" ~ \"Depression & Time\",\n      term == \"Total_p:wave\" ~ \"Procrastination & Time\",\n      term == \"status_prev2:wave\" ~ \"Previous state: MCI & Time\",\n      term == \"status_prev3:wave\" ~ \"Previous state: Dementia & Time\",\n      TRUE ~ term))\n  }\n  \n  return(output)\n}\n\ntidy_predictions &lt;- function(predictions) {\n  # Restructures model prediction matrices into tidy format for visualization.\n  # Converts numeric codes to factor labels and reshapes multiple prediction columns\n  # into key-value pairs suitable for ggplot.\n  # Arguments:\n  #   - predictions: Raw prediction matrix from model output\n  # Returns:\n  #   - Long-format dataset with probabilities for each cognitive state\n  #   \n  predictions |&gt;\n    as.matrix() |&gt;\n    as_tibble() |&gt;\n    mutate(\n      Gender = factor(ifelse(Gender == 0, \"Male\", \"Female\"), levels = c(\"Male\", \"Female\")),\n      status_prev = case_when(\n        status_prev == 1 ~ \"Normal Cognition\",\n        status_prev == 2 ~ \"MCI\",\n        status_prev == 3 ~ \"Dementia\",\n      ),\n      status_prev = factor(status_prev, levels = c(\"Normal Cognition\", \"MCI\", \"Dementia\")),\n      Total_p = as.numeric(Total_p),\n      across(c(pred.1:pred.3), as.numeric)) |&gt;\n    tidyr::pivot_longer(cols = c(pred.1:pred.3), names_to = \"status\", values_to = \"prob\") |&gt;\n    mutate(status = case_when(\n      status == \"pred.1\" ~ \"Normal Cognition\",\n      status == \"pred.2\" ~ \"MCI\",\n      status == \"pred.3\" ~ \"Dementia\"\n    ),\n    status = factor(status, levels = c(\"Normal Cognition\", \"MCI\", \"Dementia\")),\n    status_prev = factor(status_prev, levels = c(\"Normal Cognition\", \"MCI\", \"Dementia\")))\n}\n\nplot_predictions_stationary &lt;- function(predictions, variable, x_axis) {\n  # Visualizes predicted transition probabilities from stationary multi-state models.\n  # Shows probability curves by procrastination level, stratified by baseline state.\n  # Arguments:\n  #   - predictions: Tidy predictions from tidy_predictions()\n  # Returns:\n  #   - Faceted ggplot showing predicted probability curves\n  # \n  predictions |&gt;\n    ggplot(aes(x = {{variable}}, y = prob, colour = status_prev)) +\n    geom_line(linewidth = 1) +\n    ggokabeito::scale_colour_okabe_ito() +\n    labs(\n      title = \"Predicted transition probabilities (stationary model)\",\n      x = x_axis, y = \"Probability\", colour = \"Previous State\") +\n    facet_wrap(~ status, labeller = labeller(\n      status = function(x){paste0(\"Transition to: \", x)}\n    ))\n}\n\ncreate_additive_predictions &lt;- function(\n    data, model, var, var_seq, hold_constant = list(Gender = factor(0), Education_tri = factor(0))) {\n  \n  # Set default prediction sequence based on variable type\n  if (is.null(var_seq)) {\n    if (is.numeric(data[[var]])) {\n      predict_seq &lt;- seq(min(data[[var]], max(data[[var]]), length = 200))\n    } else if (is.factor(data[[var]])) {\n      predict_seq &lt;- levels(data[[var]])\n    } else {\n      predict_seq &lt;- unique(data[[var]])\n    }\n  }\n  \n  # Create list of all variables needed for prediction\n  all_vars &lt;- all.vars(formula(model)[-2])  # Get RHS variables from model formula\n  \n  # Create base grid with all variables EXCEPT the prediction variable\n  base_grid &lt;- expand.grid(\n    lapply(all_vars, function(v) {\n      if (v == var) return(NULL)  # Skip prediction variable\n      \n      # Special cases - keep all levels\n      if (v %in% c(\"status_prev\", \"wave\")) {\n        return(unique(data[[v]]))\n      }\n      \n      if (v %in% names(hold_constant)) {\n        # Use user-specified constant value\n        hold_constant[[v]]\n      } else if (is.numeric(data[[v]])) {\n        # Use mean for numeric variables\n        mean(data[[v]], na.rm = TRUE)\n      } else if (is.factor(data[[v]])) {\n        # Use first level for factors\n        factor(levels(data[[v]])[1], levels = levels(data[[v]]))\n      } else {\n        # Default to most common value\n        names(sort(table(data[[v]]), decreasing = TRUE))[1]\n      }\n    }) |&gt; purrr::compact() |&gt; setNames(all_vars[all_vars != var]),\n    KEEP.OUT.ATTRS = FALSE\n  )\n  \n  # Create full prediction grid\n  pred_grid &lt;- base_grid |&gt; \n    tidyr::crossing(!!var := var_seq) |&gt;\n    modelr::add_predictions(model = model, var = \"pred\", type = \"probs\") |&gt;\n    tidy_predictions() |&gt;\n    mutate(wave = factor(wave))\n  \n  return(pred_grid)\n}\n\n\nplot_additive_predictions &lt;- function(data, var, x_label, subtitle) {\n    \n  # Generating predictions\n  data |&gt;\n    ggplot(aes(x = as.numeric(.data[[var]]), y = prob, color = status_prev)) +\n    geom_line(linewidth = 1) +\n    ggokabeito::scale_color_okabe_ito() +\n    labs(\n      title = \"Transition Probabilities (Additive Model)\",\n      subtitle = subtitle,\n      x = x_label, \n      y = \"Predicted Probability\", \n      color = \"Previous State\"\n    ) +\n    facet_grid(wave ~ status, labeller = labeller(\n      wave = function(x) case_when(\n        x == 2 ~ \"Year = 2018\",\n        x == 3 ~ \"Year = 2020\",\n        x == 4 ~ \"Year = 2022\",\n      ),\n      status = function(x) paste(\"Transition to:\", x)\n    )) +\n    theme(\n      plot.subtitle = element_text(hjust = 0.5, size = 12, face = \"bold\"),\n      panel.spacing = unit(1, \"lines\")) \n}\n\nget_time_varying_matrix &lt;- function(model, time_point) {\n  expand.grid(\n    Gender = factor(0),\n    Age = mean(data_stack$Age),\n    Education_tri = factor(0),\n    Total_dep_2016 = mean(data_stack$Total_dep_2016),\n    Total_p = mean(data_stack$Total_p),\n    status_prev = factor(1:3),\n    wave = time_point) |&gt; \n    modelr::add_predictions(model, var = \"prob\", type = \"probs\") |&gt; \n    select(status_prev, starts_with(\"prob\")) |&gt; \n    mutate(\n      status_prev = factor(status_prev, labels = state_names),\n      across(starts_with(\"prob\"), ~round(., 3))) |&gt;\n    tibble::column_to_rownames(\"status_prev\") |&gt;\n    as.matrix() |&gt; `colnames&lt;-`(state_names)\n}\n\n\n\n\n\n\n\nCheck out my theme\ncolour &lt;- \"#212427\"\n\ntheme_set(\n  theme_minimal() +\n    theme(\n      plot.title = element_text(hjust = 0.5, size = 14, colour = colour, face = \"bold\"),\n      plot.subtitle = element_text(hjust = 0.5, size = 12, colour = colour),\n      axis.title = element_text(size = 10, colour = colour, face = \"bold\"),\n      strip.text = element_text(size = 10, colour = colour, face = \"bold\"),\n      legend.title = element_text(hjust = 0.5, colour = colour, face = \"bold\"),\n      ))\n\n\n\n\n\n\ndata &lt;- read.csv(here::here(\"analysis/data/data.csv\"))",
    "crumbs": [
      "Analysis",
      "Models",
      "Discrete Time Markov Model"
    ]
  },
  {
    "objectID": "analysis/discrete-markov.html#setting-up",
    "href": "analysis/discrete-markov.html#setting-up",
    "title": "Discrete Time Markov Model",
    "section": "",
    "text": "Check out my packages\n# Packages ---------------------------------------------------------------------\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(ggplot2)\nlibrary(patchwork)\n\n\n\n\n\n\n\nCheck out my functions\n# Functions --------------------------------------------------------------------\nextract_years &lt;- function(data, years, impute = TRUE, cog_total = FALSE, absorbing = TRUE) {\n  # Extracts cognitive function data for specified years from a dataset.\n  # Converts numeric cognitive status codes (1, 2, 3) into descriptive labels\n  # (\"Normal Cognition\", \"MCI\", \"Dementia\") for easier interpretation.\n  # Arguments:\n  #   - data: The input dataset containing cognitive function data.\n  #   - years: A vector of years for which data should be extracted.\n  # Returns:\n  #   - A dataset with ID and cognitive status columns for the specified years.\n  \n  # Create dynamic column names based on the years provided\n  cogfunction_cols &lt;- paste0(\"cogfunction\", years)\n  cogtotal_cols    &lt;- paste0(\"cogtot27_imp\", years)\n  \n  if(cog_total == FALSE) {\n    data &lt;- data |&gt;\n      # Select only the ID column and cognitive function columns for the specified years\n      select(ID, any_of(cogfunction_cols)) |&gt;\n      mutate(across(!c(ID), ~ case_when(\n        .x == 1 ~ \"Normal Cognition\",\n        .x == 2 ~ \"MCI\",\n        .x == 3 ~ \"Dementia\",\n        TRUE ~ NA_character_  # To handle missing/other cases\n      )))\n  } else {\n    data &lt;- data |&gt;\n      # Select only the ID column and cognitive function columns for the specified years\n      select(ID, any_of(cogtotal_cols)) |&gt;\n      rename_with( .cols = !ID, .fn = ~ stringr::str_replace(\n        string = .x,\n        pattern = \"cogtot27_imp\", \n        replacement = \"cog_score_\"))\n  }\n  \n  if(impute == TRUE){\n    data &lt;- data |&gt;\n      tidyr::pivot_longer(\n        cols = !ID,\n        names_to = \"Wave\",\n        values_to = \"Status\") |&gt;\n      group_by(ID) |&gt;\n      tidyr::fill(Status, .direction = \"down\") |&gt;\n      ungroup() |&gt;\n      tidyr::pivot_wider(names_from = \"Wave\", values_from = \"Status\")\n  }\n  \n  if(absorbing == TRUE) {\n    data &lt;- data |&gt;\n      tidyr::pivot_longer(\n        cols = !ID,\n        names_to = \"Wave\",\n        values_to = \"Status\") |&gt;\n      group_by(ID) |&gt;\n      mutate(Status = ifelse(cumany(Status == \"Dementia\"), \"Dementia\", Status)) |&gt;\n      ungroup() |&gt;\n      tidyr::pivot_wider(names_from = \"Wave\", values_from = \"Status\")\n  }\n  \n  return(data)\n}\n\npivot_and_factorise &lt;- function(data) {\n  # Converts cognitive function data from wide to long format and factorizes key variables.\n  # Pivots multiple cogfunction columns into wave/status pairs and converts categorical\n  # variables (Gender, Education, status) to factors with meaningful labels.\n  # Arguments:\n  #   - data: Dataset containing cognitive function variables in wide format\n  # Returns:\n  #   - Long-format dataset with factorized variables, ordered by ID and wave\n  # \n  \n  # Pivoting depression variables\n  # depression &lt;- data |&gt;\n  #   select(starts_with(\"Total_dep\")) |&gt;\n  #   tidyr::pivot_longer(\n  #     cols = everything(), names_to = \"Remove\", values_to = \"Depression\") |&gt;\n  #   select(Depression)\n\n  # Pivoting cardio variables\n  # cardio &lt;- data |&gt;\n  #   select(starts_with(\"Cardio_risk\")) |&gt;\n  #   tidyr::pivot_longer(\n  #     cols = everything(), names_to = \"Remove\", values_to = \"Cardio\") |&gt;\n  #   select(Cardio)\n\n\n  data |&gt;\n    # select(!starts_with(c(\"Total_dep\", \"Cardio_risk\"))) |&gt;\n    tidyr::pivot_longer(\n      cols = starts_with(\"cogfunction\"), names_to = \"wave\",\n      names_prefix = \"cogfunction\", values_to = \"status\") |&gt;\n    mutate(\n      Gender = factor(Gender, levels = c(0, 1)),\n      Education_tri = factor(Education_tri, levels = c(0, 1, 2)),\n      wave = factor(wave),\n      status = factor(status, \n                      levels = c(\"Normal Cognition\", \"MCI\", \"Dementia\"),\n                      labels = c(1, 2, 3))) |&gt;\n    relocate(wave, .after = ID) |&gt;\n    relocate(status, .after = wave)\n    #cbind(depression, cardio)\n}\n\ncreate_transition_table &lt;- function(year_to, year_from) {\n  # Creates a transition frequency table between two specified years of cognitive status data.\n  # Calculates row sums and total observations for transition analysis.\n  # Arguments:\n  #   - year_to: Target year for transitions (character or numeric)\n  #   - year_from: Origin year for transitions (character or numeric)\n  # Returns:\n  #   - List containing: \n  #     - transition frequency table\n  #     - row sums\n  #     - total observations\n  # \n  tbl &lt;- table(\n    table_data[[paste0(\"HRS_\", year_to)]],\n    table_data[[paste0(\"HRS_\", year_from)]],\n    dnn = c(year_to, year_from)\n  )\n  \n  # Calculate row sums and total\n  row_sums &lt;- rowSums(tbl)\n  total &lt;- sum(row_sums)\n  \n  # Return as a list with both the table and summary stats\n  list(\n    table = tbl,\n    row_sums = row_sums,\n    total = total\n  )\n}\n\ncreate_transition_dataset &lt;- function(data, transition_results) {\n  # Combines multiple transition tables into a single analysis-ready dataset.\n  # Formats period labels, ensures consistent factor levels, and structures data for visualization.\n  # Arguments:\n  #   - data: List of year pairs to process (e.g., list(c(2016,2018)))\n  #   - transition_results: List containing transition tables from create_transition_table()\n  # Returns:\n  #   - Tidy dataset with transition frequencies between all specified periods\n  # \n  data |&gt;\n    purrr::map_dfr(~ {\n      period_name &lt;- paste(.x[2], .x[1], sep = \" - \")\n      tbl &lt;- transition_results[[paste(.x[2], .x[1], sep = \"-\")]]$table\n      \n      as.data.frame(tbl) |&gt;\n        rename(t_minus_1 = 1, t = 2) %&gt;%  # Positional renaming\n        mutate(Period = period_name, .before = t_minus_1)\n    }) |&gt;\n    mutate(\n      Period = stringr::str_replace(Period, \"(\\\\d+) - (\\\\d+)\", \"\\\\2 - \\\\1\"),\n      Period = factor(Period, levels = c(\"2016 - 2018\", \"2018 - 2020\", \"2020 - 2022\")),\n      t_minus_1 = factor(t_minus_1, levels = c(\"Normal Cognition\", \"MCI\", \"Dementia\")),\n      t = factor(t, levels = c(\"Normal Cognition\", \"MCI\", \"Dementia\"))\n    )\n}\n\ncreate_transitions &lt;- function(data, absorbing = FALSE){\n  # Reshapes data from wide to long format to track cognitive status transitions over time.\n  # Calculates the next wave's cognitive status for each individual and creates a transition column.\n  # Optionally treats \"Dementia\" as an absorbing state, meaning once an individual is classified\n  # with dementia, their status cannot change in subsequent waves.\n  # Arguments:\n  #   - data: The dataset containing cognitive status data.\n  #   - absorbing: A logical flag indicating whether \"Dementia\" should be treated \n  #   as an absorbing state.\n  # Returns:\n  #   - A dataset with transition information, including current and next wave statuses.\n  \n  # Reshape the data from wide to long format to track cognitive status over waves\n  data &lt;- data |&gt;\n    select(ID, starts_with(\"cogfunction\")) |&gt;\n    tidyr::pivot_longer(cols = !ID,\n                        names_to = \"Wave\",\n                        values_to = \"Status\") |&gt;\n    mutate(Wave = as.factor(stringr::str_replace(Wave, \"cogfunction\", \"\"))) |&gt;\n    # Arrange by ID and Wave to prepare for transition calculation\n    arrange(ID, Wave) |&gt;\n    group_by(ID) |&gt;\n    # Get the next wave's cognitive status for each person\n    mutate(next_wave_status = lead(Status)) |&gt;\n    ungroup()\n  \n  # We can optionally specify dementia as an absorbing state\n  # Once an individual is classified with dementia they cannot be classified\n  # with anything else \n  if(absorbing == TRUE) {\n    data &lt;- data |&gt;\n      group_by(ID) |&gt;\n      mutate(\n        Status = ifelse(cumany(Status == \"Dementia\"), \"Dementia\", Status),\n        next_wave_status = ifelse(cumany(Status == \"Dementia\"), \"Dementia\", next_wave_status),\n        transition = paste(Status, next_wave_status, sep = \" to \")\n      ) |&gt;\n      filter(Wave %in% c(2016, 2018, 2020))\n  }\n  \n  # Filter out rows where either the current or next status is missing\n  data &lt;- data |&gt;\n    group_by(ID) |&gt;\n    filter(!is.na(Status), !is.na(next_wave_status)) |&gt;\n    ungroup() |&gt;\n    # Create a new column representing the transition from one status to the next\n    mutate(\n      transition = paste(Status, next_wave_status, sep = \" to \"),\n      transition = factor(\n        transition, \n        levels = c(\"Normal Cognition to Normal Cognition\", \"Normal Cognition to MCI\",\n                   \"Normal Cognition to Dementia\", \"MCI to Normal Cognition\", \"MCI to MCI\",\n                   \"MCI to Dementia\", \"Dementia to Dementia\") \n      ))\n  \n  return(data)\n}\n\nobserved_transition_matrix &lt;- function(data) {\n  # Converts transition data into a properly formatted probability transition matrix.\n  # Ensures consistent state ordering and converts proportions to matrix format suitable\n  # for multi-state modeling and visualization.\n  # Arguments:\n  #   - data: Transition dataset from create_transitions()\n  # Returns:\n  #   - Square transition probability matrix with states as row/column names\n  # \n  # The order I want my matrix in\n  state_order &lt;- c(\"Normal Cognition\", \"MCI\", \"Dementia\")\n  \n  data |&gt;\n    group_by(Status, next_wave_status) |&gt;\n    summarise(freq = n(),  .groups = \"drop\") |&gt;\n    group_by(Status) |&gt;\n    mutate(freq = round(proportions(freq), 3)) |&gt;\n    ungroup() |&gt;\n    complete(Status, next_wave_status, fill = list(freq = 0)) |&gt;\n    tidyr::pivot_wider(names_from = next_wave_status, values_from = freq, names_sort = TRUE) |&gt;\n    tibble::column_to_rownames(\"Status\") |&gt;\n    select(all_of(state_order)) |&gt;\n    _[state_order, ] |&gt;\n    as.matrix()\n}\n\nnormalise &lt;- function(x) {\n  # Normalizes a matrix so that each row sums to 1.\n  # Arguments:\n  #   - x: The input matrix to normalize.\n  # Returns:\n  #   - A normalized matrix where each row sums to 1.\n  x / rowSums(x)\n}\n\nreshape_matrix &lt;- function(matrix) {\n  # Converts a transition probability matrix into a tidy format suitable for visualization.\n  # Transforms the matrix into long format with explicit factor levels for cognitive states,\n  # preserving the original ordering while preparing for ggplot compatibility.\n  # Arguments:\n  #   - matrix: A square transition probability matrix with states as row/column names\n  # Returns:\n  #   - Tidy data frame with columns:\n  #     * from_state: Factor indicating origin cognitive state\n  #     * to_state: Factor indicating destination cognitive state (reversed for plotting)\n  #     * probability: Numeric transition probability values\n  \n  matrix |&gt;\n    as.data.frame() |&gt;\n    mutate(\n      from_state = factor(c(\n        \"Normal cognition\", \"MCI\", \"Dementia\"),\n        levels = c(\"Normal cognition\", \"MCI\", \"Dementia\"))\n    ) |&gt;\n    reshape2::melt(\n      id.vars = \"from_state\", \n      variable.name = \"to_state\", \n      value.name = \"probability\") |&gt;\n    mutate(to_state = factor(to_state, levels = rev(levels(to_state))))\n}\n\nplot_transition_matrix &lt;- function(matrix, observed = TRUE) {\n  # Creates a heatmap visualization of cognitive state transition probabilities.\n  # Generates either observed or estimated transition plots with consistent formatting,\n  # including labeled probability values and a diverging color scale for emphasis.\n  # Arguments:\n  #   - matrix: Tidy transition matrix from reshape_matrix()\n  #   - observed: Logical flag indicating whether data represents observed (TRUE) \n  #               or estimated (FALSE) transitions\n  # Returns:\n  #   - ggplot heatmap object with:\n  #     * State transitions as cells\n  #     * Probability values displayed numerically\n  #     * Custom color scale and axis formatting\n  \n  if(observed == TRUE) {\n    subtitle &lt;- \"Observed state transitions between assessment waves\"\n  } else {\n    subtitle &lt;- \"Estimated state transitions between assessment waves\"\n  }\n  \n  matrix |&gt;\n    ggplot(aes(x = from_state, y = to_state, fill = probability)) +\n    geom_tile(color = \"white\", linewidth = 0.5) +\n    geom_text(\n      aes(label = format(round(probability, 3), nsmall = 3)),\n      size = 4.5, \n      color = \"#212427\",\n      fontface = \"bold\") +\n    colorspace::scale_fill_continuous_diverging(\n      palette = \"Blue-Red 3\", mid = 0.50, alpha = 0.5, \n      limits = c(0, 1), name = \"Transition \\nProbability\") +\n    labs(title = \"Transition Probabilities Across Cognitive States\",\n         subtitle = subtitle,\n         x = \"Previous State (t - 1)\", \n         y = \"Current State (t)\") +\n    theme(\n      axis.text = element_text(size = 10),\n      axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1),\n      legend.position = \"right\",\n      legend.text = element_text(size = 9),\n      panel.grid = element_blank()\n    )\n}\n\ntran_stack_graph &lt;- function(data) {\n  # Creates stacked bar charts visualizing cognitive state transitions across time periods.\n  # Shows composition of current states by previous state, faceted by observation period.\n  # Arguments:\n  #   - data: Transition dataset from create_transition_dataset()\n  # Returns:\n  #   - ggplot object showing stacked transition proportions\n  # \n  data |&gt;\n    ggplot(aes(x = t_minus_1, y = Freq, fill = t)) +\n    geom_col(position = \"stack\", colour = \"black\") +\n    facet_wrap(~ Period, ncol = 3) +\n    labs(\n      x = \"Previous State (t-1)\", \n      y = \"Count\",\n      title = \"Outcomes by Prior Cognitive State\",\n      fill = \"Current State (t)\"\n    ) +\n    ggokabeito::scale_fill_okabe_ito() +\n    ggeasy::easy_move_legend(\"bottom\")\n}\n\ntran_heat_map &lt;- function(data) {\n  # Generates heatmap visualization of transition frequencies between cognitive states.\n  # Uses color intensity and labeled values to show transition patterns across time periods.\n  # Arguments:\n  #   - data: Transition dataset from create_transition_dataset()\n  # Returns:\n  #   - ggplot heatmap with state transitions as cells\n  # \n  data |&gt;\n    ggplot(aes(x = t_minus_1, y = t, fill = Freq)) +\n    geom_tile(color = \"white\") +\n    geom_text(aes(label = Freq), color = \"black\", size = 3.5) +  # Add counts\n    scale_fill_gradient(low = \"white\", high = \"steelblue\") +\n    facet_wrap(~ Period, ncol = 3) +  # Split by time period\n    labs(\n      x = \"Previous State (t-1)\", \n      y = \"Current State (t)\",\n      title = \"Cognitive State Transitions Between Time Periods\",\n      fill = \"Frequency\"\n    ) +\n    theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n    ggeasy::easy_move_legend(\"bottom\")\n}\n\ntidy_output &lt;- function(fit, multiplicative = FALSE) {\n  output &lt;- broom::tidy(fit, conf.int = TRUE) |&gt;\n    filter(term != \"(Intercept)\") |&gt;\n  mutate(across(c(estimate:p.value), ~ round(x = ., digits = 3)))\n  \n  if(any(output$y.level == \"1\")) {\n    output &lt;- output |&gt;\n      mutate(y.level = case_when(\n      y.level == \"1\" ~ \"MCI - NC\",\n      y.level == \"3\" ~ \"MCI - Dementia\"))\n  } else {\n    output &lt;- output |&gt;\n      mutate(y.level = case_when(\n      y.level == \"2\" ~ \"NC - MCI\",\n      y.level == \"3\" ~ \"NC - Dementia\"))\n  }\n  \n  if(multiplicative == FALSE) {\n    output &lt;- output |&gt;\n      mutate(\n      term = case_when(\n      term == \"Gender1\" ~ \"Being female\",\n      term == \"Education_tri1\" ~ \"High school degree vs. No education\",\n      term == \"Education_tri2\" ~ \"Further education vs. No education\",\n      term == \"Total_dep_2016\" ~ \"Depression Scores (2016)\",\n      term == \"Total_p\" ~ \"Procrastination (2020)\",\n      term == \"status_prev2\" ~ \"Previous state: MCI\",\n      term == \"status_prev3\" ~ \"Previous state: Dementia\",\n      term == \"wave\" ~ \"Time\",\n      TRUE ~ term))\n  } else {\n    output &lt;- output |&gt;\n      mutate(\n      term = case_when(\n      term == \"Gender1\" ~ \"Being female\",\n      term == \"Education_tri1\" ~ \"High school degree vs. No education\",\n      term == \"Education_tri2\" ~ \"Further education vs. No education\",\n      term == \"Depression\" ~ \"Depression Scores (2016)\",\n      term == \"Total_p\" ~ \"Procrastination (2020)\",\n      term == \"status_prev2\" ~ \"Previous state: MCI\",\n      term == \"status_prev3\" ~ \"Previous state: Dementia\",\n      term == \"wave\" ~ \"Time\",\n      term == \"Gender1:wave\" ~ \"Gender & Time\",\n      term == \"Age:wave\" ~ \"Age & Time\",\n      term == \"Education_tri1:wave\" ~ \"Education (0 - 1) & Time\",\n      term == \"Education_tri2:wave\" ~ \"Education (0 - 2) & Time\",\n      term == \"Depression:wave\" ~ \"Depression & Time\",\n      term == \"Total_p:wave\" ~ \"Procrastination & Time\",\n      term == \"status_prev2:wave\" ~ \"Previous state: MCI & Time\",\n      term == \"status_prev3:wave\" ~ \"Previous state: Dementia & Time\",\n      TRUE ~ term))\n  }\n  \n  return(output)\n}\n\ntidy_predictions &lt;- function(predictions) {\n  # Restructures model prediction matrices into tidy format for visualization.\n  # Converts numeric codes to factor labels and reshapes multiple prediction columns\n  # into key-value pairs suitable for ggplot.\n  # Arguments:\n  #   - predictions: Raw prediction matrix from model output\n  # Returns:\n  #   - Long-format dataset with probabilities for each cognitive state\n  #   \n  predictions |&gt;\n    as.matrix() |&gt;\n    as_tibble() |&gt;\n    mutate(\n      Gender = factor(ifelse(Gender == 0, \"Male\", \"Female\"), levels = c(\"Male\", \"Female\")),\n      status_prev = case_when(\n        status_prev == 1 ~ \"Normal Cognition\",\n        status_prev == 2 ~ \"MCI\",\n        status_prev == 3 ~ \"Dementia\",\n      ),\n      status_prev = factor(status_prev, levels = c(\"Normal Cognition\", \"MCI\", \"Dementia\")),\n      Total_p = as.numeric(Total_p),\n      across(c(pred.1:pred.3), as.numeric)) |&gt;\n    tidyr::pivot_longer(cols = c(pred.1:pred.3), names_to = \"status\", values_to = \"prob\") |&gt;\n    mutate(status = case_when(\n      status == \"pred.1\" ~ \"Normal Cognition\",\n      status == \"pred.2\" ~ \"MCI\",\n      status == \"pred.3\" ~ \"Dementia\"\n    ),\n    status = factor(status, levels = c(\"Normal Cognition\", \"MCI\", \"Dementia\")),\n    status_prev = factor(status_prev, levels = c(\"Normal Cognition\", \"MCI\", \"Dementia\")))\n}\n\nplot_predictions_stationary &lt;- function(predictions, variable, x_axis) {\n  # Visualizes predicted transition probabilities from stationary multi-state models.\n  # Shows probability curves by procrastination level, stratified by baseline state.\n  # Arguments:\n  #   - predictions: Tidy predictions from tidy_predictions()\n  # Returns:\n  #   - Faceted ggplot showing predicted probability curves\n  # \n  predictions |&gt;\n    ggplot(aes(x = {{variable}}, y = prob, colour = status_prev)) +\n    geom_line(linewidth = 1) +\n    ggokabeito::scale_colour_okabe_ito() +\n    labs(\n      title = \"Predicted transition probabilities (stationary model)\",\n      x = x_axis, y = \"Probability\", colour = \"Previous State\") +\n    facet_wrap(~ status, labeller = labeller(\n      status = function(x){paste0(\"Transition to: \", x)}\n    ))\n}\n\ncreate_additive_predictions &lt;- function(\n    data, model, var, var_seq, hold_constant = list(Gender = factor(0), Education_tri = factor(0))) {\n  \n  # Set default prediction sequence based on variable type\n  if (is.null(var_seq)) {\n    if (is.numeric(data[[var]])) {\n      predict_seq &lt;- seq(min(data[[var]], max(data[[var]]), length = 200))\n    } else if (is.factor(data[[var]])) {\n      predict_seq &lt;- levels(data[[var]])\n    } else {\n      predict_seq &lt;- unique(data[[var]])\n    }\n  }\n  \n  # Create list of all variables needed for prediction\n  all_vars &lt;- all.vars(formula(model)[-2])  # Get RHS variables from model formula\n  \n  # Create base grid with all variables EXCEPT the prediction variable\n  base_grid &lt;- expand.grid(\n    lapply(all_vars, function(v) {\n      if (v == var) return(NULL)  # Skip prediction variable\n      \n      # Special cases - keep all levels\n      if (v %in% c(\"status_prev\", \"wave\")) {\n        return(unique(data[[v]]))\n      }\n      \n      if (v %in% names(hold_constant)) {\n        # Use user-specified constant value\n        hold_constant[[v]]\n      } else if (is.numeric(data[[v]])) {\n        # Use mean for numeric variables\n        mean(data[[v]], na.rm = TRUE)\n      } else if (is.factor(data[[v]])) {\n        # Use first level for factors\n        factor(levels(data[[v]])[1], levels = levels(data[[v]]))\n      } else {\n        # Default to most common value\n        names(sort(table(data[[v]]), decreasing = TRUE))[1]\n      }\n    }) |&gt; purrr::compact() |&gt; setNames(all_vars[all_vars != var]),\n    KEEP.OUT.ATTRS = FALSE\n  )\n  \n  # Create full prediction grid\n  pred_grid &lt;- base_grid |&gt; \n    tidyr::crossing(!!var := var_seq) |&gt;\n    modelr::add_predictions(model = model, var = \"pred\", type = \"probs\") |&gt;\n    tidy_predictions() |&gt;\n    mutate(wave = factor(wave))\n  \n  return(pred_grid)\n}\n\n\nplot_additive_predictions &lt;- function(data, var, x_label, subtitle) {\n    \n  # Generating predictions\n  data |&gt;\n    ggplot(aes(x = as.numeric(.data[[var]]), y = prob, color = status_prev)) +\n    geom_line(linewidth = 1) +\n    ggokabeito::scale_color_okabe_ito() +\n    labs(\n      title = \"Transition Probabilities (Additive Model)\",\n      subtitle = subtitle,\n      x = x_label, \n      y = \"Predicted Probability\", \n      color = \"Previous State\"\n    ) +\n    facet_grid(wave ~ status, labeller = labeller(\n      wave = function(x) case_when(\n        x == 2 ~ \"Year = 2018\",\n        x == 3 ~ \"Year = 2020\",\n        x == 4 ~ \"Year = 2022\",\n      ),\n      status = function(x) paste(\"Transition to:\", x)\n    )) +\n    theme(\n      plot.subtitle = element_text(hjust = 0.5, size = 12, face = \"bold\"),\n      panel.spacing = unit(1, \"lines\")) \n}\n\nget_time_varying_matrix &lt;- function(model, time_point) {\n  expand.grid(\n    Gender = factor(0),\n    Age = mean(data_stack$Age),\n    Education_tri = factor(0),\n    Total_dep_2016 = mean(data_stack$Total_dep_2016),\n    Total_p = mean(data_stack$Total_p),\n    status_prev = factor(1:3),\n    wave = time_point) |&gt; \n    modelr::add_predictions(model, var = \"prob\", type = \"probs\") |&gt; \n    select(status_prev, starts_with(\"prob\")) |&gt; \n    mutate(\n      status_prev = factor(status_prev, labels = state_names),\n      across(starts_with(\"prob\"), ~round(., 3))) |&gt;\n    tibble::column_to_rownames(\"status_prev\") |&gt;\n    as.matrix() |&gt; `colnames&lt;-`(state_names)\n}\n\n\n\n\n\n\n\nCheck out my theme\ncolour &lt;- \"#212427\"\n\ntheme_set(\n  theme_minimal() +\n    theme(\n      plot.title = element_text(hjust = 0.5, size = 14, colour = colour, face = \"bold\"),\n      plot.subtitle = element_text(hjust = 0.5, size = 12, colour = colour),\n      axis.title = element_text(size = 10, colour = colour, face = \"bold\"),\n      strip.text = element_text(size = 10, colour = colour, face = \"bold\"),\n      legend.title = element_text(hjust = 0.5, colour = colour, face = \"bold\"),\n      ))\n\n\n\n\n\n\ndata &lt;- read.csv(here::here(\"analysis/data/data.csv\"))",
    "crumbs": [
      "Analysis",
      "Models",
      "Discrete Time Markov Model"
    ]
  },
  {
    "objectID": "analysis/discrete-markov.html#data-preparation",
    "href": "analysis/discrete-markov.html#data-preparation",
    "title": "Discrete Time Markov Model",
    "section": "Data Preparation",
    "text": "Data Preparation\nBefore preparing the data, we want to create a vector of covariates that we are interested in using in our analysis\n\ncols &lt;- c(\n  \"ID\", \"Gender\", \"Age\", \"Education_tri\",\n  paste0(\"Cardio_risk_\", seq(16, 22, by = 2)), \n  paste0(\"Total_dep_\", seq(2016, 2022, by = 2)),\n  \"Total_p\")\n\nFollowing this, we can now use the extract_years() function to extract the cognitive function data for the years 2016, 2018, and 2020.\n\nWe will also impute some missing values impute = TRUE using logical reasoning (if a respondent has an NA value in 2018, but has a classification of “normal cognition” in 2020, then the missing 2018 value becomes “normal cognition”).\nWe will also treat dementia as an absorbing state absorbing = TRUE.\n\n\ndata_stack &lt;- data |&gt; \n  extract_years(years = seq(2016, 2022, by = 2), impute = TRUE, absorbing = TRUE) |&gt;\n  na.omit()\n\nhead(data_stack)\n\n# A tibble: 6 × 5\n     ID cogfunction2016  cogfunction2018  cogfunction2020  cogfunction2022 \n  &lt;int&gt; &lt;chr&gt;            &lt;chr&gt;            &lt;chr&gt;            &lt;chr&gt;           \n1     1 Normal Cognition Normal Cognition Normal Cognition Normal Cognition\n2     2 Normal Cognition Normal Cognition Normal Cognition Normal Cognition\n3     3 Dementia         Dementia         Dementia         Dementia        \n4     4 Normal Cognition Normal Cognition Normal Cognition Normal Cognition\n5     5 MCI              Normal Cognition Normal Cognition Normal Cognition\n6     6 Normal Cognition Normal Cognition Normal Cognition Normal Cognition\n\n\n\nCreating a stacked dataset\nFor each respondent we will now add in their relevant covariate data. Following this, we transform the data to long format and convert categorical variables to factors using the pivot_and_factorise() function. Additionally, we will fix the Age column to properly represent the age of the respondent at each time point\n\ndata_stack &lt;- data_stack |&gt;\n  inner_join(data[, cols], by = \"ID\") |&gt;\n  pivot_and_factorise() |&gt;\n  group_by(ID) |&gt;\n  mutate(Age = Age - (2022 - as.numeric(as.character(wave))))\n\nhead(data_stack)\n\n# A tibble: 6 × 15\n# Groups:   ID [2]\n     ID wave  status Gender   Age Education_tri Cardio_risk_16 Cardio_risk_18\n  &lt;int&gt; &lt;fct&gt; &lt;fct&gt;  &lt;fct&gt;  &lt;dbl&gt; &lt;fct&gt;                  &lt;int&gt;          &lt;int&gt;\n1     1 2016  1      1         72 2                          0              0\n2     1 2018  1      1         74 2                          0              0\n3     1 2020  1      1         76 2                          0              0\n4     1 2022  1      1         78 2                          0              0\n5     2 2016  1      1         75 2                          1              1\n6     2 2018  1      1         77 2                          1              1\n# ℹ 7 more variables: Cardio_risk_20 &lt;int&gt;, Cardio_risk_22 &lt;int&gt;,\n#   Total_dep_2016 &lt;int&gt;, Total_dep_2018 &lt;int&gt;, Total_dep_2020 &lt;int&gt;,\n#   Total_dep_2022 &lt;int&gt;, Total_p &lt;int&gt;\n\n\nFinally, we will create a new variable status_prev that notes the cognitive status of the respondent in the previous wave (t - 1). This will be done by using the lag function from the dplyr package.\n\ndata_stack &lt;- data_stack |&gt;\n  mutate(status_prev = lag(status), .after = status) |&gt;\n  filter(!is.na(Total_p), Age &gt;= 50) |&gt;\n  ungroup() |&gt; \n  filter(wave != 2016)\n\nhead(data_stack)\n\n# A tibble: 6 × 16\n     ID wave  status status_prev Gender   Age Education_tri Cardio_risk_16\n  &lt;int&gt; &lt;fct&gt; &lt;fct&gt;  &lt;fct&gt;       &lt;fct&gt;  &lt;dbl&gt; &lt;fct&gt;                  &lt;int&gt;\n1     1 2018  1      1           1         74 2                          0\n2     1 2020  1      1           1         76 2                          0\n3     1 2022  1      1           1         78 2                          0\n4     2 2018  1      1           1         77 2                          1\n5     2 2020  1      1           1         79 2                          1\n6     2 2022  1      1           1         81 2                          1\n# ℹ 8 more variables: Cardio_risk_18 &lt;int&gt;, Cardio_risk_20 &lt;int&gt;,\n#   Cardio_risk_22 &lt;int&gt;, Total_dep_2016 &lt;int&gt;, Total_dep_2018 &lt;int&gt;,\n#   Total_dep_2020 &lt;int&gt;, Total_dep_2022 &lt;int&gt;, Total_p &lt;int&gt;",
    "crumbs": [
      "Analysis",
      "Models",
      "Discrete Time Markov Model"
    ]
  },
  {
    "objectID": "analysis/discrete-markov.html#transition-frequencies",
    "href": "analysis/discrete-markov.html#transition-frequencies",
    "title": "Discrete Time Markov Model",
    "section": "Transition frequencies",
    "text": "Transition frequencies\nWe will now calculate the transition frequencies between cognitive states for each time period. We will use the create_transition_table() function to create a transition table for each time period. This will be done with the help of the map() function from the purrr package. Finally, to combine all the transition tables into one dataset, we will use the create_transition_dataset() function.\n\n# Creating a table dataset\ntable_data &lt;- data |&gt;\n  extract_years(seq(2016, 2022, by = 2)) |&gt;\n  rename_with(~ gsub(\"cogfunction\", \"HRS_\", .)) |&gt;\n  mutate(\n    across(c(HRS_2016:HRS_2022), ~ factor(.x, levels = c(\"Normal Cognition\", \"MCI\", \"Dementia\")))\n  )\n\n# Creating transition frequencies ---------------------------------------------\n## These are the time periods we are interested in\ntime_periods &lt;- list(\n  c(\"2016\", \"2018\"),\n  c(\"2018\", \"2020\"), \n  c(\"2020\", \"2022\")\n)\n\n# Applying function\ntransition_results &lt;- purrr::map(time_periods, ~ create_transition_table(.x[1], .x[2]))\nnames(transition_results) &lt;- purrr::map_chr(time_periods, ~ paste(.x[2], .x[1], sep = \"-\"))\n\n### Creating one dataset\ntransition_frequencies &lt;- time_periods |&gt;\n  create_transition_dataset(transition_results = transition_results)\n\nhead(transition_frequencies)\n\n       Period        t_minus_1                t Freq\n1 2016 - 2018 Normal Cognition Normal Cognition  713\n2 2016 - 2018              MCI Normal Cognition   76\n3 2016 - 2018         Dementia Normal Cognition    0\n4 2016 - 2018 Normal Cognition              MCI   58\n5 2016 - 2018              MCI              MCI   49\n6 2016 - 2018         Dementia              MCI    0\n\n\n\nObserved transition matrix\nThe probability distribution of transitions from one state to another can be represented into a transition matrix P = (p_{ij})_{i,j} where each element of position (i, j) represents the transition probability p_{ij}.\nIn order to create this matrix we will use both the create_transitions() and observed_transition_matrix() functions.\n\n## Creating observed transition matrix -----------------------------------------\ntransition_matrix_observed &lt;- data |&gt;\n  extract_years(seq(2016, 2022, by = 2)) |&gt;\n  create_transitions() |&gt;\n  observed_transition_matrix()\n\ntransition_matrix_observed\n\n                 Normal Cognition   MCI Dementia\nNormal Cognition            0.895 0.096    0.009\nMCI                         0.530 0.376    0.094\nDementia                    0.000 0.000    1.000\n\n\n\n\nVisualisation\nLet’s visualize both the transition frequencies (Figure 1) and matrix (Figure 2).\n\n\nCheck out my code\nfig_1 &lt;- transition_frequencies |&gt; tran_stack_graph()\nfig_2 &lt;- transition_frequencies |&gt; tran_heat_map()\n\nfig_1 / fig_2\n\n\n\n\n\n\n\n\nFigure 1: Transition frequencies between cognitive states for each time period.\n\n\n\n\n\n\n\nCheck out my code\nfig_3 &lt;- transition_matrix_observed |&gt;\n  reshape_matrix() |&gt;\n  plot_transition_matrix()\n\nfig_3\n\n\n\n\n\n\n\n\nFigure 2: Observed transition matrix between cognitive states for the years 2016 - 2022.",
    "crumbs": [
      "Analysis",
      "Models",
      "Discrete Time Markov Model"
    ]
  },
  {
    "objectID": "analysis/discrete-markov.html#modelling",
    "href": "analysis/discrete-markov.html#modelling",
    "title": "Discrete Time Markov Model",
    "section": "Modelling",
    "text": "Modelling\n\nMarkov Process Fundamentals\nDiscrete-time Markov models belong to a class of stochastic processes that satisfy the Markov property, which can be formally expressed as:\n\nP(X_{t+1} = j \\vert X_t = i, X_{t-1} = i_{t-1}, \\dots X_0 = i_0) = P(X_{t+1} = j \\vert X_t = i)\n\\tag{1}\nThis property establishes that the future state X_{t+1} depends only on the current state X_t, not on the entire history of states.\n\nTransition Probability Matrix\nFor our three-state system (Normal Cognition, Mild Cognitive Impairment [MCI], Dementia), the transition matrix P captures all possible transition probabilities:\n\nP = \\begin{bmatrix}\np_{11} & p_{12} & p_{13} \\\\\np_{21} & p_{22} & p_{23} \\\\\np_{31} & p_{32} & p_{33} \\\\\n\\end{bmatrix}\n\\tag{2}\nwhere:\n\np_{ij} = P(X_{t+1} = j \\vert X_t = i) represents the probability of transitioning from state i to state j.\nEach row sums to 1, \\sum^3_{j=1} p_{ij} = 1 \\quad  \\forall_i \\in \\{1, 2, 3\\}\n\n\n\nMultinomial Logistic Regression Formulation\nWe model the transition probabilities using multinomial logistic regression, where the log-odds of each transition relative to a reference state are linear functions of covariates.\nFor a system with K states (using state K as reference), we have:\n\nlog \\left( \\frac{P(Y = j \\vert x)}{P(Y = k \\vert x)} \\right) = \\beta_{j0} + \\beta_j^Tx \\qquad \\text{for } j = 1, \\dots K-1\n\\tag{3}\nFor non-reference states j = 1, \\dots, K - 1\n\nP(Y = j \\vert x) = \\frac{e^{\\beta_{0j} + \\beta_j^Tx}}{1 + \\sum^{k - 1}_{k = 1} e^{\\beta_{0k} + \\beta_k^Tx}}\n\\tag{4}\nFor the reference state K:\n\nP(Y = k \\vert x) = \\frac{1}{1 + \\sum^{k - 1}_{k = 1} e^{\\beta_{0k} + \\beta_j^Tx }}\n\\tag{5}\n\n\nTime-Homogeneous Approach\nOur implementation assumes time-homogeneous transitions, but the framework can be extended to time-varying probabilities:\n\nP^{(t)} = \\begin{bmatrix}\np_{11}^{(t)} & p_{12}^{(t)} & \\cdots & p_{1n}^{(t)} \\\\\np_{21}^{(t)} & p_{22}^{(t)} & \\cdots & p_{2n}^{(t)} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\np_{n1}^{(t)} & \\cdots & \\cdots & p_{nn}^{(t)} \\\\\n\\end{bmatrix}\n\\tag{6}\nOur primary analysis assumes the transition matrix remains fixed:\n\nP^{(t)} \\equiv P \\qquad \\forall \\; t\n\\tag{7}\n\n\nAbsorbing State Specification\nWe model Dementia as an absorbing state:\n\np_{3j} = \\begin{cases}\n1 \\qquad \\text{if } j = 3 \\\\\n0 \\qquad \\text{otherwise} \\end{cases}\n\\tag{8}\nyielding the constrained transition matrix:\n\nP = \\begin{bmatrix}\np_{11} & p_{12} & p_{13} \\\\\np_{21} & p_{22} & p_{23} \\\\\n0      & 0      & 1      \\\\\n\\end{bmatrix}\n\\tag{9}\n\n\n\nStationary model\nWe estimate three progressively complex stationary models using nnet::multinom()\n\n\nCheck out my models\n# Baseline model (only gender; reference: NC)\nfit_1a &lt;- nnet::multinom(\n  status ~ Gender + Age + Education_tri + Total_dep_2016, \n  family = multinomial, \n  data = data_stack, trace = FALSE)\n\n# Baseline model (only gender; reference: MCI)\nfit_1b &lt;- nnet::multinom(\n  status ~ Gender + Age + Education_tri + Total_dep_2016, \n  family = multinomial, \n  data = data_stack |&gt; mutate(status = relevel(status, ref = 2)), \n  trace = FALSE)\n\n# With procrastination (reference: NC)\nfit_2a &lt;- nnet::multinom(\n  status ~ Gender + Age + Education_tri + Total_dep_2016 + Total_p, \n  family = multinomial, \n  data = data_stack, trace = FALSE)\n\n# With procrastination (reference: MCI)\nfit_2b &lt;- nnet::multinom(\n  status ~ Gender + Age + Education_tri + Total_dep_2016 + Total_p, \n  family = multinomial, \n  data = data_stack |&gt; mutate(status = relevel(status, ref = 2)), \n  trace = FALSE)\n\n# Full model with previous state (reference NC)\nfit_3a &lt;- nnet::multinom(\n  status ~ Gender + Age + Education_tri + Total_dep_2016 + Total_p + status_prev, \n  family = multinomial, \n  data = data_stack, trace = FALSE)\n\n# Full model with previous state (reference MCI)\nfit_3b &lt;- nnet::multinom(\n  status ~ Gender + Age + Education_tri + Total_dep_2016 + Total_p + status_prev, \n  family = multinomial, \n  data = data_stack |&gt; mutate(status = relevel(status, ref = 2)), \n  trace = FALSE)\n\n\n\nModel comparison\nWe evaluate model improvement (Table 1) using likelihood ratio tests:\n\nD = -2 \\times \\ell_{\\text{reduced}} - \\ell_{\\text{full}}\n\\tag{10}\n\nanova(fit_1a, fit_2a, fit_3a) |&gt;\n  mutate(\n    Model = c(\"Baseline\", \"Procrastination\", \"Procrastination + Previous Status\"),\n    `Resid. Dev`= round(`Resid. Dev`, digits = 3),\n    `LR stat.` = round(`LR stat.`, digits = 3),\n    `Pr(Chi)` = round(`Pr(Chi)`, digits = 3)\n    ) |&gt;\n  DT::datatable(\n    options = list(\n      pageLength = 3,\n      dom = \"t\",\n      ordering = FALSE,\n      columnDefs = list(list(className = \"dt-center\", targets = \"_all\"))\n    ),\n    rownames = FALSE\n  )\n\n\n\n\n\n\n\n\n\nTable 1: Likelihood ratio test for stationary models\n\n\n\n\n\n\nEstimated parameters\nBelow we present the estimated parameters for the stationary models (Table 2). We will transform the estimates to odds ratios and colour them based on significance.\n\n\nCheck out my code\nstationary_results &lt;- rbind(tidy_output(fit_3a), tidy_output(fit_3b)) |&gt;\n  rename(transition = y.level) |&gt;\n  mutate(\n    # Transforming to odds ratios\n    estimate = exp(estimate),\n    conf.low = exp(conf.low),\n    conf.high = exp(conf.high),\n    \n    # Mutating to factors\n    transition = factor(\n      transition, \n      levels = c(\"NC - MCI\", \"MCI - NC\", \n                 \"NC - Dementia\", \"MCI - Dementia\")),\n    term = factor(\n      term, \n      levels = c(\"Being female\", \"Age\", \"High school degree vs. No education\",\n                 \"Further education vs. No education\", \"Depression Scores (2016)\",\n                 \"Procrastination (2020)\", \"Previous state: MCI\", \n                 \"Previous state: Dementia\")),\n    \n    # Creating a colour code\n    colour = case_when(\n      estimate &gt; 1 & p.value &lt; 0.05 ~ \"Positive\",\n      estimate &lt; 1 & p.value &lt; 0.05 ~ \"Negative\",\n      TRUE ~ \"NS\"),\n    \n    colour = factor(colour, levels = c(\"Positive\", \"Negative\", \"NS\"))\n    )\n\nstationary_results |&gt;\n  mutate(across(c(estimate, conf.low, conf.high), ~ round(x = ., digits = 3))) |&gt;\n  DT::datatable(\n    options = list(\n      pageLength = 6,\n      dom = \"tip\",\n      ordering = FALSE,\n      columnDefs = list(list(className = \"dt-center\", targets = \"_all\"))\n    ),\n    rownames = FALSE\n  )\n\n\n\n\n\n\n\n\n\n\nTable 2: Estimated parameters for the stationary model\n\n\n\n\n\n\nModel visualisation\nLet’s visualise the estimated odds ratios (Figure 3) and the predicted transition probabilities (Figure 4) for the stationary model .\n\n\nCheck out my code\nfig_4a &lt;- stationary_results |&gt;\n  filter(!term %in% c(\"Previous state: MCI\", \"Previous state: Dementia\")) |&gt;\n  ggplot(aes(x = estimate, y = transition, colour = colour)) +\n  geom_vline(xintercept = 1, linetype = \"dashed\", color = \"gray50\") +\n  ggstance::geom_pointrangeh(\n    aes(xmin = conf.low, xmax = conf.high),\n    position = ggstance::position_dodgev(height = 0.5),\n    size = 1.25,\n    fatten = 3) +\n  scale_colour_manual(values = c(\n    \"Positive\" = \"#0072B2\", \n    \"Negative\" = \"#E69F00\", \n    \"NS\"       = \"#B2BEB5\")) +\n  labs(title = \"Odds ratios (stationary model)\",\n       x = \"Odds Ratio\", y = \"Predictor\") +\n  guides(colour = \"none\") +\n  facet_wrap(~ term, scales = \"free_x\") +\n  theme_bw() +\n  theme(\n    plot.title = element_text(hjust = 0.5, size = 14, face = \"bold\"),\n    axis.title = element_text(size = 12, face = \"bold\"),\n    strip.text = element_text(size = 10, face = \"bold\"),\n    panel.grid.major.y = element_blank(),\n    panel.grid.minor.y = element_blank())\n\nfig_4a\n\n\n\n\n\n\n\n\nFigure 3: Estimated odds ratios for the stationary model.\n\n\n\n\n\n\n\nCheck out my code\n## Making a prediction dataset -------------------------------------------------\npred_data &lt;- expand.grid(\n  Gender = factor(0),\n  Age = mean(data_stack$Age),\n  Education_tri = factor(0),\n  Total_dep_2016 = mean(data_stack$Total_dep_2016),\n  status_prev = levels(data_stack$status_prev),\n  Total_p = seq(0, 60, length = 200))\n\n## Plotting predictions\nfig_4b &lt;- pred_data |&gt;\n  modelr::add_predictions(model = fit_3a, var = \"pred\", type = \"probs\") |&gt;\n  tidy_predictions() |&gt;\n  plot_predictions_stationary(variable = Total_p, x_axis = \"Total Procrastination\")\n\nfig_4b\n\n\n\n\n\n\n\n\nFigure 4: Predicted transition probabilities from the stationary model.\n\n\n\n\n\n\n\nEstimated transition matrix\nFinally, we can compare the observed and predicted transition matrices. We will use the estimated probabilities from the model to fill in the transition matrix.\n\n# Get all unique states\nnames &lt;- c(\"Normal Cognition\", \"MCI\", \"Dementia\")\nstates &lt;- sort(unique(data_stack$status))\nn_states &lt;- length(states)\n\n# Create empty transition matrix\ntransition_matrix_estimated &lt;- matrix(\n  0, nrow = n_states, ncol = n_states,\n  dimnames = list(paste(\"From\", names), paste(\"To\", names))\n  )\n\n# Getting estimated probabilities\nestimated_probs &lt;- expand.grid(\n  Gender = factor(0),\n  Age = mean(data_stack$Age),\n  Education_tri = factor(0),\n  Total_dep_2016 = mean(data_stack$Total_dep_2016),\n  Total_p = mean(data_stack$Total_p),\n  status_prev = states) |&gt;\n  modelr::add_predictions(model = fit_3a, var = \"pred\", type = \"probs\")\n\n# Filling in matrix\nfor(i in 1:n_states) {\n  transition_matrix_estimated[i, ] &lt;- estimated_probs$pred[i, ]\n}\n\ntransition_matrix_estimated |&gt; round(digits = 3)\n\n                      To Normal Cognition To MCI To Dementia\nFrom Normal Cognition               0.786  0.188       0.025\nFrom MCI                            0.398  0.449       0.153\nFrom Dementia                       0.000  0.000       1.000\n\n\nLet’s plot this and then compare with our observed matrix\n\n\nCheck out my code\nfig_5 &lt;- transition_matrix_estimated |&gt;\n  reshape_matrix() |&gt;\n  plot_transition_matrix(observed = FALSE)\n\nfig_3 + fig_5 + plot_layout(axis_titles = \"collect\", guides = \"collect\")\n\n\n\n\n\n\n\n\nFigure 5: Comparison of observed and estimated transition matrices.\n\n\n\n\n\n\n\n\nNon-stationary model\nWe can also estimate a non-stationary model (Equation 6) by incorporating time (wave) into our model. This model allows for time-varying transition probabilities p^{(t)}_{ij}.\nWe estimate three progressively complex non-stationary models:\n\nAdditive time effects (fit_4): Baseline covariates + wave\nState-specific time effects (fit_5): Interaction between previous state and wave\nFull time interactions (fit_6): All covariates interacting with wave\n\n\n\nCheck out my models\n## Small processing to fix wave column\ndata_stack &lt;- data_stack |&gt;\n  mutate(wave = case_when(\n    wave == \"2016\" ~ 1,\n    wave == \"2018\" ~ 2,\n    wave == \"2020\" ~ 3,\n    wave == \"2022\" ~ 4\n  ))\n\n# Model 4: Additive time effects\nfit_4a &lt;- nnet::multinom(\n  status ~ Gender + Age + Education_tri + Total_dep_2016 + Total_p + status_prev + wave, family = multinomial, \n  data = data_stack, trace = FALSE)\n\nfit_4b &lt;- nnet::multinom(\n  status ~ Gender + Age + Education_tri + Total_dep_2016 + Total_p + status_prev + wave, family = multinomial, \n  data = data_stack |&gt; mutate(status = relevel(status, ref = 2)), \n  trace = FALSE)\n\n# Model 5: State-specific time effects\nfit_5a &lt;- nnet::multinom(\n  status ~ Gender + Age + Education_tri + Total_dep_2016 + Total_p + (status_prev * wave), family = multinomial, \n  data = data_stack, trace = FALSE)\n\nfit_5b &lt;- nnet::multinom(\n  status ~ Gender + Age + Education_tri + Total_dep_2016 + Total_p + (status_prev * wave), family = multinomial, \n  data = data_stack |&gt; mutate(status = relevel(status, ref = 2)), \n  trace = FALSE)\n\n# Model 6: Full time interactions\nfit_6a &lt;- nnet::multinom(\n  status ~ (Gender + Age + Education_tri + Total_dep_2016 + Total_p + status_prev) * wave, family = multinomial, \n  data = data_stack, trace = FALSE)\n\nfit_6b &lt;- nnet::multinom(\n  status ~ (Gender + Age + Education_tri + Total_dep_2016 + Total_p + status_prev) * wave, family = multinomial, \n  data = data_stack |&gt; mutate(status = relevel(status, ref = 2)), \n  trace = FALSE)\n\n\n\nModel comparison\nAgain, we will evaluate model improvement using likelihood ratio tests (Equation 10; Table 3). However, this time, we will also compare the best fitted non-stationary models fit_3.\n\n\nCheck out my code\n# Fit statistics\nmodels &lt;- list(\n  \"Stationary\" = fit_3a,\n  \"Additive Time\" = fit_4a,\n  \"State-Time Interaction\" = fit_5a,\n  \"Full Interactions\" = fit_6a\n)\n\n# Create comparison table\ncomparison_table &lt;- purrr::map_dfr(models, broom::glance, .id = \"Model\") |&gt;\n  select(edf:AIC) |&gt;\n  mutate(across(where(is.numeric), \\(x) round(x, digits = 1)))\n\n# Outputting as table\nanova(fit_3a, fit_4a, fit_5a, fit_6a) |&gt;\n  mutate(\n    Model = c(\"Stationary\", \"Additive\", \"State-Time Interactions\", \"Full Interactions\"),\n    `Resid. Dev` = round(`Resid. Dev`, digits = 3),\n    `LR stat.` = round(`LR stat.`, digits = 3),\n    `Pr(Chi)` = round(`Pr(Chi)`, digits = 3)\n    ) |&gt;\n  cbind(comparison_table) |&gt;\n  DT::datatable(\n    options = list(\n      pagelength = 4,\n      dom = \"t\",\n      ordering = FALSE,\n      columnDefs = list(list(className = 'dt-center', targets = \"_all\"))\n    ),\n    rownames = FALSE\n  )\n\n\n\n\n\n\n\n\n\n\nTable 3: Likelihood ratio test for non-stationary models\n\n\n\n\nThis is interesting!! Looks like adding in time as an additive term improved things. However, having full time interactions is better than having state-time interactions\n\nAdditive ModelMultiplicative Model\n\n\n\nEstimated parameters\nKey coefficients from the selected non-stationary model fit_4\n\nadditive_results &lt;- rbind(tidy_output(fit_4a), tidy_output(fit_4b))\n\nadditive_results |&gt;\n  rename(transiton = y.level) |&gt;\n  mutate(across(c(estimate, conf.low, conf.high), ~ round(x = ., digits = 3))) |&gt;\n  DT::datatable(\n    options = list(\n      pageLength = 6,\n      ordering = FALSE,\n      columnDefs = list(list(className = \"dt-center\", targets = \"_all\"))\n    ),\n    rownames = FALSE,\n    colnames = c(\"Transition\", \"Predictor\", \"Estimate\", \"Standard Error\",\n                 \"Statistic\", \"p-val\", \"Lower CI\", \"Upper CI\")\n  )\n\n\n\n\n\n\n\nModel visualisation\nLet’s visualize the predicted transition probabilities from the non-stationary model.\n\nFigure 6 shows the predicted transition probabilities for age\nFigure 7 shows the predicted transition probabilities for depression\nFigure 8 shows the predicted transition probabilities for per education level\nFigure 9 shows the predicted transition probabilities for procrastination\n\n\nAgeDepressionEducation LevelProcrastination\n\n\n\n\nCheck our my code\ncreate_additive_predictions(data = data_stack, model = fit_4a, var = \"Age\", var_seq = seq(50, 97, by = 5)) |&gt;\n  plot_additive_predictions(var = \"Age\", x_label = \"Age\", subtitle = \"By Age\")\n\n\n\n\n\n\n\n\nFigure 6: Predicted transition probabilities from the non-stationary model (for age).\n\n\n\n\n\n\n\n\n\nCheck our my code\ncreate_additive_predictions(data = data_stack, model = fit_4a, var = \"Total_dep_2016\", var_seq = seq(0, 8, by = 1)) |&gt;\n  plot_additive_predictions(var = \"Total_dep_2016\", x_label = \"Depression\", subtitle = \"By depression\")\n\n\n\n\n\n\n\n\nFigure 7: Predicted transition probabilities from the non-stationary model (for depression).\n\n\n\n\n\n\n\n\n\nCheck our my code\ncreate_additive_predictions(data = data_stack, model = fit_4a, var = \"Education_tri\", var_seq = factor(c(0:2)), hold_constant = list(Gender = factor(0))) |&gt;\n  plot_additive_predictions(var = \"Education_tri\", x_label = \"Education\", subtitle = \"By education level\") +\n  geom_point(size = 2) +\n  scale_x_continuous(breaks = c(0, 1, 2), labels = c(\"No Education\", \"High School\", \"Further Education\")) +\n  theme(axis.text.x = element_text(size = 8, angle = 60, vjust = 0.90, hjust = 1))\n\n\n\n\n\n\n\n\nFigure 8: Predicted transition probabilities from the non-stationary model (for having a high school degree).\n\n\n\n\n\n\n\n\n\nCheck our my code\ncreate_additive_predictions(data = data_stack, model = fit_4a, var = \"Total_p\", var_seq = seq(0, 60, by = 1)) |&gt;\n  plot_additive_predictions(var = \"Total_p\", x_label = \"Procrastination\", subtitle = \"By procrastination\")\n\n\n\n\n\n\n\n\nFigure 9: Predicted transition probabilities from the non-stationary model (for procrastination).\n\n\n\n\n\n\n\n\n\n\nEstimated transition matrices\nFigure 10 shows the estimated time-varying transition matrices\n\n\nCheck out my code\n# Create prediction grid for each time point\ntime_points &lt;- unique(data_stack$wave)\nstate_names &lt;- c(\"Normal Cognition\", \"MCI\", \"Dementia\")\n\n# Get matrices for all time points\ntime_varying_matrices &lt;- purrr::map(\n  setNames(time_points, paste(time_points, \"Years\")),\n  ~ get_time_varying_matrix(fit_4a, .x)\n)\n\n# Converting into a tidy data frame\nnon_stationary_matrices &lt;- purrr::imap_dfr(\n  time_varying_matrices,\n  ~ as.data.frame(.x) |&gt; \n    tibble::rownames_to_column(\"From\") |&gt; \n    pivot_longer(-From, names_to = \"To\", values_to = \"probability\") |&gt; \n    mutate(Time = .y),\n  .id = \"Time_point\"\n) |&gt; \n  mutate(\n    From = factor(From, levels = state_names),\n    To = factor(To, levels = rev(state_names)),\n    Time_point = forcats::fct_inorder(Time_point)\n  )\n\n# Plotting \nnon_stationary_matrices |&gt;\nggplot(aes(x = From, y = To, fill = probability)) +\n  geom_tile(color = \"white\", linewidth = 0.5) +\n  geom_text(\n    aes(label = format(round(probability, 3), nsmall = 3)),\n    size = 4.5, \n    color = \"#212427\",\n    fontface = \"bold\") +\n    colorspace::scale_fill_continuous_diverging(\n    palette = \"Blue-Red 3\", mid = 0.50, alpha = 0.5, \n    limits = c(0, 1), name = \"Transition \\nProbability\") +\n  labs(\n    title = \"Estimated Time-Varying Transition Matrices\",\n    subtitle = \"Showing changes in transition probabilities over time\",\n    x = \"Previous State (t-1)\",\n    y = \"Next State (t)\",\n    fill = \"Probability\"\n  ) +\n  facet_wrap(~ Time_point, ncol = 3, labeller = labeller(\n    Time_point = function(x){\n      case_when(x == \"2 Years\" ~ \"2018\",\n                x == \"3 Years\" ~ \"2020\",\n                x == \"4 Years\" ~ \"2022\")\n    })) +\n  theme(\n    axis.text = element_text(size = 10),\n    axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1),\n    legend.position = \"right\",\n    legend.text = element_text(size = 9),\n    panel.grid = element_blank()\n  )\n\n\n\n\n\n\n\n\nFigure 10: Estimated time-varying transition matrices.\n\n\n\n\n\n\n\n\n\nEstimated parameters\nKey coefficients from the selected non-stationary model fit_6\n\nmultiplicative_output &lt;- rbind(\n  tidy_output(fit_6a, multiplicative = TRUE),\n  tidy_output(fit_6b, multiplicative = TRUE))\n\nmultiplicative_output |&gt;\n  mutate(across(c(estimate, conf.low, conf.high), ~ round(x = ., digits = 3))) |&gt;\n  DT::datatable(\n    options = list(\n      pageLength = 6,\n      ordering = FALSE,\n      columnDefs = list(list(className = \"dt-center\", targets = \"_all\"))\n    ),\n    rownames = FALSE,\n    colnames = c(\"Transition\", \"Predictor\", \"Estimate\", \"Standard Error\",\n                 \"Statistic\", \"p-val\", \"Lower CI\", \"Upper CI\")\n  )",
    "crumbs": [
      "Analysis",
      "Models",
      "Discrete Time Markov Model"
    ]
  },
  {
    "objectID": "analysis/discrete-markov.html#matrix-distance-metrics",
    "href": "analysis/discrete-markov.html#matrix-distance-metrics",
    "title": "Discrete Time Markov Model",
    "section": "Matrix distance metrics",
    "text": "Matrix distance metrics\nGiven two matrices P = (p_{ij}) and \\hat{P} = (\\hat{p}_{ij}) of size m \\times n, we define the following distance measures\nFrobenius Norm (Matrix Euclidean Distance)\nD_{\\text{Frobenius}}(P, \\hat{P}) = \\|P - \\hat{P}\\|_F = \\sqrt{\\sum_{i=1}^{m}\\sum_{j=1}^{n} |p_{ij} - \\hat{p}_{ij}|^2}\n\nMeasures the Euclidean distance in matrix space\nSensitive to large differences due to squaring\nEquivalent to the vector 2-norm of the flattened matrix\n\nManhattan Distance (L1 Norm)\nD_{\\text{Manhattan}}(P, \\hat{P}) = \\sum_{i=1}^{m}\\sum_{j=1}^{n} |p_{ij} - \\hat{p}_{ij}|\n\nSum of absolute differences between corresponding elements\nLess sensitive to outliers than Frobenius norm\nUseful when sparse differences are important\n\nMaximum Difference (Infinity Norm)\nD_{\\text{Max}}(A, B) = \\max_{\\substack{1 \\leq i \\leq m \\\\ 1 \\leq j \\leq n}} |a_{ij} - b_{ij}|\n\nCaptures the single largest difference between elements\nUseful for worst-case analysis\nIgnores the distribution of other differences\n\nMean Absolute Difference\nD_{\\text{MeanAbs}}(P, \\hat{P}) = \\frac{1}{mn}\\sum_{i=1}^{m}\\sum_{j=1}^{n} |p_{ij} - \\hat{p}_{ij}|\n\nAverage absolute difference across all elements\nScales with matrix size (unlike Manhattan distance)\nEasy to interpret as average error per element\n\nRoot Mean Square Error (RMSE)\nD_{\\text{RMSE}}(P, \\hat{P}) = \\sqrt{\\frac{1}{mn}\\sum_{i=1}^{m}\\sum_{j=1}^{n} (p_{ij} - \\hat{p}_{ij})^2}\n\nSimilar to Frobenius but normalized by matrix size\nSensitive to large errors due to squaring\nCommon in statistical and machine learning applications\n\nCorrelation-Based Distance\nD_{\\text{Corr}}(P, \\hat{P}) = 1 - \\frac{\\sum_{i=1}^{m}\\sum_{j=1}^{n} (p_{ij} - \\bar{P})(\\hat{p}_{ij} - \\bar{\\hat{P}})}{\\sqrt{\\sum_{i=1}^{m}\\sum_{j=1}^{n} (p_{ij} - \\bar{P})^2 \\sum_{i=1}^{m}\\sum_{j=1}^{n} (\\hat{p}_{ij} - \\bar{\\hat{p}})^2}}\n\nMeasures linear relationship between matrix elements\n\\bar{P} = \\frac{1}{mn}\\sum_{i,j}p_{ij} (mean of all elements in P)\n\\bar{\\hat{P}} = \\frac{1}{mn}\\sum_{i,j}\\hat{p}_{ij} (mean of all elements in \\hat{P})\nRange: [0,2] where 0 = perfect positive correlation\n\nKullback-Leibler Divergence\nFor matrices where each row sums to 1 (\\sum_j p_{ij} = \\sum_j \\hat{P}_{ij} = 1) and p_{ij}, \\hat{p}_{ij} &gt; 0:\n\nD_{\\text{KL}}(P \\parallel \\hat{P}) = \\sum_{i=1}^{m}\\sum_{j=1}^{n} p_{ij} \\log\\left(\\frac{p_{ij}}{\\hat{p}_{ij}}\\right)\n\n\nMeasures information loss when \\hat{P} approximates P\nAsymmetric: D_{\\text{KL}}(P \\parallel \\hat{P}) \\neq D_{\\text{KL}}(\\hat{P} \\parallel P)\n0\\log0 = 0 by convention\nIn practice, add \\epsilon &gt; 0 (e.g., 10^{-10}) to avoid zeros\n\n\nImplementation\nLet’s calculate the distance metrics between the observed P and estimated transition matrices \\hat{P}.\n\np       &lt;- transition_matrix_observed\np_hat   &lt;- transition_matrix_estimated\nepsilon &lt;- 1e-10\n\n# Creating tibble of distance metrics\ndistances &lt;- tibble(\n  Metric = c(\"Frobenius\", \"Manhattan\", \"Max\", \"MeanAbs\", \"RMSE\", \"Correlation\", \"KL\"),\n  Value = c(\n    norm(p - p_hat, type = \"F\"),\n    sum(abs(p - p_hat)),\n    max(abs(p - p_hat)),\n    mean(abs(p - p_hat)),\n    sqrt(mean((p - p_hat)^2)),\n    1 - cor(c(p), c(p_hat)),\n    sum((p + epsilon) * log((p + epsilon) / (p_hat + epsilon)))\n  )) |&gt;\n  mutate(Value = round(Value, 4))\n\ndistances |&gt;\n  mutate(Metric = case_when(\n    Metric == \"Frobenius\" ~ \"Frobenius Distance\",\n    Metric == \"Manhattan\" ~ \"Manhattan Distance\",\n    Metric == \"Max\" ~ \"Max Difference\",\n    Metric == \"MeanAbs\" ~ \"Mean Absolute Difference\",\n    Metric == \"RMSE\" ~ \"Root Mean Square Error\",\n    Metric == \"Correlation\" ~ \"Correlation Distance\",\n    Metric == \"KL\" ~ \"Kullback-Leibler Divergence\"\n  )) |&gt;\n  knitr::kable(caption = \"Distance based metrics\", align = \"c\") |&gt;\n  kableExtra::kable_styling(\n    bootstrap_options = c(\"striped\", \"hover\"),\n    full_width = FALSE)\n\n\nDistance based metrics\n\n\nMetric\nValue\n\n\n\n\nFrobenius Distance\n0.2165\n\n\nManhattan Distance\n0.4814\n\n\nMax Difference\n0.1320\n\n\nMean Absolute Difference\n0.0535\n\n\nRoot Mean Square Error\n0.0722\n\n\nCorrelation Distance\n0.0166\n\n\nKullback-Leibler Divergence\n0.0811\n\n\n\n\n\n\n\n\n\nVisualisation\nLet’s visualize the distance metrics between the observed and estimated transition matrices (Figure 11).\n\n\nCheck out my code\ncaption = stringr::str_glue(\n  \"**RMSE:** Root Mean Squared Error\\n\n   **KL:** Kullback-Leibler Divergence\\n\n   **Correlation:** 1 - Pearson Correlation Coefficient\")\n\ndistances |&gt;\n  ggplot(aes(x = reorder(Metric, -Value), y = Value, fill = Metric)) +\n  geom_col(colour = \"black\") +\n  geom_text(aes(label = Value), vjust = -0.5) +\n  ggokabeito::scale_fill_okabe_ito() +\n  scale_y_continuous(expand = expansion(mult = c(0.075, 0.075))) +\n  labs(\n    title = \"Distance Between Transition Matrices\",\n    x = \"Distance Metric\",\n    y = \"Value\",\n    caption = caption) +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(hjust = 0.5, size = 14, face = \"bold\"),\n    axis.title = element_text(face = \"bold\", size = 12),\n    plot.caption = ggtext::element_markdown(size = 10),\n    legend.position = \"none\")\n\n\n\n\n\n\n\n\nFigure 11: Distance metrics between observed and estimated transition matrices.",
    "crumbs": [
      "Analysis",
      "Models",
      "Discrete Time Markov Model"
    ]
  },
  {
    "objectID": "analysis/paper.html",
    "href": "analysis/paper.html",
    "title": "Paper",
    "section": "",
    "text": "HTML\n   \n  \n  \n   HTML (new window)\n  \n\n  \n   PDF\n   \n  \n  \n   PDF (download)"
  }
]